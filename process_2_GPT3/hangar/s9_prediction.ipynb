{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 7: Predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n",
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n",
      "Length: 50\n",
      "Unique Cell Types: 5\n",
      "Unique Gene Markers: 50\n",
      "--------------------\n",
      "Subject Outlier 0 (Embedding): ZScore_v0\n",
      "Subject Outlier 1 (Expression): ZScore_v0\n",
      "Subject_Outlier: ZScore_v0_ZScore_v0\n",
      "Subject normalization 0 (Embedding): StandardScaler\n",
      "Subject normalization 1 (Expression): StandardScaler\n",
      "Subject Autoencoder 0 (Embedding): Basic_v1\n",
      "Subject Autoencoder 1 (Expression): Basic_v1\n",
      "Subject Dimension Reduction 0 (Embedding): PCA_n3\n",
      "Subject Dimension Reduction 1 (Expression): Free\n",
      "--------------------\n",
      "Tools of ML: Complex\n",
      "Machine Learning Models: Basic\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "except: \n",
    "    %run s0_config.ipynb \n",
    "    %run s8_preparation.ipynb \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3- `Bench`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0- `Operation: Neural Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 1536)]               0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNo  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " ise)                                                                                             \n",
      "                                                                                                  \n",
      " gaussian_noise_1 (Gaussian  (None, 1536)                 0         ['input_emb[0][0]']           \n",
      " Noise)                                                                                           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   128       ['gaussian_noise[0][0]']      \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  393472    ['gaussian_noise_1[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   2080      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 160)                  0         ['dense_1[0][0]',             \n",
      "                                                                     'dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 5)                    805       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 429381 (1.64 MB)\n",
      "Trainable params: 429381 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.6484 - accuracy: 0.0938 - val_loss: 1.8837 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5941 - accuracy: 0.1875 - val_loss: 1.9291 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5782 - accuracy: 0.2500 - val_loss: 1.9717 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5083 - accuracy: 0.2188 - val_loss: 2.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5322 - accuracy: 0.2188 - val_loss: 2.0622 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5016 - accuracy: 0.2500 - val_loss: 2.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4785 - accuracy: 0.4062 - val_loss: 2.1550 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4857 - accuracy: 0.2812 - val_loss: 2.2043 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4479 - accuracy: 0.3750 - val_loss: 2.2534 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4146 - accuracy: 0.4062 - val_loss: 2.3042 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4289 - accuracy: 0.3438 - val_loss: 2.3568 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3638 - accuracy: 0.3750 - val_loss: 2.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3699 - accuracy: 0.3125 - val_loss: 2.4693 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3945 - accuracy: 0.2812 - val_loss: 2.5291 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3780 - accuracy: 0.4062 - val_loss: 2.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.3532 - accuracy: 0.3438 - val_loss: 2.6538 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3516 - accuracy: 0.3750 - val_loss: 2.7181 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2932 - accuracy: 0.3125 - val_loss: 2.7845 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3294 - accuracy: 0.4062 - val_loss: 2.8516 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3827 - accuracy: 0.2500 - val_loss: 2.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3040 - accuracy: 0.3750 - val_loss: 2.9851 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3164 - accuracy: 0.3750 - val_loss: 3.0517 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2879 - accuracy: 0.3125 - val_loss: 3.1195 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2695 - accuracy: 0.4688 - val_loss: 3.1880 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2679 - accuracy: 0.4375 - val_loss: 3.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2204 - accuracy: 0.5000 - val_loss: 3.3323 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2406 - accuracy: 0.5312 - val_loss: 3.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2206 - accuracy: 0.4688 - val_loss: 3.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2290 - accuracy: 0.4375 - val_loss: 3.5598 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1899 - accuracy: 0.6250 - val_loss: 3.6369 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7083 - accuracy: 0.6000\n",
      "Fold 1 Test Accuracy: 0.6000000238418579\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 1.7058 - accuracy: 0.0625 - val_loss: 1.4379 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6665 - accuracy: 0.1562 - val_loss: 1.4839 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6287 - accuracy: 0.2188 - val_loss: 1.5315 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5786 - accuracy: 0.2500 - val_loss: 1.5834 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5797 - accuracy: 0.1562 - val_loss: 1.6371 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5366 - accuracy: 0.2188 - val_loss: 1.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5023 - accuracy: 0.4375 - val_loss: 1.7532 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5023 - accuracy: 0.3125 - val_loss: 1.8183 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4499 - accuracy: 0.3125 - val_loss: 1.8876 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4478 - accuracy: 0.3125 - val_loss: 1.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4655 - accuracy: 0.3125 - val_loss: 2.0402 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4222 - accuracy: 0.3125 - val_loss: 2.1210 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3796 - accuracy: 0.3438 - val_loss: 2.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4106 - accuracy: 0.3750 - val_loss: 2.2894 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3229 - accuracy: 0.4062 - val_loss: 2.3772 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3853 - accuracy: 0.4062 - val_loss: 2.4654 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3668 - accuracy: 0.4688 - val_loss: 2.5538 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3143 - accuracy: 0.4375 - val_loss: 2.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2993 - accuracy: 0.4688 - val_loss: 2.7295 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3093 - accuracy: 0.4375 - val_loss: 2.8173 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3192 - accuracy: 0.4375 - val_loss: 2.9056 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2949 - accuracy: 0.4062 - val_loss: 2.9914 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2543 - accuracy: 0.4688 - val_loss: 3.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3128 - accuracy: 0.5000 - val_loss: 3.1561 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2127 - accuracy: 0.5938 - val_loss: 3.2333 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2014 - accuracy: 0.5312 - val_loss: 3.3099 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2293 - accuracy: 0.5000 - val_loss: 3.3835 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2308 - accuracy: 0.5625 - val_loss: 3.4561 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1574 - accuracy: 0.5938 - val_loss: 3.5299 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1289 - accuracy: 0.6875 - val_loss: 3.6041 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0781 - accuracy: 0.3000\n",
      "Fold 2 Test Accuracy: 0.30000001192092896\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 1.7049 - accuracy: 0.0625 - val_loss: 1.5415 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.6749 - accuracy: 0.0938 - val_loss: 1.5897 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6401 - accuracy: 0.2500 - val_loss: 1.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5929 - accuracy: 0.2500 - val_loss: 1.6847 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6175 - accuracy: 0.1875 - val_loss: 1.7324 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5544 - accuracy: 0.2812 - val_loss: 1.7792 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5723 - accuracy: 0.2812 - val_loss: 1.8271 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5225 - accuracy: 0.2500 - val_loss: 1.8758 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5050 - accuracy: 0.3750 - val_loss: 1.9258 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5007 - accuracy: 0.1875 - val_loss: 1.9785 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4883 - accuracy: 0.2812 - val_loss: 2.0331 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5011 - accuracy: 0.3438 - val_loss: 2.0892 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4423 - accuracy: 0.3750 - val_loss: 2.1472 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4490 - accuracy: 0.2812 - val_loss: 2.2058 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4706 - accuracy: 0.3750 - val_loss: 2.2650 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4183 - accuracy: 0.3438 - val_loss: 2.3241 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4190 - accuracy: 0.3438 - val_loss: 2.3832 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4212 - accuracy: 0.3750 - val_loss: 2.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3816 - accuracy: 0.5000 - val_loss: 2.4984 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4430 - accuracy: 0.4062 - val_loss: 2.5523 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4113 - accuracy: 0.3125 - val_loss: 2.6039 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3429 - accuracy: 0.4688 - val_loss: 2.6544 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3635 - accuracy: 0.6250 - val_loss: 2.7038 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3514 - accuracy: 0.5312 - val_loss: 2.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3654 - accuracy: 0.4688 - val_loss: 2.8015 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2906 - accuracy: 0.5625 - val_loss: 2.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3134 - accuracy: 0.5938 - val_loss: 2.8931 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3033 - accuracy: 0.5938 - val_loss: 2.9371 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3431 - accuracy: 0.5312 - val_loss: 2.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2924 - accuracy: 0.6562 - val_loss: 3.0136 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4266 - accuracy: 0.4000\n",
      "Fold 3 Test Accuracy: 0.4000000059604645\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.6817 - accuracy: 0.0938 - val_loss: 1.8130 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6218 - accuracy: 0.2500 - val_loss: 1.8630 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6136 - accuracy: 0.1875 - val_loss: 1.9108 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5462 - accuracy: 0.3125 - val_loss: 1.9581 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5549 - accuracy: 0.2188 - val_loss: 2.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5033 - accuracy: 0.3438 - val_loss: 2.0556 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4951 - accuracy: 0.2812 - val_loss: 2.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5281 - accuracy: 0.2812 - val_loss: 2.1626 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4388 - accuracy: 0.5000 - val_loss: 2.2208 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4112 - accuracy: 0.4062 - val_loss: 2.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3911 - accuracy: 0.4375 - val_loss: 2.3472 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3520 - accuracy: 0.5625 - val_loss: 2.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3967 - accuracy: 0.4375 - val_loss: 2.4878 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3421 - accuracy: 0.5625 - val_loss: 2.5627 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3424 - accuracy: 0.4062 - val_loss: 2.6399 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2996 - accuracy: 0.5000 - val_loss: 2.7208 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3569 - accuracy: 0.4062 - val_loss: 2.8044 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2910 - accuracy: 0.4062 - val_loss: 2.8885 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.2968 - accuracy: 0.4062 - val_loss: 2.9746 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3121 - accuracy: 0.4375 - val_loss: 3.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2827 - accuracy: 0.5000 - val_loss: 3.1514 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2426 - accuracy: 0.5000 - val_loss: 3.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2380 - accuracy: 0.5312 - val_loss: 3.3331 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2611 - accuracy: 0.4375 - val_loss: 3.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1730 - accuracy: 0.6250 - val_loss: 3.5155 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1517 - accuracy: 0.6562 - val_loss: 3.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1799 - accuracy: 0.5625 - val_loss: 3.6967 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1225 - accuracy: 0.6250 - val_loss: 3.7867 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1275 - accuracy: 0.6250 - val_loss: 3.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0654 - accuracy: 0.7188 - val_loss: 3.9693 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.6297 - accuracy: 0.7000\n",
      "Fold 4 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 562ms/step - loss: 1.6741 - accuracy: 0.1562 - val_loss: 1.5922 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6333 - accuracy: 0.2812 - val_loss: 1.6602 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5869 - accuracy: 0.2500 - val_loss: 1.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6073 - accuracy: 0.2812 - val_loss: 1.7931 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5401 - accuracy: 0.3438 - val_loss: 1.8606 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4805 - accuracy: 0.3125 - val_loss: 1.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4465 - accuracy: 0.3438 - val_loss: 1.9998 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4585 - accuracy: 0.1875 - val_loss: 2.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4745 - accuracy: 0.2188 - val_loss: 2.1456 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4419 - accuracy: 0.3438 - val_loss: 2.2203 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3875 - accuracy: 0.3750 - val_loss: 2.2963 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4065 - accuracy: 0.3125 - val_loss: 2.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3456 - accuracy: 0.4375 - val_loss: 2.4550 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3379 - accuracy: 0.3750 - val_loss: 2.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3820 - accuracy: 0.3750 - val_loss: 2.6196 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3097 - accuracy: 0.5000 - val_loss: 2.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3463 - accuracy: 0.3750 - val_loss: 2.7891 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3217 - accuracy: 0.4062 - val_loss: 2.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3183 - accuracy: 0.3750 - val_loss: 2.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3109 - accuracy: 0.4688 - val_loss: 3.0512 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3063 - accuracy: 0.3125 - val_loss: 3.1417 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2880 - accuracy: 0.3750 - val_loss: 3.2336 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2393 - accuracy: 0.4688 - val_loss: 3.3247 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2391 - accuracy: 0.4062 - val_loss: 3.4151 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1827 - accuracy: 0.5938 - val_loss: 3.5074 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2468 - accuracy: 0.4062 - val_loss: 3.5986 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1971 - accuracy: 0.4375 - val_loss: 3.6889 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2372 - accuracy: 0.3438 - val_loss: 3.7791 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1644 - accuracy: 0.5938 - val_loss: 3.8697 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1949 - accuracy: 0.5000 - val_loss: 3.9590 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7002 - accuracy: 0.7000\n",
      "Fold 5 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.5400000035762786\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_0 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_0_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_0_Aut_0_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_0_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_0_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_0_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 1536)]               0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_10 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_11 (Gaussia  (None, 1536)                 0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 64)                   128       ['gaussian_noise_10[0][0]']   \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 256)                  393472    ['gaussian_noise_11[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 64)                   0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 256)                  0         ['dense_27[0][0]']            \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 32)                   2080      ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 128)                  32896     ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 160)                  0         ['dense_26[0][0]',            \n",
      " )                                                                   'dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 5)                    805       ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 429381 (1.64 MB)\n",
      "Trainable params: 429381 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 1.7209 - accuracy: 0.2812 - val_loss: 3.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3220 - accuracy: 0.9688 - val_loss: 3.1571 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 3.2099 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 3.2618 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.3266 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1900e-04 - accuracy: 1.0000 - val_loss: 3.3860 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1998e-04 - accuracy: 1.0000 - val_loss: 3.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5956e-04 - accuracy: 1.0000 - val_loss: 3.4849 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6616e-04 - accuracy: 1.0000 - val_loss: 3.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9218e-05 - accuracy: 1.0000 - val_loss: 3.5652 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.6017e-05 - accuracy: 1.0000 - val_loss: 3.6021 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6454e-05 - accuracy: 1.0000 - val_loss: 3.6383 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6140e-05 - accuracy: 1.0000 - val_loss: 3.6706 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.2906e-06 - accuracy: 1.0000 - val_loss: 3.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4845e-05 - accuracy: 1.0000 - val_loss: 3.7321 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2538e-06 - accuracy: 1.0000 - val_loss: 3.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.0405e-06 - accuracy: 1.0000 - val_loss: 3.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.1851e-06 - accuracy: 1.0000 - val_loss: 3.8097 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1809e-06 - accuracy: 1.0000 - val_loss: 3.8325 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.6565e-06 - accuracy: 1.0000 - val_loss: 3.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.0978e-06 - accuracy: 1.0000 - val_loss: 3.8745 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.2759e-07 - accuracy: 1.0000 - val_loss: 3.8937 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9467e-06 - accuracy: 1.0000 - val_loss: 3.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1511e-06 - accuracy: 1.0000 - val_loss: 3.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8179e-06 - accuracy: 1.0000 - val_loss: 3.9432 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.1898e-07 - accuracy: 1.0000 - val_loss: 3.9572 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8477e-06 - accuracy: 1.0000 - val_loss: 3.9702 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.3213e-07 - accuracy: 1.0000 - val_loss: 3.9820 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.8312e-07 - accuracy: 1.0000 - val_loss: 3.9929 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0394e-06 - accuracy: 1.0000 - val_loss: 4.0029 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0073 - accuracy: 0.8000\n",
      "Fold 1 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 2.0944 - accuracy: 0.1250 - val_loss: 1.7236 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3288 - accuracy: 0.9062 - val_loss: 1.5827 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 1.5190 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4834 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4769 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.7103e-04 - accuracy: 1.0000 - val_loss: 1.4840 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.8684e-04 - accuracy: 1.0000 - val_loss: 1.5010 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3972e-04 - accuracy: 1.0000 - val_loss: 1.5249 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8057e-04 - accuracy: 1.0000 - val_loss: 1.5547 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2851e-05 - accuracy: 1.0000 - val_loss: 1.5893 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.1616e-05 - accuracy: 1.0000 - val_loss: 1.6250 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.7949e-05 - accuracy: 1.0000 - val_loss: 1.6632 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8572e-05 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1544e-06 - accuracy: 1.0000 - val_loss: 1.7414 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.4748e-06 - accuracy: 1.0000 - val_loss: 1.7789 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5336e-06 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7502e-04 - accuracy: 1.0000 - val_loss: 1.8508 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9962e-05 - accuracy: 1.0000 - val_loss: 1.8850 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5423e-06 - accuracy: 1.0000 - val_loss: 1.9175 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.6230e-06 - accuracy: 1.0000 - val_loss: 1.9484 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.0030e-06 - accuracy: 1.0000 - val_loss: 1.9778 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7173e-06 - accuracy: 1.0000 - val_loss: 2.0051 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.8722e-06 - accuracy: 1.0000 - val_loss: 2.0303 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.9951e-06 - accuracy: 1.0000 - val_loss: 2.0540 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0505e-06 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 8.5309e-07 - accuracy: 1.0000 - val_loss: 2.0971 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.9802e-07 - accuracy: 1.0000 - val_loss: 2.1165 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.3958e-07 - accuracy: 1.0000 - val_loss: 2.1344 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.6450e-07 - accuracy: 1.0000 - val_loss: 2.1510 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.4878e-07 - accuracy: 1.0000 - val_loss: 2.1670 - val_accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6691 - accuracy: 0.7000\n",
      "Fold 2 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 1.9648 - accuracy: 0.2812 - val_loss: 1.4322 - val_accuracy: 0.3750\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3351 - accuracy: 0.9688 - val_loss: 1.0412 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.4983e-04 - accuracy: 1.0000 - val_loss: 0.1723 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2883e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.5311e-05 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2822e-04 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4548e-05 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2300e-05 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0666e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0091e-05 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4139e-05 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6454e-05 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5555e-06 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9822e-06 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6279e-06 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2910e-06 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1027e-06 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5013e-06 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1941e-06 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2222e-06 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.3958e-07 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.2154e-08 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4379e-06 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3448e-06 - accuracy: 1.0000 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.9604e-07 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.9744e-07 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Fold 3 Test Accuracy: 1.0\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 2.2616 - accuracy: 0.0625 - val_loss: 1.6484 - val_accuracy: 0.1250\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 1.6133 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 1.6048 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.6202 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6453 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6780 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.8093e-04 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3517e-04 - accuracy: 1.0000 - val_loss: 1.7733 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7917e-05 - accuracy: 1.0000 - val_loss: 1.8272 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4018e-05 - accuracy: 1.0000 - val_loss: 1.8833 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.4116e-06 - accuracy: 1.0000 - val_loss: 1.9398 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0177e-05 - accuracy: 1.0000 - val_loss: 1.9939 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1010e-05 - accuracy: 1.0000 - val_loss: 2.0456 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.5431e-06 - accuracy: 1.0000 - val_loss: 2.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.7666e-06 - accuracy: 1.0000 - val_loss: 2.1434 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.3074e-07 - accuracy: 1.0000 - val_loss: 2.1884 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.6361e-06 - accuracy: 1.0000 - val_loss: 2.2313 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7471e-06 - accuracy: 1.0000 - val_loss: 2.2712 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3320e-06 - accuracy: 1.0000 - val_loss: 2.3079 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.5491e-06 - accuracy: 1.0000 - val_loss: 2.3421 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.4191e-07 - accuracy: 1.0000 - val_loss: 2.3743 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2410e-07 - accuracy: 1.0000 - val_loss: 2.4044 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6019e-07 - accuracy: 1.0000 - val_loss: 2.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.2526e-07 - accuracy: 1.0000 - val_loss: 2.4582 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5522e-06 - accuracy: 1.0000 - val_loss: 2.4822 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.6077e-07 - accuracy: 1.0000 - val_loss: 2.5044 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1723e-07 - accuracy: 1.0000 - val_loss: 2.5249 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.9174e-07 - accuracy: 1.0000 - val_loss: 2.5438 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.2957e-07 - accuracy: 1.0000 - val_loss: 2.5613 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9860e-07 - accuracy: 1.0000 - val_loss: 2.5775 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4310 - accuracy: 0.8000\n",
      "Fold 4 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 1.6925 - accuracy: 0.3438 - val_loss: 1.5014 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2545 - accuracy: 1.0000 - val_loss: 1.4880 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 1.5165 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.5627 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6169 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.3641e-04 - accuracy: 1.0000 - val_loss: 1.6787 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7759e-04 - accuracy: 1.0000 - val_loss: 1.7377 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7962e-04 - accuracy: 1.0000 - val_loss: 1.7965 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7385e-05 - accuracy: 1.0000 - val_loss: 1.8512 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.2687e-05 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2088e-05 - accuracy: 1.0000 - val_loss: 1.9525 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.7564e-06 - accuracy: 1.0000 - val_loss: 2.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.9004e-06 - accuracy: 1.0000 - val_loss: 2.0506 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4758e-05 - accuracy: 1.0000 - val_loss: 2.0982 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7844e-06 - accuracy: 1.0000 - val_loss: 2.1439 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1213e-06 - accuracy: 1.0000 - val_loss: 2.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.8801e-07 - accuracy: 1.0000 - val_loss: 2.2251 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7316e-05 - accuracy: 1.0000 - val_loss: 2.2621 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.4250e-07 - accuracy: 1.0000 - val_loss: 2.2959 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2796e-05 - accuracy: 1.0000 - val_loss: 2.3272 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6093e-06 - accuracy: 1.0000 - val_loss: 2.3560 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.3271e-07 - accuracy: 1.0000 - val_loss: 2.3826 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8918e-07 - accuracy: 1.0000 - val_loss: 2.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.2841e-07 - accuracy: 1.0000 - val_loss: 2.4309 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.2526e-07 - accuracy: 1.0000 - val_loss: 2.4524 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1176e-06 - accuracy: 1.0000 - val_loss: 2.4723 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.8976e-07 - accuracy: 1.0000 - val_loss: 2.4910 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2351e-06 - accuracy: 1.0000 - val_loss: 2.5082 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0117e-07 - accuracy: 1.0000 - val_loss: 2.5241 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9597e-06 - accuracy: 1.0000 - val_loss: 2.5387 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3739 - accuracy: 0.8000\n",
      "Fold 5 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.8200000047683715\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_1 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_0_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 1536)]               0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_20 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_21 (Gaussia  (None, 1536)                 0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_50 (Dense)            (None, 64)                   128       ['gaussian_noise_20[0][0]']   \n",
      "                                                                                                  \n",
      " dense_52 (Dense)            (None, 256)                  393472    ['gaussian_noise_21[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 64)                   0         ['dense_50[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 256)                  0         ['dense_52[0][0]']            \n",
      "                                                                                                  \n",
      " dense_51 (Dense)            (None, 32)                   2080      ['dropout_20[0][0]']          \n",
      "                                                                                                  \n",
      " dense_53 (Dense)            (None, 128)                  32896     ['dropout_21[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 160)                  0         ['dense_51[0][0]',            \n",
      " e)                                                                  'dense_53[0][0]']            \n",
      "                                                                                                  \n",
      " dense_54 (Dense)            (None, 5)                    805       ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 429381 (1.64 MB)\n",
      "Trainable params: 429381 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 1.6739 - accuracy: 0.1250 - val_loss: 1.5313 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6381 - accuracy: 0.2188 - val_loss: 1.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5829 - accuracy: 0.3438 - val_loss: 1.7693 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5841 - accuracy: 0.2500 - val_loss: 1.9003 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4941 - accuracy: 0.4062 - val_loss: 2.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5198 - accuracy: 0.3438 - val_loss: 2.1740 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4734 - accuracy: 0.2812 - val_loss: 2.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.4806 - accuracy: 0.2500 - val_loss: 2.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 1.4266 - accuracy: 0.3750 - val_loss: 2.6458 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4285 - accuracy: 0.3438 - val_loss: 2.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4521 - accuracy: 0.2812 - val_loss: 2.9680 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4394 - accuracy: 0.2500 - val_loss: 3.1254 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4500 - accuracy: 0.3125 - val_loss: 3.2750 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4362 - accuracy: 0.3438 - val_loss: 3.4158 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4185 - accuracy: 0.3125 - val_loss: 3.5492 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3402 - accuracy: 0.3750 - val_loss: 3.6756 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3475 - accuracy: 0.4688 - val_loss: 3.7977 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4196 - accuracy: 0.2500 - val_loss: 3.9120 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4264 - accuracy: 0.2500 - val_loss: 4.0208 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4192 - accuracy: 0.2188 - val_loss: 4.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3878 - accuracy: 0.3750 - val_loss: 4.2223 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3537 - accuracy: 0.3438 - val_loss: 4.3166 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3311 - accuracy: 0.4062 - val_loss: 4.4081 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3460 - accuracy: 0.4062 - val_loss: 4.4964 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4001 - accuracy: 0.3125 - val_loss: 4.5822 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3241 - accuracy: 0.4062 - val_loss: 4.6621 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3966 - accuracy: 0.2812 - val_loss: 4.7377 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3047 - accuracy: 0.4062 - val_loss: 4.8123 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3503 - accuracy: 0.3125 - val_loss: 4.8838 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4004 - accuracy: 0.1562 - val_loss: 4.9516 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1041 - accuracy: 0.0000e+00\n",
      "Fold 1 Test Accuracy: 0.0\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.6536 - accuracy: 0.0938 - val_loss: 1.6191 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6879 - accuracy: 0.0000e+00 - val_loss: 1.6688 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6117 - accuracy: 0.1875 - val_loss: 1.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5590 - accuracy: 0.2500 - val_loss: 1.7789 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5310 - accuracy: 0.1875 - val_loss: 1.8424 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5242 - accuracy: 0.2812 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4973 - accuracy: 0.2188 - val_loss: 1.9928 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4571 - accuracy: 0.4375 - val_loss: 2.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4370 - accuracy: 0.3125 - val_loss: 2.1745 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4670 - accuracy: 0.3438 - val_loss: 2.2743 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4417 - accuracy: 0.3125 - val_loss: 2.3801 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4342 - accuracy: 0.2500 - val_loss: 2.4887 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3930 - accuracy: 0.2812 - val_loss: 2.5999 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3850 - accuracy: 0.2812 - val_loss: 2.7149 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3894 - accuracy: 0.3750 - val_loss: 2.8308 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3804 - accuracy: 0.3125 - val_loss: 2.9472 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3422 - accuracy: 0.4375 - val_loss: 3.0611 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3501 - accuracy: 0.3438 - val_loss: 3.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3255 - accuracy: 0.4375 - val_loss: 3.2738 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3323 - accuracy: 0.4062 - val_loss: 3.3723 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3028 - accuracy: 0.4062 - val_loss: 3.4687 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3156 - accuracy: 0.4062 - val_loss: 3.5622 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3122 - accuracy: 0.4375 - val_loss: 3.6530 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3602 - accuracy: 0.3438 - val_loss: 3.7401 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3333 - accuracy: 0.3438 - val_loss: 3.8224 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3096 - accuracy: 0.3750 - val_loss: 3.9012 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3416 - accuracy: 0.3750 - val_loss: 3.9784 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2822 - accuracy: 0.4375 - val_loss: 4.0542 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3293 - accuracy: 0.3750 - val_loss: 4.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3178 - accuracy: 0.5000 - val_loss: 4.1992 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3932 - accuracy: 0.2000\n",
      "Fold 2 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 1.6060 - accuracy: 0.1562 - val_loss: 1.7874 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5741 - accuracy: 0.3125 - val_loss: 1.8209 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5370 - accuracy: 0.3750 - val_loss: 1.8655 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5317 - accuracy: 0.2500 - val_loss: 1.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5607 - accuracy: 0.2188 - val_loss: 1.9743 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5244 - accuracy: 0.3125 - val_loss: 2.0346 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5471 - accuracy: 0.1875 - val_loss: 2.0942 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4662 - accuracy: 0.2812 - val_loss: 2.1531 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5302 - accuracy: 0.2188 - val_loss: 2.2134 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4850 - accuracy: 0.3125 - val_loss: 2.2743 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4886 - accuracy: 0.3750 - val_loss: 2.3388 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4449 - accuracy: 0.2812 - val_loss: 2.4034 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4459 - accuracy: 0.4062 - val_loss: 2.4696 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4568 - accuracy: 0.3750 - val_loss: 2.5352 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4818 - accuracy: 0.3438 - val_loss: 2.6013 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4944 - accuracy: 0.4375 - val_loss: 2.6628 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4075 - accuracy: 0.3125 - val_loss: 2.7214 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4287 - accuracy: 0.3750 - val_loss: 2.7783 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4520 - accuracy: 0.3438 - val_loss: 2.8327 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4357 - accuracy: 0.3125 - val_loss: 2.8871 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.4498 - accuracy: 0.3750 - val_loss: 2.9359 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3710 - accuracy: 0.4688 - val_loss: 2.9813 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4080 - accuracy: 0.4062 - val_loss: 3.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4131 - accuracy: 0.4375 - val_loss: 3.0576 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3767 - accuracy: 0.3750 - val_loss: 3.0920 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3993 - accuracy: 0.4062 - val_loss: 3.1243 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4078 - accuracy: 0.4062 - val_loss: 3.1557 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3851 - accuracy: 0.4375 - val_loss: 3.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3985 - accuracy: 0.3438 - val_loss: 3.2104 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4130 - accuracy: 0.3125 - val_loss: 3.2307 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5648 - accuracy: 0.3000\n",
      "Fold 3 Test Accuracy: 0.30000001192092896\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 1.5617 - accuracy: 0.2188 - val_loss: 1.9929 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5441 - accuracy: 0.4062 - val_loss: 2.0661 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5509 - accuracy: 0.2812 - val_loss: 2.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5246 - accuracy: 0.1875 - val_loss: 2.2136 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5065 - accuracy: 0.2500 - val_loss: 2.2901 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4719 - accuracy: 0.3125 - val_loss: 2.3717 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4935 - accuracy: 0.2188 - val_loss: 2.4587 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4433 - accuracy: 0.3438 - val_loss: 2.5519 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4186 - accuracy: 0.3438 - val_loss: 2.6468 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4339 - accuracy: 0.3438 - val_loss: 2.7465 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3949 - accuracy: 0.3125 - val_loss: 2.8519 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3850 - accuracy: 0.3438 - val_loss: 2.9583 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4082 - accuracy: 0.4062 - val_loss: 3.0635 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4426 - accuracy: 0.0938 - val_loss: 3.1678 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4012 - accuracy: 0.3750 - val_loss: 3.2698 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3551 - accuracy: 0.5625 - val_loss: 3.3732 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4234 - accuracy: 0.1562 - val_loss: 3.4748 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3323 - accuracy: 0.3750 - val_loss: 3.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3353 - accuracy: 0.4688 - val_loss: 3.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3781 - accuracy: 0.2812 - val_loss: 3.7759 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3954 - accuracy: 0.2500 - val_loss: 3.8707 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3288 - accuracy: 0.3438 - val_loss: 3.9621 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3453 - accuracy: 0.2188 - val_loss: 4.0501 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3162 - accuracy: 0.4375 - val_loss: 4.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3645 - accuracy: 0.2812 - val_loss: 4.2203 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3621 - accuracy: 0.4062 - val_loss: 4.3000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3266 - accuracy: 0.3438 - val_loss: 4.3778 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2571 - accuracy: 0.5000 - val_loss: 4.4542 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3389 - accuracy: 0.3438 - val_loss: 4.5268 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3277 - accuracy: 0.2500 - val_loss: 4.5983 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9205 - accuracy: 0.2000\n",
      "Fold 4 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 1.7366 - accuracy: 0.0938 - val_loss: 1.5432 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6561 - accuracy: 0.2812 - val_loss: 1.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6310 - accuracy: 0.3125 - val_loss: 1.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5849 - accuracy: 0.3750 - val_loss: 1.7483 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5786 - accuracy: 0.3125 - val_loss: 1.8204 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5606 - accuracy: 0.2812 - val_loss: 1.9002 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5021 - accuracy: 0.4375 - val_loss: 1.9846 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4922 - accuracy: 0.2188 - val_loss: 2.0760 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4666 - accuracy: 0.2188 - val_loss: 2.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4884 - accuracy: 0.2812 - val_loss: 2.2671 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4862 - accuracy: 0.3125 - val_loss: 2.3680 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4583 - accuracy: 0.2812 - val_loss: 2.4721 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4550 - accuracy: 0.1875 - val_loss: 2.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4017 - accuracy: 0.3438 - val_loss: 2.6869 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4045 - accuracy: 0.2812 - val_loss: 2.7972 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4285 - accuracy: 0.2812 - val_loss: 2.9060 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4016 - accuracy: 0.2500 - val_loss: 3.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4441 - accuracy: 0.2500 - val_loss: 3.1220 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3934 - accuracy: 0.3438 - val_loss: 3.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3632 - accuracy: 0.4062 - val_loss: 3.3358 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3599 - accuracy: 0.3750 - val_loss: 3.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.3799 - accuracy: 0.1875 - val_loss: 3.5473 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3669 - accuracy: 0.2500 - val_loss: 3.6509 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3507 - accuracy: 0.3750 - val_loss: 3.7509 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3318 - accuracy: 0.3750 - val_loss: 3.8505 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3251 - accuracy: 0.3750 - val_loss: 3.9502 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3418 - accuracy: 0.3438 - val_loss: 4.0481 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3336 - accuracy: 0.4062 - val_loss: 4.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3701 - accuracy: 0.3125 - val_loss: 4.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3043 - accuracy: 0.3750 - val_loss: 4.3192 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9597 - accuracy: 0.2000\n",
      "Fold 5 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.18000000417232515\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_2 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0              = encoder\n",
    "    \n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_30 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_31 (Gaussia  (None, 3)                    0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_75 (Dense)            (None, 64)                   128       ['gaussian_noise_30[0][0]']   \n",
      "                                                                                                  \n",
      " dense_77 (Dense)            (None, 256)                  1024      ['gaussian_noise_31[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 64)                   0         ['dense_75[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)        (None, 256)                  0         ['dense_77[0][0]']            \n",
      "                                                                                                  \n",
      " dense_76 (Dense)            (None, 32)                   2080      ['dropout_30[0][0]']          \n",
      "                                                                                                  \n",
      " dense_78 (Dense)            (None, 128)                  32896     ['dropout_31[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenat  (None, 160)                  0         ['dense_76[0][0]',            \n",
      " e)                                                                  'dense_78[0][0]']            \n",
      "                                                                                                  \n",
      " dense_79 (Dense)            (None, 5)                    805       ['concatenate_15[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36933 (144.27 KB)\n",
      "Trainable params: 36933 (144.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 1.7295 - accuracy: 0.0000e+00 - val_loss: 1.4445 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6859 - accuracy: 0.0000e+00 - val_loss: 1.4802 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6521 - accuracy: 0.1250 - val_loss: 1.5192 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6302 - accuracy: 0.1250 - val_loss: 1.5594 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6227 - accuracy: 0.2188 - val_loss: 1.6008 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6086 - accuracy: 0.2500 - val_loss: 1.6432 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5814 - accuracy: 0.2500 - val_loss: 1.6871 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5088 - accuracy: 0.4688 - val_loss: 1.7318 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5402 - accuracy: 0.3750 - val_loss: 1.7773 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5263 - accuracy: 0.3438 - val_loss: 1.8234 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5453 - accuracy: 0.2500 - val_loss: 1.8693 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5030 - accuracy: 0.4062 - val_loss: 1.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4630 - accuracy: 0.3438 - val_loss: 1.9600 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4689 - accuracy: 0.3750 - val_loss: 2.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4419 - accuracy: 0.3125 - val_loss: 2.0556 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4581 - accuracy: 0.3125 - val_loss: 2.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4314 - accuracy: 0.3750 - val_loss: 2.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4316 - accuracy: 0.3125 - val_loss: 2.2075 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4001 - accuracy: 0.4062 - val_loss: 2.2609 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4419 - accuracy: 0.2812 - val_loss: 2.3164 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4233 - accuracy: 0.3438 - val_loss: 2.3730 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3685 - accuracy: 0.3438 - val_loss: 2.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3733 - accuracy: 0.3438 - val_loss: 2.4900 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3704 - accuracy: 0.3750 - val_loss: 2.5516 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3731 - accuracy: 0.3750 - val_loss: 2.6158 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3437 - accuracy: 0.4062 - val_loss: 2.6827 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3421 - accuracy: 0.3750 - val_loss: 2.7508 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3062 - accuracy: 0.4688 - val_loss: 2.8202 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2982 - accuracy: 0.3750 - val_loss: 2.8909 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3192 - accuracy: 0.4375 - val_loss: 2.9630 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6898 - accuracy: 0.0000e+00\n",
      "Fold 1 Test Accuracy: 0.0\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 1.6117 - accuracy: 0.1562 - val_loss: 1.6541 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6281 - accuracy: 0.1875 - val_loss: 1.6751 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6143 - accuracy: 0.1562 - val_loss: 1.6962 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5743 - accuracy: 0.2500 - val_loss: 1.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5652 - accuracy: 0.1875 - val_loss: 1.7400 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5543 - accuracy: 0.1562 - val_loss: 1.7631 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5385 - accuracy: 0.2500 - val_loss: 1.7867 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5762 - accuracy: 0.2500 - val_loss: 1.8107 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5209 - accuracy: 0.2500 - val_loss: 1.8356 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5117 - accuracy: 0.3125 - val_loss: 1.8617 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4903 - accuracy: 0.3438 - val_loss: 1.8885 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4927 - accuracy: 0.3438 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4604 - accuracy: 0.3438 - val_loss: 1.9466 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5122 - accuracy: 0.3125 - val_loss: 1.9777 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4511 - accuracy: 0.3750 - val_loss: 2.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4689 - accuracy: 0.3125 - val_loss: 2.0430 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4376 - accuracy: 0.4062 - val_loss: 2.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4634 - accuracy: 0.3750 - val_loss: 2.1128 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4246 - accuracy: 0.4062 - val_loss: 2.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4003 - accuracy: 0.3750 - val_loss: 2.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3829 - accuracy: 0.4062 - val_loss: 2.2270 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3942 - accuracy: 0.4688 - val_loss: 2.2681 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3892 - accuracy: 0.3438 - val_loss: 2.3107 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3648 - accuracy: 0.4062 - val_loss: 2.3544 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3343 - accuracy: 0.4688 - val_loss: 2.3991 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3225 - accuracy: 0.4688 - val_loss: 2.4452 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3309 - accuracy: 0.5312 - val_loss: 2.4928 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2986 - accuracy: 0.4375 - val_loss: 2.5415 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3482 - accuracy: 0.4062 - val_loss: 2.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3208 - accuracy: 0.4375 - val_loss: 2.6429 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.8979 - accuracy: 0.2000\n",
      "Fold 2 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 1.6249 - accuracy: 0.2500 - val_loss: 1.6791 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6205 - accuracy: 0.3750 - val_loss: 1.7053 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6026 - accuracy: 0.3125 - val_loss: 1.7328 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6439 - accuracy: 0.2812 - val_loss: 1.7607 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5947 - accuracy: 0.3750 - val_loss: 1.7901 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5743 - accuracy: 0.3750 - val_loss: 1.8204 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5638 - accuracy: 0.2500 - val_loss: 1.8513 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5795 - accuracy: 0.1875 - val_loss: 1.8826 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5261 - accuracy: 0.4375 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5482 - accuracy: 0.3438 - val_loss: 1.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5084 - accuracy: 0.3438 - val_loss: 1.9813 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5482 - accuracy: 0.4062 - val_loss: 2.0181 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5016 - accuracy: 0.3750 - val_loss: 2.0565 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5234 - accuracy: 0.4062 - val_loss: 2.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4942 - accuracy: 0.4375 - val_loss: 2.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4850 - accuracy: 0.4062 - val_loss: 2.1802 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4626 - accuracy: 0.4062 - val_loss: 2.2258 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4815 - accuracy: 0.3125 - val_loss: 2.2724 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4789 - accuracy: 0.3125 - val_loss: 2.3191 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4266 - accuracy: 0.5000 - val_loss: 2.3666 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4015 - accuracy: 0.5312 - val_loss: 2.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4428 - accuracy: 0.4688 - val_loss: 2.4658 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4235 - accuracy: 0.2812 - val_loss: 2.5171 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4200 - accuracy: 0.3438 - val_loss: 2.5693 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4111 - accuracy: 0.4688 - val_loss: 2.6221 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4115 - accuracy: 0.3125 - val_loss: 2.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4026 - accuracy: 0.3438 - val_loss: 2.7308 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3320 - accuracy: 0.5625 - val_loss: 2.7865 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4114 - accuracy: 0.3438 - val_loss: 2.8418 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3708 - accuracy: 0.4062 - val_loss: 2.8980 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5120 - accuracy: 0.4000\n",
      "Fold 3 Test Accuracy: 0.4000000059604645\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 1.5958 - accuracy: 0.3125 - val_loss: 1.6401 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6306 - accuracy: 0.3125 - val_loss: 1.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6357 - accuracy: 0.1562 - val_loss: 1.7042 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6144 - accuracy: 0.1562 - val_loss: 1.7384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5914 - accuracy: 0.2812 - val_loss: 1.7739 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5841 - accuracy: 0.1875 - val_loss: 1.8103 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5512 - accuracy: 0.2500 - val_loss: 1.8473 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5536 - accuracy: 0.2812 - val_loss: 1.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5436 - accuracy: 0.1875 - val_loss: 1.9233 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5103 - accuracy: 0.4062 - val_loss: 1.9629 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5532 - accuracy: 0.1875 - val_loss: 2.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5202 - accuracy: 0.2812 - val_loss: 2.0456 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4759 - accuracy: 0.4062 - val_loss: 2.0881 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4797 - accuracy: 0.3438 - val_loss: 2.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5236 - accuracy: 0.3438 - val_loss: 2.1765 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4628 - accuracy: 0.3750 - val_loss: 2.2226 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4679 - accuracy: 0.3750 - val_loss: 2.2696 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4862 - accuracy: 0.3438 - val_loss: 2.3180 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4342 - accuracy: 0.4062 - val_loss: 2.3676 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4223 - accuracy: 0.3438 - val_loss: 2.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4186 - accuracy: 0.5938 - val_loss: 2.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4253 - accuracy: 0.2812 - val_loss: 2.5194 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4250 - accuracy: 0.4062 - val_loss: 2.5704 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4282 - accuracy: 0.5000 - val_loss: 2.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3783 - accuracy: 0.5000 - val_loss: 2.6736 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4235 - accuracy: 0.3438 - val_loss: 2.7267 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3914 - accuracy: 0.3125 - val_loss: 2.7815 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3880 - accuracy: 0.4375 - val_loss: 2.8375 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 1.3771 - accuracy: 0.4375 - val_loss: 2.8948 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3759 - accuracy: 0.3750 - val_loss: 2.9531 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6283 - accuracy: 0.3000\n",
      "Fold 4 Test Accuracy: 0.30000001192092896\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 1.6702 - accuracy: 0.0938 - val_loss: 1.4892 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6774 - accuracy: 0.1562 - val_loss: 1.5122 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6662 - accuracy: 0.1250 - val_loss: 1.5367 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6464 - accuracy: 0.1250 - val_loss: 1.5626 - val_accuracy: 0.6250\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5926 - accuracy: 0.2812 - val_loss: 1.5899 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6155 - accuracy: 0.2188 - val_loss: 1.6189 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6015 - accuracy: 0.1875 - val_loss: 1.6485 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5868 - accuracy: 0.3438 - val_loss: 1.6796 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5580 - accuracy: 0.2812 - val_loss: 1.7123 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5441 - accuracy: 0.2500 - val_loss: 1.7468 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5458 - accuracy: 0.3750 - val_loss: 1.7839 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5056 - accuracy: 0.3750 - val_loss: 1.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5059 - accuracy: 0.3750 - val_loss: 1.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5101 - accuracy: 0.3438 - val_loss: 1.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4842 - accuracy: 0.3750 - val_loss: 1.9597 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4585 - accuracy: 0.3750 - val_loss: 2.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4838 - accuracy: 0.2812 - val_loss: 2.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4492 - accuracy: 0.4062 - val_loss: 2.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.4536 - accuracy: 0.2500 - val_loss: 2.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3988 - accuracy: 0.3438 - val_loss: 2.2273 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3889 - accuracy: 0.4375 - val_loss: 2.2880 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4140 - accuracy: 0.3125 - val_loss: 2.3514 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3803 - accuracy: 0.3750 - val_loss: 2.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4118 - accuracy: 0.2812 - val_loss: 2.4845 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3742 - accuracy: 0.3750 - val_loss: 2.5548 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3701 - accuracy: 0.4375 - val_loss: 2.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3501 - accuracy: 0.2812 - val_loss: 2.7045 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3366 - accuracy: 0.4375 - val_loss: 2.7828 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3271 - accuracy: 0.3750 - val_loss: 2.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3468 - accuracy: 0.4375 - val_loss: 2.9462 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6858 - accuracy: 0.2000\n",
      "Fold 5 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.2200000047683716\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "operationnn.ipynb has finished\n",
      "Out_1_Nor_1_Aut_1_DR_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_3 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_1\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_1 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    print(f\"{subject_label}\")\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_1                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_1          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_1  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1- `Operation: SVM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [6.496516227722168, [-0.023179981857538223, -0...\n",
       "1     [7.216111660003662, [-0.02709014154970646, 0.0...\n",
       "2     [4.820352077484131, [-0.027471184730529785, 0....\n",
       "3     [3.285065174102783, [-0.017391610890626907, 0....\n",
       "4     [2.013909101486206, [-0.02618575282394886, -0....\n",
       "5     [2.750776767730713, [-0.02786310203373432, 0.0...\n",
       "6     [1.8918119668960571, [-0.016522565856575966, 0...\n",
       "7     [5.782482147216797, [-0.020461147651076317, 0....\n",
       "8     [5.027541160583496, [-0.018992045894265175, 0....\n",
       "9     [1.8539708852767944, [-0.01821018196642399, -0...\n",
       "10    [3.9321811199188232, [-0.012247681617736816, 0...\n",
       "11    [3.068100929260254, [-0.02337650954723358, -0....\n",
       "12    [2.01381778717041, [-0.030698079615831375, -0....\n",
       "13    [1.693952560424805, [-0.029411470517516136, -0...\n",
       "14    [1.7035424709320068, [-0.00034768227487802505,...\n",
       "15    [2.4735491275787354, [-0.017089633271098137, -...\n",
       "16    [1.9176887273788452, [-0.008595016784965992, -...\n",
       "17    [2.430889844894409, [-0.008053204976022243, -0...\n",
       "18    [1.6459747552871704, [-0.018414746969938278, -...\n",
       "19    [1.318286657333374, [-0.02043631114065647, 0.0...\n",
       "20    [3.4722657203674316, [-0.03089701570570469, -0...\n",
       "21    [4.7200236320495605, [-0.03779100999236107, 0....\n",
       "22    [4.3272175788879395, [-0.036703381687402725, 0...\n",
       "23    [4.4580535888671875, [-0.032608307898044586, 0...\n",
       "24    [4.602021217346191, [-0.03874512389302254, 0.0...\n",
       "25    [4.8144941329956055, [-0.03462428227066994, 0....\n",
       "26    [4.9346489906311035, [-0.02666221372783184, 0....\n",
       "27    [3.1254734992980957, [-0.022845221683382988, -...\n",
       "28    [4.516481399536133, [-0.03620649501681328, 0.0...\n",
       "29    [4.090731620788574, [-0.025632625445723534, 0....\n",
       "30    [2.4618544578552246, [-0.01764203980565071, 0....\n",
       "31    [5.273684501647949, [-0.02164112590253353, -0....\n",
       "32    [4.290997505187988, [-0.01618216373026371, 0.0...\n",
       "33    [1.679938554763794, [-0.0021745830308645964, 0...\n",
       "34    [2.607694149017334, [-0.010331124998629093, 0....\n",
       "35    [1.9697431325912476, [-0.009212559089064598, -...\n",
       "36    [3.9581973552703857, [-0.017974235117435455, 0...\n",
       "37    [3.8590359687805176, [-0.031197870150208473, -...\n",
       "38    [2.568978786468506, [0.0010776142589747906, 0....\n",
       "39    [1.8100850582122805, [-0.009785622358322144, -...\n",
       "40    [2.185464382171631, [-0.021880967542529106, -0...\n",
       "41    [2.8507373332977295, [0.006584431044757366, -0...\n",
       "42    [2.999174118041992, [-0.00319025875069201, -0....\n",
       "43    [3.1167471408843994, [0.005019814241677523, 0....\n",
       "44    [2.5410046577453613, [-0.01442825049161911, -0...\n",
       "45    [2.421492576599121, [-0.014833754859864712, -0...\n",
       "46    [3.1219165325164795, [0.001740546664223075, 0....\n",
       "47    [3.2749857902526855, [-0.016992609947919846, -...\n",
       "48    [3.203280210494995, [-0.0013845551293343306, -...\n",
       "49    [2.97369647026062, [-0.008292808197438717, -0....\n",
       "Name: Expression_Embeddings, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subject_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [6.496516227722168, [-0.023179981857538223, -0...\n",
       "1     [7.216111660003662, [-0.02709014154970646, 0.0...\n",
       "2     [4.820352077484131, [-0.027471184730529785, 0....\n",
       "3     [3.285065174102783, [-0.017391610890626907, 0....\n",
       "4     [2.013909101486206, [-0.02618575282394886, -0....\n",
       "5     [2.750776767730713, [-0.02786310203373432, 0.0...\n",
       "6     [1.8918119668960571, [-0.016522565856575966, 0...\n",
       "7     [5.782482147216797, [-0.020461147651076317, 0....\n",
       "8     [5.027541160583496, [-0.018992045894265175, 0....\n",
       "9     [1.8539708852767944, [-0.01821018196642399, -0...\n",
       "10    [3.9321811199188232, [-0.012247681617736816, 0...\n",
       "11    [3.068100929260254, [-0.02337650954723358, -0....\n",
       "12    [2.01381778717041, [-0.030698079615831375, -0....\n",
       "13    [1.693952560424805, [-0.029411470517516136, -0...\n",
       "14    [1.7035424709320068, [-0.00034768227487802505,...\n",
       "15    [2.4735491275787354, [-0.017089633271098137, -...\n",
       "16    [1.9176887273788452, [-0.008595016784965992, -...\n",
       "17    [2.430889844894409, [-0.008053204976022243, -0...\n",
       "18    [1.6459747552871704, [-0.018414746969938278, -...\n",
       "19    [1.318286657333374, [-0.02043631114065647, 0.0...\n",
       "20    [3.4722657203674316, [-0.03089701570570469, -0...\n",
       "21    [4.7200236320495605, [-0.03779100999236107, 0....\n",
       "22    [4.3272175788879395, [-0.036703381687402725, 0...\n",
       "23    [4.4580535888671875, [-0.032608307898044586, 0...\n",
       "24    [4.602021217346191, [-0.03874512389302254, 0.0...\n",
       "25    [4.8144941329956055, [-0.03462428227066994, 0....\n",
       "26    [4.9346489906311035, [-0.02666221372783184, 0....\n",
       "27    [3.1254734992980957, [-0.022845221683382988, -...\n",
       "28    [4.516481399536133, [-0.03620649501681328, 0.0...\n",
       "29    [4.090731620788574, [-0.025632625445723534, 0....\n",
       "30    [2.4618544578552246, [-0.01764203980565071, 0....\n",
       "31    [5.273684501647949, [-0.02164112590253353, -0....\n",
       "32    [4.290997505187988, [-0.01618216373026371, 0.0...\n",
       "33    [1.679938554763794, [-0.0021745830308645964, 0...\n",
       "34    [2.607694149017334, [-0.010331124998629093, 0....\n",
       "35    [1.9697431325912476, [-0.009212559089064598, -...\n",
       "36    [3.9581973552703857, [-0.017974235117435455, 0...\n",
       "37    [3.8590359687805176, [-0.031197870150208473, -...\n",
       "38    [2.568978786468506, [0.0010776142589747906, 0....\n",
       "39    [1.8100850582122805, [-0.009785622358322144, -...\n",
       "40    [2.185464382171631, [-0.021880967542529106, -0...\n",
       "41    [2.8507373332977295, [0.006584431044757366, -0...\n",
       "42    [2.999174118041992, [-0.00319025875069201, -0....\n",
       "43    [3.1167471408843994, [0.005019814241677523, 0....\n",
       "44    [2.5410046577453613, [-0.01442825049161911, -0...\n",
       "45    [2.421492576599121, [-0.014833754859864712, -0...\n",
       "46    [3.1219165325164795, [0.001740546664223075, 0....\n",
       "47    [3.2749857902526855, [-0.016992609947919846, -...\n",
       "48    [3.203280210494995, [-0.0013845551293343306, -...\n",
       "49    [2.97369647026062, [-0.008292808197438717, -0....\n",
       "Name: Expression_Embeddings, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subject_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_0 == 1: \n",
    "    SVM_Dict_Out_1_Nor_0_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                 y_Cell_Type              = Cell_Type, \n",
    "                                                 subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\", \n",
    "                                                 subject_outlier          = subject_outlier, \n",
    "                                                 subject_normalization    = subject_normalization, \n",
    "                                                 subject_autoencoder      = subject_autoencoder, \n",
    "                                                 subject_dimension        = subject_dimension,\n",
    "                                                 data_source = \"list\" )\n",
    "    Model_SVM_Out_1_Nor_0_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_0_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_0_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_0_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_1 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_2 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_3 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_1 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_1                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_1          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_1  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_1           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2- `Operation: SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_0 == 1: \n",
    "    SGD_Dict_Out_1_Nor_0_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                    y_Cell_Type           = Cell_Type,\n",
    "                                                    subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                    subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )  \n",
    "    Model_SGD_Out_1_Nor_0_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_0_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_0_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_0_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_1 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )  \n",
    "    Model_SGD_Out_1_Nor_1_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_1 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension,\n",
    "                                                        data_source = \"list\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_1                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_1          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_1  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_1           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3- `Operation: Random Forest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_0 == 1: \n",
    "    RF_Dict_Out_1_Nor_0_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )    \n",
    "    Model_RF_Out_1_Nor_0_Aut_0_DR_0                = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_0_Aut_0_DR_0          = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_0_Aut_0_DR_0  = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_0_Aut_0_DR_0           = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_1 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension, \n",
    "                                                data_source = \"list\" )  \n",
    "    Model_RF_Out_1_Nor_1_Aut_0_DR_0                = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_0_DR_0          = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_0_DR_0  = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_0_DR_0           = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_0                = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_0          = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_0  = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_0           = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_1 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_1                = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_1          = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_1  = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_1           = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4- `Operation: Decision Tree`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_0 == 1: \n",
    "    DT_Dict_Out_1_Nor_0_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                        subject_outlier       = subject_outlier, \n",
    "                                        subject_normalization = subject_normalization, \n",
    "                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                        subject_dimension     = subject_dimension,\n",
    "                                        data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_0_Aut_0_DR_0                = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_0_Aut_0_DR_0          = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_0_Aut_0_DR_0  = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_0_Aut_0_DR_0           = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_1 == 1: \n",
    "  DT_Dict_Out_1_Nor_1_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                            subject_normalization = subject_normalization, \n",
    "                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                            subject_dimension     = subject_dimension,\n",
    "                                            data_source = \"list\" )   \n",
    "  Model_DT_Out_1_Nor_1_Aut_0_DR_0                = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "  Predictions_DT_Out_1_Nor_1_Aut_0_DR_0          = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "  Statistics_Detailed_DT_Out_1_Nor_1_Aut_0_DR_0  = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "  Statistics_DT_Out_1_Nor_1_Aut_0_DR_0           = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_2 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_0                = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_0          = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_0  = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_0           = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_3 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_1 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_1                = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_1          = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_1  = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_1           = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5- `Operation: Gradient Boosting`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_0 == 1: \n",
    "    GB_Dict_Out_1_Nor_0_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier, \n",
    "                                                            subject_normalization = subject_normalization, \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension,\n",
    "                                                            data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_0_Aut_0_DR_0                = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_0_Aut_0_DR_0          = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_0_Aut_0_DR_0  = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_0_Aut_0_DR_0           = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_1 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier,\n",
    "                                                            subject_normalization = subject_normalization,  \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension, \n",
    "                                                            data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_0_DR_0                = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_0_DR_0          = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_0_DR_0  = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_0_DR_0           = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_2 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_0                = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_0          = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_0  = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_0           = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_3 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_1 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_1                = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_1          = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_1  = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_1           = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4- `Operation: Combine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-) `Statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_N_0 == 1: \n",
    "        NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0], axis = 0) \n",
    "    if switch_N_1 == 1:\n",
    "        NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0], axis = 0)\n",
    "    if switch_N_2 == 1:\n",
    "        NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0], axis = 0) \n",
    "    if switch_N_3 == 1:\n",
    "        NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1], axis = 0) \n",
    "except:\n",
    "    pass \n",
    "\n",
    "SVM_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_SVM_0 == 1: \n",
    "        SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "    if switch_SVM_1 == 1:\n",
    "        SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_SVM_2 == 1:\n",
    "        SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "    if switch_SVM_3 == 1:\n",
    "        SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0) \n",
    "except:\n",
    "    pass \n",
    "\n",
    "SGD_All = pd.DataFrame()\n",
    "try: \n",
    "    if switch_SGD_0 == 1:\n",
    "        SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_SGD_1 == 1:\n",
    "        SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_SGD_2 == 1:\n",
    "        SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_SGD_3 == 1:\n",
    "        SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "DT_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_DT_0 == 1:\n",
    "        DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_DT_1 == 1:\n",
    "        DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_DT_2 == 1:\n",
    "        DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_DT_3 == 1:\n",
    "        DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "RF_All = pd.DataFrame()\n",
    "try:\n",
    "    if switch_RF_0 == 1:\n",
    "        RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_RF_1 == 1:\n",
    "        RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_RF_2 == 1:\n",
    "        RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_RF_3 == 1:\n",
    "        RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "GB_All = pd.DataFrame()\n",
    "try: \n",
    "    if switch_GB_0 == 1:\n",
    "        GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_GB_1 == 1:\n",
    "        GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_GB_2 == 1:\n",
    "        GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "    if switch_GB_3 == 1:\n",
    "        GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) `Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All_Models = []\n",
    "NN_All_Encoders = [] \n",
    "if switch_N_0 == 1: \n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_0_Aut_0_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0)\n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_N_1 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_0_DR_0)\n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_N_2 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0)\n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_N_3 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_1\")  \n",
    "\n",
    "NN_All_Models_Dict = {} \n",
    "for i in range(len(NN_All_Models)):\n",
    "    NN_All_Models_Dict[f\"Model_{i}\"] = NN_All_Models[i] \n",
    "\n",
    "NN_All_Encoders_Dict = {}\n",
    "for i in range(len(NN_All_Encoders)):\n",
    "    NN_All_Encoders_Dict[f\"Encoder_{i}\"] = NN_All_Encoders[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_All_Models = []\n",
    "if switch_SVM_0 == 1: \n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_SVM_1 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SVM_2 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SVM_3 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "SVM_All_Models_Dict = {} \n",
    "for i in range(len(SVM_All_Models)):\n",
    "    SVM_All_Models_Dict[f\"Model_{i}\"] = SVM_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_All_Models = []\n",
    "if switch_SGD_0 == 1: \n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_SGD_1 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SGD_2 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SGD_3 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "SGD_All_Models_Dict = {} \n",
    "for i in range(len(SGD_All_Models)):\n",
    "    SGD_All_Models_Dict[f\"Model_{i}\"] = SGD_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_All_Models = []\n",
    "if switch_DT_0 == 1: \n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_DT_1 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_0_DR_0\")  \n",
    "if switch_DT_2 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "if switch_DT_3 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "DT_All_Models_Dict = {} \n",
    "for i in range(len(DT_All_Models)):\n",
    "    DT_All_Models_Dict[f\"Model_{i}\"] = DT_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_All_Models = []\n",
    "if switch_RF_0 == 1: \n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_RF_1 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_RF_2 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_1_DR_0\") \n",
    "if switch_RF_3 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "RF_All_Models_Dict = {} \n",
    "for i in range(len(RF_All_Models)):\n",
    "    RF_All_Models_Dict[f\"Model_{i}\"] = RF_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_All_Models = []\n",
    "if switch_GB_0 == 1:\n",
    "    try: \n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_GB_1 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_GB_2 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_0\") \n",
    "\n",
    "if switch_GB_3 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "GB_All_Models_Dict = {} \n",
    "for i in range(len(GB_All_Models)):\n",
    "    GB_All_Models_Dict[f\"Model_{i}\"] = GB_All_Models[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-) `Report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject Outlier: ZScore_v0_ZScore_v0\n",
      "Subject Normalization: StandardScaler_StandardScaler\n",
      "Subject Autoencoder: Basic_v1_Basic_v1\n",
      "Subject Dimension: PCA_n3_Free\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subject Outlier: {subject_outlier}\")\n",
    "print(f\"Subject Normalization: {subject_normalization}\") \n",
    "print(f\"Subject Autoencoder: {subject_autoencoder}\")\n",
    "print(f\"Subject Dimension: {subject_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Applications  \\\n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "\n",
       "        Applications_Condition Model  \\\n",
       "0       Out_1_Nor_1_Aut_1_DR_0    DT   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0    RF   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0   SGD   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0   SVM   \n",
       "0       Out_1_Nor_1_Aut_1_DR_0    RF   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0    RF   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1    RF   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1    DT   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0   SGD   \n",
       "0  Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0    DT   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0    DT   \n",
       "0  Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0   SVM   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1   SVM   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1   SGD   \n",
       "0       Out_1_Nor_1_Aut_1_DR_0   SGD   \n",
       "0       Out_1_Nor_1_Aut_1_DR_0   SVM   \n",
       "0  Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "\n",
       "                                          Parameters  Accuracy  Precision  \\\n",
       "0                                              Basic      1.00   1.000000   \n",
       "0                                              Basic      1.00   1.000000   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      1.00   1.000000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      1.00   1.000000   \n",
       "0                                              Basic      1.00   1.000000   \n",
       "0                                              Basic      1.00   1.000000   \n",
       "0                                              Basic      0.90   0.933333   \n",
       "0                                              Basic      0.80   0.900000   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      0.80   0.800000   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.82   0.733333   \n",
       "0                                              Basic      0.70   0.833333   \n",
       "0                                              Basic      0.70   0.833333   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.54   0.725000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      0.40   0.380000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      0.40   0.300000   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      0.30   0.275000   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      0.30   0.150000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      0.20   0.057143   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.22   0.047619   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.18   0.040000   \n",
       "\n",
       "   Recall        F1  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     0.9  0.900000  \n",
       "0     0.8  0.840000  \n",
       "0     0.8  0.800000  \n",
       "0     0.8  0.750000  \n",
       "0     0.7  0.710000  \n",
       "0     0.7  0.710000  \n",
       "0     0.7  0.680000  \n",
       "0     0.4  0.354286  \n",
       "0     0.4  0.333333  \n",
       "0     0.3  0.285714  \n",
       "0     0.3  0.200000  \n",
       "0     0.2  0.088889  \n",
       "0     0.2  0.075000  \n",
       "0     0.2  0.066667  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data = pd.concat([NN_All, SVM_All, DT_All, RF_All, GB_All, SGD_All], axis=0) \n",
    "All_Data.sort_values(by = [\"F1\"], ascending= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6- `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"data_raw\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(data_raw, file)   \n",
    "\n",
    "export_name = \"subject_data_full\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_data_full, file)   \n",
    "\n",
    "    \n",
    "export_name = \"subject_outlier_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_0, file)   \n",
    "\n",
    "export_name = \"subject_outlier_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_1, file)   \n",
    "\n",
    "export_name = \"subject_outlier\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier, file)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_normalization_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_0, file)   \n",
    "\n",
    "export_name = \"subject_normalization_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_1, file)   \n",
    "\n",
    "export_name = \"subject_normalization\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization, file)   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_autoencoder_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_0, file)   \n",
    "\n",
    "export_name = \"subject_autoencoder_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_1, file) \n",
    "\n",
    "export_name = \"subject_autoencoder\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder, file)   \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_dimension_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_0, file)   \n",
    "\n",
    "export_name = \"subject_dimension_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_1, file)   \n",
    "\n",
    "export_name = \"subject_dimension\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension, file)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Applications  \\\n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "\n",
       "        Applications_Condition Model  \\\n",
       "0  Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "\n",
       "                                          Parameters  Accuracy  Precision  \\\n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.54   0.725000   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.82   0.733333   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.18   0.040000   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.22   0.047619   \n",
       "\n",
       "   Recall        F1  \n",
       "0     0.7  0.680000  \n",
       "0     0.8  0.750000  \n",
       "0     0.2  0.066667  \n",
       "0     0.2  0.075000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN\n",
    "export_name = \"NN_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All, file)\n",
    "\n",
    "# --------------------\n",
    "# GB\n",
    "export_name = \"GB_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Models, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All_Models, file) \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All_Models, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "# GB\n",
    "export_name = \"GB_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All_Models, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Encoders\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Encoders, file) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
