{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- `Config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Documents/Thesis/exp1/bilimnn/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Path Management\n",
    "import pickle\n",
    "import os\n",
    "# Data Handling \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Transformers \n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "# Tokenization\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"Jupyter has been running from Manager\") \n",
    "except:\n",
    "    temp  = \"temp\"\n",
    "    %run s0_config.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- `Load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_name = \"subject_data\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_setup}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_data = pickle.load(file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell_Type</th>\n",
       "      <th>Gene_Marker</th>\n",
       "      <th>Expression</th>\n",
       "      <th>P Value</th>\n",
       "      <th>P Value(Adj)</th>\n",
       "      <th>Score</th>\n",
       "      <th>Expression_Gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hematopoietic stem cell</td>\n",
       "      <td>PRSS57</td>\n",
       "      <td>1.8250</td>\n",
       "      <td>3.733220e-99</td>\n",
       "      <td>3.934440e-95</td>\n",
       "      <td>21.135736</td>\n",
       "      <td>[1.825013518333435, 'PRSS57']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hematopoietic stem cell</td>\n",
       "      <td>ENSG00000175061</td>\n",
       "      <td>2.7580</td>\n",
       "      <td>3.352268e-93</td>\n",
       "      <td>1.766478e-89</td>\n",
       "      <td>20.478439</td>\n",
       "      <td>[2.757690668106079, 'ENSG00000175061']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hematopoietic stem cell</td>\n",
       "      <td>SPINK2</td>\n",
       "      <td>1.7420</td>\n",
       "      <td>5.660589e-89</td>\n",
       "      <td>2.386278e-85</td>\n",
       "      <td>19.998631</td>\n",
       "      <td>[1.7422393560409546, 'SPINK2']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hematopoietic stem cell</td>\n",
       "      <td>SOX4</td>\n",
       "      <td>1.7340</td>\n",
       "      <td>3.750766e-80</td>\n",
       "      <td>7.187150e-77</td>\n",
       "      <td>18.958588</td>\n",
       "      <td>[1.7343593835830688, 'SOX4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hematopoietic stem cell</td>\n",
       "      <td>SMIM24</td>\n",
       "      <td>1.4780</td>\n",
       "      <td>1.085542e-78</td>\n",
       "      <td>1.906754e-75</td>\n",
       "      <td>18.780741</td>\n",
       "      <td>[1.4784719944000244, 'SMIM24']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>double negative T regulatory cell</td>\n",
       "      <td>CD3D,CD3E,CST7,GZMA,NKG7</td>\n",
       "      <td>2.3152</td>\n",
       "      <td>1.470268e-231</td>\n",
       "      <td>5.165050e-228</td>\n",
       "      <td>35.086993</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>double negative T regulatory cell</td>\n",
       "      <td>CD3D,CD3E,CST7,CTSW,NKG7</td>\n",
       "      <td>2.3286</td>\n",
       "      <td>1.470268e-231</td>\n",
       "      <td>5.165050e-228</td>\n",
       "      <td>34.929794</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>double negative T regulatory cell</td>\n",
       "      <td>CD3D,CD3E,GZMA,CTSW,NKG7</td>\n",
       "      <td>2.3194</td>\n",
       "      <td>1.470268e-231</td>\n",
       "      <td>5.165050e-228</td>\n",
       "      <td>34.775430</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>double negative T regulatory cell</td>\n",
       "      <td>CD3D,CST7,GZMA,CTSW,NKG7</td>\n",
       "      <td>2.2566</td>\n",
       "      <td>1.470268e-231</td>\n",
       "      <td>5.165050e-228</td>\n",
       "      <td>34.478230</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>double negative T regulatory cell</td>\n",
       "      <td>CD3E,CST7,GZMA,CTSW,NKG7</td>\n",
       "      <td>2.3148</td>\n",
       "      <td>1.470268e-231</td>\n",
       "      <td>5.165050e-228</td>\n",
       "      <td>34.108781</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2652 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Cell_Type               Gene_Marker  Expression  \\\n",
       "0             hematopoietic stem cell                    PRSS57      1.8250   \n",
       "1             hematopoietic stem cell           ENSG00000175061      2.7580   \n",
       "2             hematopoietic stem cell                    SPINK2      1.7420   \n",
       "3             hematopoietic stem cell                      SOX4      1.7340   \n",
       "4             hematopoietic stem cell                    SMIM24      1.4780   \n",
       "..                                ...                       ...         ...   \n",
       "51  double negative T regulatory cell  CD3D,CD3E,CST7,GZMA,NKG7      2.3152   \n",
       "52  double negative T regulatory cell  CD3D,CD3E,CST7,CTSW,NKG7      2.3286   \n",
       "53  double negative T regulatory cell  CD3D,CD3E,GZMA,CTSW,NKG7      2.3194   \n",
       "54  double negative T regulatory cell  CD3D,CST7,GZMA,CTSW,NKG7      2.2566   \n",
       "55  double negative T regulatory cell  CD3E,CST7,GZMA,CTSW,NKG7      2.3148   \n",
       "\n",
       "          P Value   P Value(Adj)      Score  \\\n",
       "0    3.733220e-99   3.934440e-95  21.135736   \n",
       "1    3.352268e-93   1.766478e-89  20.478439   \n",
       "2    5.660589e-89   2.386278e-85  19.998631   \n",
       "3    3.750766e-80   7.187150e-77  18.958588   \n",
       "4    1.085542e-78   1.906754e-75  18.780741   \n",
       "..            ...            ...        ...   \n",
       "51  1.470268e-231  5.165050e-228  35.086993   \n",
       "52  1.470268e-231  5.165050e-228  34.929794   \n",
       "53  1.470268e-231  5.165050e-228  34.775430   \n",
       "54  1.470268e-231  5.165050e-228  34.478230   \n",
       "55  1.470268e-231  5.165050e-228  34.108781   \n",
       "\n",
       "                           Expression_Gene  \n",
       "0            [1.825013518333435, 'PRSS57']  \n",
       "1   [2.757690668106079, 'ENSG00000175061']  \n",
       "2           [1.7422393560409546, 'SPINK2']  \n",
       "3             [1.7343593835830688, 'SOX4']  \n",
       "4           [1.4784719944000244, 'SMIM24']  \n",
       "..                                     ...  \n",
       "51                                     NaN  \n",
       "52                                     NaN  \n",
       "53                                     NaN  \n",
       "54                                     NaN  \n",
       "55                                     NaN  \n",
       "\n",
       "[2652 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_data = subject_data.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_one = pd.DataFrame() \n",
    "all_in_one[\"Cell_Type\"]        = subject_data[\"Cell_Type\"]\n",
    "all_in_one[\"Gene_Marker\"]      = subject_data[\"Gene_Marker\"]\n",
    "all_in_one[\"Expression\"]       = subject_data[\"Expression\"]\n",
    "all_in_one[\"Expression_Gene\"]  = subject_data[\"Expression_Gene\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.A- `Operation` | BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-) `Context Construction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        hematopoietic stem cell PRSS57\n",
       "1               hematopoietic stem cell ENSG00000175061\n",
       "2                        hematopoietic stem cell SPINK2\n",
       "3                          hematopoietic stem cell SOX4\n",
       "4                        hematopoietic stem cell SMIM24\n",
       "                            ...                        \n",
       "51    double negative T regulatory cell CD3D,CD3E,CS...\n",
       "52    double negative T regulatory cell CD3D,CD3E,CS...\n",
       "53    double negative T regulatory cell CD3D,CD3E,GZ...\n",
       "54    double negative T regulatory cell CD3D,CST7,GZ...\n",
       "55    double negative T regulatory cell CD3E,CST7,GZ...\n",
       "Length: 2652, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = subject_data['Cell_Type'] + \" \" + subject_data['Gene_Marker']\n",
    "texts = texts.astype(str)\n",
    "texts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-) `Transformer Selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Step 2: Tokenization \n",
    "tokenized = texts.apply(lambda x: tokenizer(x, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")) \n",
    "# Step 3: Model Selection  \n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-) `Tokenization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [04:42<00:00,  3.41s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 32\n",
    "Combined_Text_Embeddings = []\n",
    "\n",
    "# Assuming model is already loaded and set to evaluation mode with model.eval()\n",
    "\n",
    "for i in tqdm(range(0, len(tokenized), batch_size)):\n",
    "    # Here, make sure you're extracting batches correctly\n",
    "    batch = tokenized[i:i+batch_size]\n",
    "    \n",
    "    # Now, prepare your inputs. This assumes each entry in `batch` is a dictionary\n",
    "    # returned by the tokenizer corresponding to a single example.\n",
    "    batch_input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    batch_attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    \n",
    "    # Ensure dimensions are correct: [batch_size, sequence_length]\n",
    "    # If you encounter an error here, check the structure and content of `batch`\n",
    "    inputs = {\n",
    "        'input_ids': batch_input_ids.squeeze(),  # Remove any extra dimensions\n",
    "        'attention_mask': batch_attention_mask.squeeze()  # Remove any extra dimensions\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        batch_embeddings = outputs.pooler_output\n",
    "        Combined_Text_Embeddings.append(batch_embeddings)\n",
    "\n",
    "# Combine embeddings from all batches\n",
    "Embeddings_BERT = torch.cat(Combined_Text_Embeddings, dim=0)\n",
    "\n",
    "#Embeddings_BERT = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2652, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embeddings_BERT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-) `Main Data Creation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_full[\"Cell_Type_Embeddings\"] = Embeddings_BERT  \n",
    "all_in_one[\"Gene_Marker_BERT\"] = [embedding.tolist() for embedding in Embeddings_BERT] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_list = data_full[\"Cell_Type_Embeddings\"].tolist()  # Get the column as a list of lists\n",
    "#embeddings_tensor = torch.tensor(embeddings_list)             # Convert to a tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.B- `Operation` | GPT2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-) `Context Construction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        hematopoietic stem cell PRSS57\n",
       "1               hematopoietic stem cell ENSG00000175061\n",
       "2                        hematopoietic stem cell SPINK2\n",
       "3                          hematopoietic stem cell SOX4\n",
       "4                        hematopoietic stem cell SMIM24\n",
       "                            ...                        \n",
       "51    double negative T regulatory cell CD3D,CD3E,CS...\n",
       "52    double negative T regulatory cell CD3D,CD3E,CS...\n",
       "53    double negative T regulatory cell CD3D,CD3E,GZ...\n",
       "54    double negative T regulatory cell CD3D,CST7,GZ...\n",
       "55    double negative T regulatory cell CD3E,CST7,GZ...\n",
       "Length: 2652, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = subject_data['Cell_Type'] + \" \" + subject_data['Gene_Marker']\n",
    "texts = texts.astype(str)\n",
    "texts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-) `Transformer Selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "model = GPT2Model.from_pretrained('gpt2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-) `Tokenization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:17<00:00,  4.68it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "Combined_Text_Embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch_texts = texts[i:i+batch_size].tolist()\n",
    "    inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use the mean of the last hidden state as embedding representation\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        Combined_Text_Embeddings.append(embeddings)\n",
    "\n",
    "# Combine all batch embeddings into a single tensor\n",
    "Embeddings_GPT = torch.cat(Combined_Text_Embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2652, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embeddings_GPT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-) `Main Data Creation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 \n",
    "#data_full = subject_data.copy() \n",
    "# Step 2: \n",
    "#data_full[\"Cell_Type_Embeddings\"] = Embeddings_BERT  \n",
    "all_in_one[\"Gene_Marker_GPT2\"] = [embedding.tolist() for embedding in Embeddings_GPT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.C- `Operation` | GPT3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai \n",
    "from openai.embeddings_utils import get_embeddings  \n",
    "openai.api_key = OPENAI_API_KEY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-) `Context Construction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        hematopoietic stem cell PRSS57\n",
       "1               hematopoietic stem cell ENSG00000175061\n",
       "2                        hematopoietic stem cell SPINK2\n",
       "3                          hematopoietic stem cell SOX4\n",
       "4                        hematopoietic stem cell SMIM24\n",
       "                            ...                        \n",
       "51    double negative T regulatory cell CD3D,CD3E,CS...\n",
       "52    double negative T regulatory cell CD3D,CD3E,CS...\n",
       "53    double negative T regulatory cell CD3D,CD3E,GZ...\n",
       "54    double negative T regulatory cell CD3D,CST7,GZ...\n",
       "55    double negative T regulatory cell CD3E,CST7,GZ...\n",
       "Length: 2652, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = subject_data['Cell_Type'] + \" \" + subject_data['Gene_Marker']\n",
    "texts = texts.astype(str)\n",
    "texts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-) `Transformer Selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\\ntokenizer.pad_token = tokenizer.eos_token \\n\\nmodel = GPT2Model.from_pretrained('gpt2') \\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "model = GPT2Model.from_pretrained('gpt2') \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-) `Tokenization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2652/2652 [17:13<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for embeddings\n",
    "embeddings_list = []\n",
    "\n",
    "for text in tqdm(texts):\n",
    "    response = openai.Embedding.create(\n",
    "      input=text,\n",
    "      engine=\"text-embedding-ada-002\"  # or another suitable GPT-3 model\n",
    "    )\n",
    "    embedding = response['data'][0]['embedding']\n",
    "    embeddings_list.append(embedding)\n",
    "\n",
    "# Convert list of embeddings to a suitable format (e.g., numpy array)\n",
    "Embeddings_GPT = np.array(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2652, 1536)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embeddings_GPT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-) `Main Data Creation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 \n",
    "#data_full = subject_data.copy() \n",
    "# Step 2: \n",
    "#data_full[\"Cell_Type_Embeddings\"] = Embeddings_BERT  \n",
    "all_in_one[\"Gene_Marker_GPT3\"] = [embedding.tolist() for embedding in Embeddings_GPT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing   import StandardScaler\n",
    "scaler = StandardScaler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_one[\"Expression_Normalized\"] = scaler.fit_transform(all_in_one[\"Expression\"].values.reshape(-1, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_BERT = np.stack(all_in_one[\"Gene_Marker_BERT\"].values)  \n",
    "scaler = StandardScaler() \n",
    "all_in_one[\"Gene_Marker_BERT_Normalized\"] = list(scaler.fit_transform(embeddings_BERT)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_GPT2 = np.stack(all_in_one[\"Gene_Marker_GPT2\"].values)  \n",
    "scaler = StandardScaler() \n",
    "all_in_one[\"Gene_Marker_GPT2_Normalized\"] = list(scaler.fit_transform(embeddings_GPT2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_GPT3 = np.stack(all_in_one[\"Gene_Marker_GPT3\"].values)  \n",
    "scaler = StandardScaler() \n",
    "all_in_one[\"Gene_Marker_GPT3_Normalized\"] = list(scaler.fit_transform(embeddings_GPT3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_barcode = \"process_3\"\n",
    "export_name = \"all_in_one\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/preprocessed\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(all_in_one, file)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilimnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
