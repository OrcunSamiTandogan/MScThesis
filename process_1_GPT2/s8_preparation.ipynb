{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 7: Predictions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- `Config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "except: \n",
    "    %run s0_config.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- `Load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_name = \"data_raw\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    data_raw = pickle.load(file) \n",
    "\n",
    "import_name = \"subject_data_full\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_data_full = pickle.load(file) \n",
    "\n",
    "\n",
    "import_name = \"subject_outlier_0\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_outlier_0 = pickle.load(file) \n",
    "\n",
    "\n",
    "import_name = \"subject_outlier_1\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_outlier_1 = pickle.load(file) \n",
    "\n",
    "\n",
    "    \n",
    "import_name = \"subject_normalization_0\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_normalization_0 = pickle.load(file) \n",
    "\n",
    "\n",
    "import_name = \"subject_normalization_1\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_normalization_1 = pickle.load(file) \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "import_name = \"subject_autoencoder_0\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_autoencoder_0 = pickle.load(file) \n",
    "\n",
    "\n",
    "import_name = \"subject_autoencoder_1\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_autoencoder_1 = pickle.load(file) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "import_name = \"subject_dimension_0\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_dimension_0 = pickle.load(file) \n",
    "\n",
    "\n",
    "import_name = \"subject_dimension_1\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_dimension}\", f\"{import_name}\" + \".pkl\")) , 'rb') as file:\n",
    "    subject_dimension_1 = pickle.load(file) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_label  = subject_outlier_0     + \"_\" + subject_outlier_1     + \"_\" + subject_normalization_0 + \"_\" + subject_normalization_1 + \"_\" \n",
    "subject_label += subject_autoencoder_0 + \"_\" + subject_autoencoder_1 + \"_\" + subject_dimension_0     + \"_\" + subject_dimension_1 + \"_\" \n",
    "subject_label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- `Preprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0-) `Overview`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length: {len(subject_data_full)}\")\n",
    "Cell_Type   = subject_data_full[\"Cell_Type\"] \n",
    "Gene_Marker = subject_data_full[\"Gene_Marker\"] \n",
    "print(f\"Unique Cell Types: {Cell_Type.nunique()}\")\n",
    "print(f\"Unique Gene Markers: {Gene_Marker.nunique()}\")\n",
    "\n",
    "print(\"--------------------\")\n",
    "print(f\"Subject Outlier 0 (Embedding): {subject_outlier_0}\")\n",
    "print(f\"Subject Outlier 1 (Expression): {subject_outlier_1}\")\n",
    "subject_outlier = subject_outlier_0 + \"_\" + subject_outlier_1 \n",
    "print(\"Subject_Outlier:\", subject_outlier)\n",
    "\n",
    "print(f\"Subject normalization 0 (Embedding): {subject_normalization_0}\")\n",
    "print(f\"Subject normalization 1 (Expression): {subject_normalization_1}\")\n",
    "subject_normalization = subject_normalization_0 + \"_\" + subject_normalization_1 \n",
    "\n",
    "print(f\"Subject Autoencoder 0 (Embedding): {subject_autoencoder_0}\")\n",
    "print(f\"Subject Autoencoder 1 (Expression): {subject_autoencoder_1}\")\n",
    "subject_autoencoder = subject_autoencoder_0 + \"_\" + subject_autoencoder_1 \n",
    "\n",
    "print(f\"Subject Dimension Reduction 0 (Embedding): {subject_dimension_0}\") \n",
    "print(f\"Subject Dimension Reduction 1 (Expression): {subject_dimension_1}\") \n",
    "subject_dimension = subject_dimension_0 + \"_\" + subject_dimension_1 \n",
    "\n",
    "print(\"--------------------\") \n",
    "pd.concat([subject_data_full.head(5), subject_data_full.tail(5)])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-) `Preparation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data_full[\"Embeddings_Autoencoder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column from Expression and Cell_Type_Gene_Marker_Embeddings column as list [ Expression, Cell_Type_Gene_Marker_Embeddings ]\n",
    "#subject_data_full[\"Expression_Embeddings_Final\"] = subject_data_full[[\"Expression_Autoencoder\", \"Embeddings_Autoencoder\"]].values.tolist() \n",
    "subject_data_full[\"Subject_Column\"] = subject_data_full[\"Embeddings_Autoencoder\"] \n",
    "subject_data_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_data_full[[\"Cell_Type\",\"Expression_Autoencoder\", \"Embeddings_Autoencoder\", \"Expression_Embeddings_Final\"] ]\n",
    "subject_data_full[[\"Cell_Type\",\"Embeddings_Autoencoder\", \"Subject_Column\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bench-Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-) `Tool Setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"tool.ipynb\")     \n",
    "%run $tool_prediction \n",
    "\n",
    "tool_basic_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"toolbasic.ipynb\")     \n",
    "%run $tool_basic_prediction \n",
    "\n",
    "#tool_map = access_data_path(target_folder = f\"class/{folder_prediction}\", target_file = \"toolmap.ipynb\")     \n",
    "#%run $tool_map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-) `Panel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-) `Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_models = \"basic\"  \n",
    "try:\n",
    "    if manager == 1:\n",
    "        switch_models = \"complex\"      \n",
    "        switch_models = \"basic\"  \n",
    "        print(\"Machine Learning Models: Complex\")\n",
    "except:\n",
    "    switch_models = \"basic\"  \n",
    "    print(\"Machine Learning Models: Basic\")\n",
    "\n",
    "\n",
    "if switch_models == \"basic\":\n",
    "    SGD_Method = prediction_model_SGD_multilabel_basic\n",
    "    SVM_Method = prediction_model_SVM_multilabel_basic\n",
    "    GB_Method  = prediction_model_GB_multilabel_basic\n",
    "    RF_Method  = prediction_model_RF_multilabel_basic\n",
    "    DT_Method  = prediction_model_DT_multilabel_basic\n",
    "else:\n",
    "    SGD_Method = prediction_model_SGD_multilabel\n",
    "    SVM_Method = prediction_model_SVM_multilabel\n",
    "    GB_Method  = prediction_model_GB_multilabel\n",
    "    RF_Method  = prediction_model_RF_multilabel\n",
    "    DT_Method  = prediction_model_DT_multilabel\n",
    "\n",
    "\n",
    "switch_complex_model = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-) `Switches`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting \n",
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "        switch_N_0 = 1\n",
    "        switch_N_1 = 1\n",
    "        switch_N_2 = 1\n",
    "        switch_N_3 = 1\n",
    "except:\n",
    "    switch_N_0 = 1\n",
    "    switch_N_1 = 1\n",
    "    switch_N_2 = 1\n",
    "    switch_N_3 = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------\n",
    "# Stochastic Gradient Descent \n",
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "        switch_SGD_0 = 1\n",
    "        switch_SGD_1 = 1\n",
    "        switch_SGD_2 = 1\n",
    "        switch_SGD_3 = 1\n",
    "except:\n",
    "    switch_SGD_0 = 1\n",
    "    switch_SGD_1 = 1\n",
    "    switch_SGD_2 = 1\n",
    "    switch_SGD_3 = 1\n",
    "\n",
    "# ------------------------\n",
    "# Random Forest \n",
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "        switch_RF_0 = 1\n",
    "        switch_RF_1 = 1\n",
    "        switch_RF_2 = 1\n",
    "        switch_RF_3 = 1\n",
    "except:\n",
    "    switch_RF_0 = 1\n",
    "    switch_RF_1 = 1\n",
    "    switch_RF_2 = 1\n",
    "    switch_RF_3 = 1\n",
    "\n",
    "# ------------------------ \n",
    "# Decision Tree \n",
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "        switch_DT_0 = 1\n",
    "        switch_DT_1 = 1\n",
    "        switch_DT_2 = 1\n",
    "        switch_DT_3 = 1\n",
    "except:\n",
    "    switch_DT_0 = 1\n",
    "    switch_DT_1 = 1\n",
    "    switch_DT_2 = 1\n",
    "    switch_DT_3 = 1\n",
    "\n",
    "# ------------------------ \n",
    "# Support Vector Machine \n",
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "        switch_SVM_0 = 1\n",
    "        switch_SVM_1 = 1\n",
    "        switch_SVM_2 = 1\n",
    "        switch_SVM_3 = 1\n",
    "except:\n",
    "    switch_SVM_0 = 1\n",
    "    switch_SVM_1 = 1\n",
    "    switch_SVM_2 = 1 \n",
    "    switch_SVM_3= 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
