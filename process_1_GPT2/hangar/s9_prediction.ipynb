{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 7: Predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n",
      "Length: 1872\n",
      "Unique Cell Types: 12\n",
      "Unique Gene Markers: 1602\n",
      "--------------------\n",
      "Subject Outlier 0 (Embedding): Free_v0\n",
      "Subject_Outlier: Free_v0\n",
      "Subject Normalization 0 (Embedding): StandardScaler\n",
      "Subject Autoencoder 0 (Embedding): Free_v0\n",
      "Subject Dimension Reduction 0 (Embedding): Free_v0\n",
      "--------------------\n",
      "Tools of ML: Complex\n",
      "Machine Learning Models: Basic\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "except: \n",
    "    %run s0_config.ipynb \n",
    "    %run s8_preparation.ipynb \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3- `Bench`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0- `Operation: Neural Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [-0.1713259220123291, -0.1984623372554779, -0....\n",
       "1     [-0.014635225757956505, -0.4390987753868103, -...\n",
       "2     [-0.035851024091243744, -0.4263487756252289, 0...\n",
       "3     [-0.05883532762527466, -0.35421204566955566, -...\n",
       "4     [-0.37293335795402527, -0.4042693078517914, 0....\n",
       "                            ...                        \n",
       "51    [0.06260330975055695, -0.4410420358181, 0.4309...\n",
       "52    [0.05649421736598015, -0.3864367604255676, 0.3...\n",
       "53    [0.03859759122133255, -0.3970209062099457, 0.4...\n",
       "54    [0.13350529968738556, -0.4641953706741333, 0.3...\n",
       "55    [0.05018668249249458, -0.3949635326862335, 0.2...\n",
       "Name: Embeddings, Length: 1872, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subject_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "operationnn.ipynb working\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_emb (InputLayer)      [(None, 768)]             0         \n",
      "                                                                 \n",
      " gaussian_noise (GaussianNo  (None, 768)               0         \n",
      " ise)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               196864    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231308 (903.55 KB)\n",
      "Trainable params: 231308 (903.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 7ms/step - loss: 4.3922 - accuracy: 0.1671 - val_loss: 2.5793 - val_accuracy: 0.0600\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5857 - accuracy: 0.4937 - val_loss: 2.0762 - val_accuracy: 0.4567\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8325 - accuracy: 0.7569 - val_loss: 1.3414 - val_accuracy: 0.6167\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.9031 - val_loss: 1.2302 - val_accuracy: 0.5333\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9424 - val_loss: 0.8334 - val_accuracy: 0.7333\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9691 - val_loss: 0.7899 - val_accuracy: 0.6767\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9833 - val_loss: 0.5269 - val_accuracy: 0.8067\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9841 - val_loss: 0.5136 - val_accuracy: 0.8167\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9916 - val_loss: 0.4958 - val_accuracy: 0.8267\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9875 - val_loss: 0.2988 - val_accuracy: 0.9167\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9942 - val_loss: 0.4057 - val_accuracy: 0.8500\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9925 - val_loss: 0.2732 - val_accuracy: 0.9300\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.4426 - val_accuracy: 0.8267\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9958 - val_loss: 0.3669 - val_accuracy: 0.8900\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 0.9958 - val_loss: 0.4779 - val_accuracy: 0.8100\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9983 - val_loss: 0.3342 - val_accuracy: 0.8733\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.2994 - val_accuracy: 0.8933\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.2867 - val_accuracy: 0.8967\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.4408 - val_accuracy: 0.7967\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.9333\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.3082 - val_accuracy: 0.9167\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.3217 - val_accuracy: 0.8833\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.3014 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.3227 - val_accuracy: 0.9133\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9167\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9067\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.8900\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.3581 - val_accuracy: 0.8633\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.5112 - val_accuracy: 0.8167\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9942 - val_loss: 0.4213 - val_accuracy: 0.8500\n",
      "12/12 [==============================] - 0s 871us/step - loss: 0.1338 - accuracy: 0.9573\n",
      "Fold 1 Test Accuracy: 0.9573333263397217\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.7025 - accuracy: 0.1512 - val_loss: 2.4292 - val_accuracy: 0.2800\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.8189 - accuracy: 0.3860 - val_loss: 1.9314 - val_accuracy: 0.3600\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8314 - accuracy: 0.7485 - val_loss: 1.9033 - val_accuracy: 0.4800\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.9073 - val_loss: 1.5998 - val_accuracy: 0.3767\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9490 - val_loss: 1.5012 - val_accuracy: 0.4200\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9733 - val_loss: 1.0671 - val_accuracy: 0.5567\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0951 - accuracy: 0.9808 - val_loss: 1.1099 - val_accuracy: 0.6200\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9875 - val_loss: 0.7727 - val_accuracy: 0.7233\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 0.9891 - val_loss: 1.0138 - val_accuracy: 0.6100\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9883 - val_loss: 0.6002 - val_accuracy: 0.8100\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.9933 - val_loss: 0.9418 - val_accuracy: 0.7067\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9933 - val_loss: 0.7584 - val_accuracy: 0.7700\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9958 - val_loss: 0.6857 - val_accuracy: 0.7867\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 0.9968 - val_accuracy: 0.6700\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.8165 - val_accuracy: 0.7100\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0139 - accuracy: 0.9992 - val_loss: 0.6060 - val_accuracy: 0.8133\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5721 - val_accuracy: 0.8033\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.8476 - val_accuracy: 0.7067\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.7888 - val_accuracy: 0.7400\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.5553 - val_accuracy: 0.8167\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.8167\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.5537 - val_accuracy: 0.8200\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.4655 - val_accuracy: 0.8433\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6472 - val_accuracy: 0.7933\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9016 - val_accuracy: 0.7300\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.8700\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.6733\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.4756 - val_accuracy: 0.8400\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.6692 - val_accuracy: 0.8133\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.8467\n",
      "12/12 [==============================] - 0s 626us/step - loss: 0.0820 - accuracy: 0.9760\n",
      "Fold 2 Test Accuracy: 0.9760000109672546\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 4ms/step - loss: 5.2164 - accuracy: 0.1853 - val_loss: 2.2934 - val_accuracy: 0.4100\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.6780 - accuracy: 0.4658 - val_loss: 1.5871 - val_accuracy: 0.4833\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.7988 - val_loss: 1.2191 - val_accuracy: 0.6633\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.9132 - val_loss: 1.1054 - val_accuracy: 0.6867\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2071 - accuracy: 0.9566 - val_loss: 0.9543 - val_accuracy: 0.6467\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9691 - val_loss: 0.9243 - val_accuracy: 0.7167\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9825 - val_loss: 0.7651 - val_accuracy: 0.6933\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.9833 - val_loss: 0.6389 - val_accuracy: 0.7533\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9908 - val_loss: 0.5978 - val_accuracy: 0.7867\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9958 - val_loss: 0.4113 - val_accuracy: 0.8767\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9950 - val_loss: 0.4114 - val_accuracy: 0.8633\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9950 - val_loss: 0.4800 - val_accuracy: 0.8000\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9967 - val_loss: 0.2726 - val_accuracy: 0.9467\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9958 - val_loss: 0.3365 - val_accuracy: 0.8733\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9983 - val_loss: 0.3715 - val_accuracy: 0.8900\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9975 - val_loss: 0.2079 - val_accuracy: 0.9500\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9958 - val_loss: 0.2264 - val_accuracy: 0.9500\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9992 - val_loss: 0.2809 - val_accuracy: 0.9167\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9992 - val_loss: 0.2025 - val_accuracy: 0.9533\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.2965 - val_accuracy: 0.9033\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9992 - val_loss: 0.1744 - val_accuracy: 0.9767\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9983 - val_loss: 0.2409 - val_accuracy: 0.9333\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1663 - val_accuracy: 0.9533\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9600\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.1401 - val_accuracy: 0.9700\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.1988 - val_accuracy: 0.9500\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 1.0395 - val_accuracy: 0.6433\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.6474 - val_accuracy: 0.7667\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 0.1657 - val_accuracy: 0.9733\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.1726 - val_accuracy: 0.9600\n",
      "12/12 [==============================] - 0s 617us/step - loss: 0.0360 - accuracy: 0.9866\n",
      "Fold 3 Test Accuracy: 0.9866310358047485\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 5.0189 - accuracy: 0.1511 - val_loss: 2.6931 - val_accuracy: 0.1900\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.6636 - accuracy: 0.4699 - val_loss: 1.8546 - val_accuracy: 0.4533\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7654 - accuracy: 0.7730 - val_loss: 1.3298 - val_accuracy: 0.5667\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.9023 - val_loss: 1.2016 - val_accuracy: 0.5600\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9566 - val_loss: 0.9056 - val_accuracy: 0.6533\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.9741 - val_loss: 0.9001 - val_accuracy: 0.6133\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.9733 - val_loss: 0.9851 - val_accuracy: 0.6200\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9800 - val_loss: 0.9242 - val_accuracy: 0.6367\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9891 - val_loss: 0.7387 - val_accuracy: 0.7567\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9891 - val_loss: 0.6141 - val_accuracy: 0.7833\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9891 - val_loss: 0.5461 - val_accuracy: 0.8367\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9917 - val_loss: 0.5242 - val_accuracy: 0.8300\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9958 - val_loss: 0.4592 - val_accuracy: 0.8833\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9950 - val_loss: 0.6181 - val_accuracy: 0.7733\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.5670 - val_accuracy: 0.8167\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9950 - val_loss: 0.6753 - val_accuracy: 0.7467\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9983 - val_loss: 0.5532 - val_accuracy: 0.8333\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9975 - val_loss: 0.5236 - val_accuracy: 0.8300\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9975 - val_loss: 0.3397 - val_accuracy: 0.9200\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.3852 - val_accuracy: 0.8833\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.5684 - val_accuracy: 0.7900\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.4798 - val_accuracy: 0.8567\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8633\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.8833\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.9067\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.5584 - val_accuracy: 0.8400\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.6396 - val_accuracy: 0.8267\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.3529 - val_accuracy: 0.9167\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.4288 - val_accuracy: 0.8400\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.5750 - val_accuracy: 0.8067\n",
      "12/12 [==============================] - 0s 832us/step - loss: 0.1204 - accuracy: 0.9599\n",
      "Fold 4 Test Accuracy: 0.9598930478096008\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 1s 4ms/step - loss: 4.8347 - accuracy: 0.2037 - val_loss: 2.6487 - val_accuracy: 0.0367\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2269 - accuracy: 0.6002 - val_loss: 1.7184 - val_accuracy: 0.4100\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8790 - val_loss: 1.4137 - val_accuracy: 0.5367\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.9491 - val_loss: 1.1478 - val_accuracy: 0.5433\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9750 - val_loss: 1.1934 - val_accuracy: 0.6067\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9766 - val_loss: 1.2176 - val_accuracy: 0.5433\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.9858 - val_loss: 1.1065 - val_accuracy: 0.6033\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9917 - val_loss: 0.8510 - val_accuracy: 0.7033\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9917 - val_loss: 0.9217 - val_accuracy: 0.6833\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9950 - val_loss: 0.7045 - val_accuracy: 0.7533\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9933 - val_loss: 0.5534 - val_accuracy: 0.8267\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9950 - val_loss: 0.9274 - val_accuracy: 0.7067\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9975 - val_loss: 0.7683 - val_accuracy: 0.7367\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9950 - val_loss: 0.5834 - val_accuracy: 0.8200\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9958 - val_loss: 0.4250 - val_accuracy: 0.9067\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.4247 - val_accuracy: 0.8933\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.6242 - val_accuracy: 0.8033\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9983 - val_loss: 0.6319 - val_accuracy: 0.8300\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.4042 - val_accuracy: 0.8567\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.5326 - val_accuracy: 0.8500\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.8533\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.2267 - val_accuracy: 0.9300\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.6566 - val_accuracy: 0.8133\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.4784 - val_accuracy: 0.8767\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.4194 - val_accuracy: 0.8833\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3074 - val_accuracy: 0.9067\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.6358 - val_accuracy: 0.8267\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.4302 - val_accuracy: 0.8867\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.7329 - val_accuracy: 0.8000\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8333\n",
      "12/12 [==============================] - 0s 733us/step - loss: 0.1452 - accuracy: 0.9545\n",
      "Fold 5 Test Accuracy: 0.9545454382896423\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.9668805718421936\n",
      "12/12 [==============================] - 0s 660us/step\n",
      "operationnn.ipynb has finished\n"
     ]
    }
   ],
   "source": [
    "if switch_N_0 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_0_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Embeddings\"] = Subject_Out_1_Nor_0_Aut_0_DR_0 # subject_data_full[\"Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationembeddings.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_0_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_0_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_0_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "operationnn.ipynb working\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_emb (InputLayer)      [(None, 768)]             0         \n",
      "                                                                 \n",
      " gaussian_noise_5 (Gaussian  (None, 768)               0         \n",
      " Noise)                                                          \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 256)               196864    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231308 (903.55 KB)\n",
      "Trainable params: 231308 (903.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.9064 - val_loss: 0.3258 - val_accuracy: 0.9033\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.2477 - val_accuracy: 0.9367\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.2272 - val_accuracy: 0.9367\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.9367\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.5193e-04 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9367\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9333\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 4.9701e-04 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.9333\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1312e-04 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9333\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.4333e-04 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9333\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.6563e-04 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 0.9333\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.6691e-04 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9333\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.2796e-04 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9333\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.6834e-04 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.9333\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5994e-04 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9333\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6022e-04 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9333\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5896e-04 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.9333\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0741e-04 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9333\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.0347e-05 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9333\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 9.1445e-05 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9333\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.7092e-04 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9367\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5530e-04 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9367\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2402e-04 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9367\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.5912e-05 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9367\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 5.7050e-05 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9367\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.8542e-05 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9367\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.2611e-05 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9367\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1902e-04 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9367\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.5874e-05 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9367\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.8409e-05 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9367\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 5.1687e-05 - accuracy: 1.0000 - val_loss: 0.2209 - val_accuracy: 0.9367\n",
      "12/12 [==============================] - 0s 803us/step - loss: 0.0725 - accuracy: 0.9867\n",
      "Fold 1 Test Accuracy: 0.9866666793823242\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.9081 - val_loss: 0.3422 - val_accuracy: 0.9033\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9267\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.2628 - val_accuracy: 0.9367\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9567\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9467\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1856e-04 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9467\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9567\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.2011e-04 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.9400\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.5024e-04 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9500\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.1045e-04 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9467\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.6931e-04 - accuracy: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9467\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.7819e-04 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9467\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.1630e-04 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9467\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.8691e-04 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9467\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2264e-04 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9467\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1028e-04 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9467\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2894e-04 - accuracy: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9467\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.6026e-04 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9500\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5369e-04 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9500\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5876e-04 - accuracy: 1.0000 - val_loss: 0.1493 - val_accuracy: 0.9533\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9452e-05 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9533\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0695e-05 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9533\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7.0020e-05 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9533\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.5532e-05 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9533\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.7915e-05 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9533\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.5500e-05 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9533\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4002e-05 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9533\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 4.1830e-05 - accuracy: 1.0000 - val_loss: 0.1680 - val_accuracy: 0.9533\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.5334e-05 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9533\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2929e-05 - accuracy: 1.0000 - val_loss: 0.1696 - val_accuracy: 0.9533\n",
      "12/12 [==============================] - 0s 806us/step - loss: 0.0301 - accuracy: 0.9947\n",
      "Fold 2 Test Accuracy: 0.9946666955947876\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.9032 - val_loss: 0.2852 - val_accuracy: 0.9167\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.2190 - val_accuracy: 0.9300\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1935 - val_accuracy: 0.9333\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.0468e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9433\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.0216e-04 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9333\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.5701e-04 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9333\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1249e-04 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.9433\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.4640e-04 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9400\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 3.1680e-04 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 0.9467\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2752e-04 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9467\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.4010e-04 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9467\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7117e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.8967\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4310e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9033\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.3128e-04 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9400\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.6053e-04 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9400\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.8086e-04 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9333\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.1003e-04 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9367\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.1487e-04 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9367\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.4293e-05 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9367\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.3977e-05 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.9367\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.7849e-04 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9233\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.6533e-05 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9233\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2191e-04 - accuracy: 1.0000 - val_loss: 0.2465 - val_accuracy: 0.9167\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1873e-04 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.9233\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.0510e-05 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9333\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.9107e-04 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9367\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.7483e-04 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9200\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.5465e-05 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9233\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.7866e-04 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9233\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5769e-04 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.9200\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9840\n",
      "Fold 3 Test Accuracy: 0.9839572310447693\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8957 - val_loss: 0.2357 - val_accuracy: 0.9400\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.2125 - val_accuracy: 0.9300\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9400\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9367\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 8.1396e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9500\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.7505e-04 - accuracy: 1.0000 - val_loss: 0.1754 - val_accuracy: 0.9533\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.0086e-04 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9433\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.3762e-04 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9400\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.7825e-04 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9500\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.8235e-04 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9567\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1652e-04 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9567\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.6096e-04 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9533\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.0402e-04 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9533\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4072e-04 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9500\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.3676e-04 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9500\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 5.9083e-04 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9533\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.1940 - val_accuracy: 0.9367\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9925 - val_loss: 0.1180 - val_accuracy: 0.9700\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 0.2257 - val_accuracy: 0.9433\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9967 - val_loss: 0.2394 - val_accuracy: 0.9367\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9200\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7.3919e-04 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.8700\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.0214 - accuracy: 0.9958 - val_loss: 0.3698 - val_accuracy: 0.8700\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.4768 - val_accuracy: 0.8733\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9967 - val_loss: 0.5160 - val_accuracy: 0.8767\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.2975 - val_accuracy: 0.9000\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9983 - val_loss: 0.3407 - val_accuracy: 0.8867\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.2748 - val_accuracy: 0.9200\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9433\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9975 - val_loss: 0.0579 - val_accuracy: 0.9800\n",
      "12/12 [==============================] - 0s 801us/step - loss: 0.0041 - accuracy: 0.9973\n",
      "Fold 4 Test Accuracy: 0.9973261952400208\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8965 - val_loss: 0.3071 - val_accuracy: 0.9167\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 0.3214 - val_accuracy: 0.9100\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.8667\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 9.2334e-04 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.8900\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7.1317e-04 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9067\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6255e-04 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9033\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.6621e-04 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9000\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.5974e-04 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.9033\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.7383e-04 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9033\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 2.1655e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9067\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.4382e-04 - accuracy: 1.0000 - val_loss: 0.3029 - val_accuracy: 0.9033\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8154e-04 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.9067\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2121e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9133\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3144e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9133\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6975e-04 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9167\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2666e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9200\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5667e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9200\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.2256e-04 - accuracy: 1.0000 - val_loss: 0.2591 - val_accuracy: 0.9200\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9200\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.9957e-05 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9200\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2344e-04 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9200\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.3437e-05 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9167\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 8.8357e-05 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9100\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0354e-04 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9133\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9675e-05 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9133\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.9697e-05 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9133\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 7.2257e-05 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9133\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 6.2424e-05 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9167\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 3.6630e-05 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9167\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 3.8956e-05 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9167\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9840\n",
      "Fold 5 Test Accuracy: 0.9839572310447693\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.9893148064613342\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    }
   ],
   "source": [
    "if switch_N_1 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Embeddings\"] = Subject_Out_1_Nor_1_Aut_0_DR_0 # subject_data_full[\"Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationembeddings.ipynb\")\n",
    "    %run $tool_prediction  \n",
    "  \n",
    "    Model_NeNe_Out_1_Nor_1_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "operationnn.ipynb working\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_emb (InputLayer)      [(None, 768)]             0         \n",
      "                                                                 \n",
      " gaussian_noise_10 (Gaussia  (None, 768)               0         \n",
      " nNoise)                                                         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 256)               196864    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231308 (903.55 KB)\n",
      "Trainable params: 231308 (903.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.1331 - accuracy: 0.1763 - val_loss: 2.8174 - val_accuracy: 0.1167\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5584 - accuracy: 0.4946 - val_loss: 1.9764 - val_accuracy: 0.3667\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.7767 - accuracy: 0.7928 - val_loss: 1.5056 - val_accuracy: 0.6733\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.8997 - val_loss: 1.5197 - val_accuracy: 0.4133\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.9507 - val_loss: 1.3662 - val_accuracy: 0.5133\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9649 - val_loss: 1.3184 - val_accuracy: 0.5600\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9808 - val_loss: 0.9573 - val_accuracy: 0.6733\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9858 - val_loss: 1.0192 - val_accuracy: 0.6467\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9858 - val_loss: 0.7985 - val_accuracy: 0.6833\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9950 - val_loss: 0.9361 - val_accuracy: 0.6433\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0472 - accuracy: 0.9908 - val_loss: 0.6140 - val_accuracy: 0.7700\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9942 - val_loss: 0.5463 - val_accuracy: 0.8233\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9983 - val_loss: 0.6934 - val_accuracy: 0.7700\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9958 - val_loss: 0.7377 - val_accuracy: 0.7400\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9992 - val_loss: 0.5897 - val_accuracy: 0.7967\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9983 - val_loss: 0.5577 - val_accuracy: 0.7867\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.3535 - val_accuracy: 0.9067\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9975 - val_loss: 0.6005 - val_accuracy: 0.8067\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0152 - accuracy: 0.9983 - val_loss: 0.4709 - val_accuracy: 0.8733\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8233\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.4132 - val_accuracy: 0.8633\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.3248 - val_accuracy: 0.9067\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.4730 - val_accuracy: 0.8433\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.7933\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.4041 - val_accuracy: 0.8567\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.7900\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8800\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.8233\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.6516 - val_accuracy: 0.7933\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.8733\n",
      "12/12 [==============================] - 0s 663us/step - loss: 0.1342 - accuracy: 0.9627\n",
      "Fold 1 Test Accuracy: 0.9626666903495789\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.0063 - accuracy: 0.1554 - val_loss: 2.2164 - val_accuracy: 0.3933\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.6159 - accuracy: 0.4829 - val_loss: 1.8716 - val_accuracy: 0.3867\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.8037 - val_loss: 1.2948 - val_accuracy: 0.6767\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.9156 - val_loss: 1.5683 - val_accuracy: 0.4633\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9607 - val_loss: 0.9365 - val_accuracy: 0.7433\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.9699 - val_loss: 0.8444 - val_accuracy: 0.7433\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9883 - val_loss: 0.8095 - val_accuracy: 0.6467\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9883 - val_loss: 0.6823 - val_accuracy: 0.7667\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9908 - val_loss: 0.6362 - val_accuracy: 0.8000\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9900 - val_loss: 0.5519 - val_accuracy: 0.8300\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9916 - val_loss: 0.4997 - val_accuracy: 0.8433\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9950 - val_loss: 0.6322 - val_accuracy: 0.7800\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9950 - val_loss: 0.4006 - val_accuracy: 0.8833\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9967 - val_loss: 0.4440 - val_accuracy: 0.8633\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.4127 - val_accuracy: 0.8700\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.4954 - val_accuracy: 0.8433\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9975 - val_loss: 0.3320 - val_accuracy: 0.8967\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.8633\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.3447 - val_accuracy: 0.9033\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 0.9975 - val_loss: 0.7095 - val_accuracy: 0.7567\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.4541 - val_accuracy: 0.8667\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.4606 - val_accuracy: 0.8800\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.8933\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.4381 - val_accuracy: 0.8733\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.5292 - val_accuracy: 0.8433\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5216 - val_accuracy: 0.8567\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.4613 - val_accuracy: 0.8567\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.3691 - val_accuracy: 0.8700\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.8433\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8433\n",
      "12/12 [==============================] - 0s 700us/step - loss: 0.0919 - accuracy: 0.9707\n",
      "Fold 2 Test Accuracy: 0.9706666469573975\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2776 - accuracy: 0.1745 - val_loss: 2.5596 - val_accuracy: 0.1600\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.7103 - accuracy: 0.4491 - val_loss: 2.0833 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.8954 - accuracy: 0.7479 - val_loss: 1.7300 - val_accuracy: 0.5600\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.9082 - val_loss: 1.3587 - val_accuracy: 0.5667\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2287 - accuracy: 0.9524 - val_loss: 1.0409 - val_accuracy: 0.6900\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9750 - val_loss: 0.9016 - val_accuracy: 0.6867\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9775 - val_loss: 0.5351 - val_accuracy: 0.8167\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9841 - val_loss: 0.6508 - val_accuracy: 0.7433\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9933 - val_loss: 0.8114 - val_accuracy: 0.7033\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9950 - val_loss: 0.7703 - val_accuracy: 0.6633\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9950 - val_loss: 0.6050 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9950 - val_loss: 0.5180 - val_accuracy: 0.7800\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9967 - val_loss: 0.8459 - val_accuracy: 0.6633\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9967 - val_loss: 0.5541 - val_accuracy: 0.7833\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.5148 - val_accuracy: 0.8133\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9983 - val_loss: 0.4737 - val_accuracy: 0.8367\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 1.1010 - val_accuracy: 0.6533\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9942 - val_loss: 0.4263 - val_accuracy: 0.8667\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.3231 - val_accuracy: 0.8967\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.4029 - val_accuracy: 0.8467\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 0.9950 - val_loss: 0.4409 - val_accuracy: 0.8500\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.4017 - val_accuracy: 0.8333\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9950 - val_loss: 0.6036 - val_accuracy: 0.7867\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.3887 - val_accuracy: 0.8667\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.6085 - val_accuracy: 0.8033\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8633\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.8567\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.2972 - val_accuracy: 0.9033\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.6805 - val_accuracy: 0.7533\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8667\n",
      "12/12 [==============================] - 0s 634us/step - loss: 0.0528 - accuracy: 0.9840\n",
      "Fold 3 Test Accuracy: 0.9839572310447693\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.3634 - accuracy: 0.2112 - val_loss: 2.3581 - val_accuracy: 0.2733\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.0632 - accuracy: 0.6820 - val_loss: 1.6584 - val_accuracy: 0.5467\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.9249 - val_loss: 1.1470 - val_accuracy: 0.6967\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.9583 - val_loss: 1.2127 - val_accuracy: 0.6433\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9800 - val_loss: 0.9545 - val_accuracy: 0.6567\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9808 - val_loss: 0.9339 - val_accuracy: 0.6900\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9891 - val_loss: 0.7652 - val_accuracy: 0.7400\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.9883 - val_loss: 0.5851 - val_accuracy: 0.8033\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9950 - val_loss: 0.6181 - val_accuracy: 0.8033\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9925 - val_loss: 0.6331 - val_accuracy: 0.7700\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 0.9925 - val_loss: 0.4742 - val_accuracy: 0.8500\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9958 - val_loss: 0.8042 - val_accuracy: 0.7300\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9983 - val_loss: 0.7462 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.5378 - val_accuracy: 0.8233\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.6288 - val_accuracy: 0.8033\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.7933\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.9956 - val_accuracy: 0.6800\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.9393 - val_accuracy: 0.7333\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.5625 - val_accuracy: 0.8467\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.5237 - val_accuracy: 0.7967\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5787 - val_accuracy: 0.8000\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.8054 - val_accuracy: 0.7033\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.5072 - val_accuracy: 0.8367\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9958 - val_loss: 0.3667 - val_accuracy: 0.8967\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.5676 - val_accuracy: 0.8200\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 0.9992 - val_loss: 0.6433 - val_accuracy: 0.7833\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.6529 - val_accuracy: 0.8033\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.8024 - val_accuracy: 0.7200\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9000\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8767\n",
      "12/12 [==============================] - 0s 684us/step - loss: 0.0683 - accuracy: 0.9786\n",
      "Fold 4 Test Accuracy: 0.9786096215248108\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.3875 - accuracy: 0.1694 - val_loss: 2.1874 - val_accuracy: 0.2167\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4791 - accuracy: 0.5217 - val_loss: 2.0989 - val_accuracy: 0.3067\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.7963 - val_loss: 1.6675 - val_accuracy: 0.4533\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.9282 - val_loss: 1.3352 - val_accuracy: 0.5933\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.9541 - val_loss: 1.3587 - val_accuracy: 0.5167\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9708 - val_loss: 0.9150 - val_accuracy: 0.7233\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9674 - val_loss: 0.9841 - val_accuracy: 0.6633\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9891 - val_loss: 0.8107 - val_accuracy: 0.7300\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9875 - val_loss: 1.1153 - val_accuracy: 0.6133\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9891 - val_loss: 0.6785 - val_accuracy: 0.7633\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9983 - val_loss: 0.9017 - val_accuracy: 0.6200\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.6048 - val_accuracy: 0.8033\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9975 - val_loss: 0.8529 - val_accuracy: 0.7033\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 0.9992 - val_loss: 0.8632 - val_accuracy: 0.6733\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9983 - val_loss: 1.2473 - val_accuracy: 0.6067\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.9566 - val_accuracy: 0.6533\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9983 - val_loss: 0.7245 - val_accuracy: 0.7533\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.8067\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.6011 - val_accuracy: 0.8067\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9967 - val_loss: 0.5953 - val_accuracy: 0.7833\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 2.1989 - val_accuracy: 0.4467\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9858 - val_loss: 0.4158 - val_accuracy: 0.8600\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9992 - val_loss: 0.6401 - val_accuracy: 0.8100\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.5470 - val_accuracy: 0.8300\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.2770 - val_accuracy: 0.9033\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8200\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.5356 - val_accuracy: 0.8533\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.8867\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.8833\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.8600\n",
      "12/12 [==============================] - 0s 550us/step - loss: 0.1072 - accuracy: 0.9679\n",
      "Fold 5 Test Accuracy: 0.9679144620895386\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.972762930393219\n",
      "12/12 [==============================] - 0s 506us/step\n",
      "operationnn.ipynb has finished\n"
     ]
    }
   ],
   "source": [
    "if switch_N_2 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_0 # subject_data_full[\"Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationembeddings.ipynb\")\n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0              = encoder\n",
    "    \n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "operationnn.ipynb working\n",
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_emb (InputLayer)      [(None, 768)]             0         \n",
      "                                                                 \n",
      " gaussian_noise_15 (Gaussia  (None, 768)               0         \n",
      " nNoise)                                                         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 256)               196864    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 231308 (903.55 KB)\n",
      "Trainable params: 231308 (903.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.6663 - accuracy: 0.1896 - val_loss: 2.1227 - val_accuracy: 0.4433\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.3339 - accuracy: 0.5673 - val_loss: 1.8465 - val_accuracy: 0.4933\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.8429 - val_loss: 1.2849 - val_accuracy: 0.6900\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9265 - val_loss: 0.8707 - val_accuracy: 0.7167\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9683 - val_loss: 0.7773 - val_accuracy: 0.7533\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.9749 - val_loss: 0.5056 - val_accuracy: 0.8367\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9850 - val_loss: 0.6520 - val_accuracy: 0.7567\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9808 - val_loss: 1.1496 - val_accuracy: 0.6533\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9875 - val_loss: 0.5670 - val_accuracy: 0.8200\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9967 - val_loss: 0.5665 - val_accuracy: 0.8300\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0313 - accuracy: 0.9975 - val_loss: 0.7756 - val_accuracy: 0.6800\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9942 - val_loss: 0.6143 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.4742 - val_accuracy: 0.8467\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9975 - val_loss: 0.3494 - val_accuracy: 0.9067\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9967 - val_loss: 0.4569 - val_accuracy: 0.8500\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9975 - val_loss: 0.3678 - val_accuracy: 0.9100\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9958 - val_loss: 0.2523 - val_accuracy: 0.9367\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9975 - val_loss: 0.4328 - val_accuracy: 0.8567\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.3676 - val_accuracy: 0.8867\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.1883 - val_accuracy: 0.9600\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.4106 - val_accuracy: 0.8500\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.2663 - val_accuracy: 0.9200\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.4005 - val_accuracy: 0.8667\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 0.3300 - val_accuracy: 0.9100\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9033\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9300\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 1.1230 - val_accuracy: 0.7800\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.2287 - val_accuracy: 0.9300\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.8967\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9133\n",
      "12/12 [==============================] - 0s 878us/step - loss: 0.0978 - accuracy: 0.9787\n",
      "Fold 1 Test Accuracy: 0.9786666631698608\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 4.5006 - accuracy: 0.1838 - val_loss: 1.9794 - val_accuracy: 0.3500\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.3617 - accuracy: 0.5422 - val_loss: 1.5679 - val_accuracy: 0.5700\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.8421 - val_loss: 1.3162 - val_accuracy: 0.5467\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.9323 - val_loss: 1.0643 - val_accuracy: 0.5933\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9666 - val_loss: 0.9198 - val_accuracy: 0.7467\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9799 - val_loss: 0.9624 - val_accuracy: 0.6267\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.9866 - val_loss: 0.7728 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0664 - accuracy: 0.9850 - val_loss: 0.5968 - val_accuracy: 0.7700\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9916 - val_loss: 0.6900 - val_accuracy: 0.7367\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9942 - val_loss: 0.6725 - val_accuracy: 0.7700\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9958 - val_loss: 0.6062 - val_accuracy: 0.7833\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9925 - val_loss: 0.7968 - val_accuracy: 0.7033\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 0.9983 - val_loss: 0.4721 - val_accuracy: 0.8333\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9933 - val_loss: 0.5418 - val_accuracy: 0.8200\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9992 - val_loss: 0.5361 - val_accuracy: 0.8233\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.3158 - val_accuracy: 0.9067\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9992 - val_loss: 0.3758 - val_accuracy: 0.8800\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.3286 - val_accuracy: 0.8967\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.3839 - val_accuracy: 0.8767\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9167\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.3718 - val_accuracy: 0.8867\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.4400 - val_accuracy: 0.8400\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0148 - accuracy: 0.9992 - val_loss: 0.4247 - val_accuracy: 0.8500\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.4116 - val_accuracy: 0.8600\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.8667\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.8567\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9100\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9600\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.1718 - val_accuracy: 0.9733\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.2880 - val_accuracy: 0.9033\n",
      "12/12 [==============================] - 0s 712us/step - loss: 0.0596 - accuracy: 0.9813\n",
      "Fold 2 Test Accuracy: 0.981333315372467\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5895 - accuracy: 0.1661 - val_loss: 2.3323 - val_accuracy: 0.1367\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.5849 - accuracy: 0.4891 - val_loss: 1.9010 - val_accuracy: 0.2800\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.8139 - val_loss: 1.5396 - val_accuracy: 0.4967\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.3066 - accuracy: 0.9391 - val_loss: 1.4852 - val_accuracy: 0.5333\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9683 - val_loss: 0.8691 - val_accuracy: 0.7300\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9766 - val_loss: 0.8838 - val_accuracy: 0.7300\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9833 - val_loss: 0.8734 - val_accuracy: 0.6500\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0540 - accuracy: 0.9900 - val_loss: 0.7843 - val_accuracy: 0.7400\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9942 - val_loss: 0.4820 - val_accuracy: 0.8767\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9933 - val_loss: 0.8612 - val_accuracy: 0.7000\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9983 - val_loss: 0.5052 - val_accuracy: 0.8400\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9967 - val_loss: 0.7235 - val_accuracy: 0.7567\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9992 - val_loss: 0.3231 - val_accuracy: 0.9233\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.3505 - val_accuracy: 0.9033\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9992 - val_loss: 0.8776 - val_accuracy: 0.6833\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9992 - val_loss: 0.6970 - val_accuracy: 0.7867\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.3043 - val_accuracy: 0.9200\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.4175 - val_accuracy: 0.8833\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.6899 - val_accuracy: 0.7900\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.5213 - val_accuracy: 0.8167\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.6715 - val_accuracy: 0.7633\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.8667\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9100\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.8600\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.2919 - val_accuracy: 0.9200\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.2662 - val_accuracy: 0.9367\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.8967\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.8967\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9367\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9167\n",
      "12/12 [==============================] - 0s 624us/step - loss: 0.0527 - accuracy: 0.9840\n",
      "Fold 3 Test Accuracy: 0.9839572310447693\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.2590 - accuracy: 0.1603 - val_loss: 2.4762 - val_accuracy: 0.1400\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 1.4435 - accuracy: 0.5367 - val_loss: 2.1854 - val_accuracy: 0.2867\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.8431 - val_loss: 1.4627 - val_accuracy: 0.6167\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.9274 - val_loss: 1.1778 - val_accuracy: 0.6933\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9658 - val_loss: 0.7645 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9758 - val_loss: 0.6765 - val_accuracy: 0.7900\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.9883 - val_loss: 1.0716 - val_accuracy: 0.6333\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9883 - val_loss: 1.0526 - val_accuracy: 0.6400\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9917 - val_loss: 0.8481 - val_accuracy: 0.6933\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9933 - val_loss: 0.9342 - val_accuracy: 0.6900\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9958 - val_loss: 0.7592 - val_accuracy: 0.7467\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0323 - accuracy: 0.9942 - val_loss: 0.7402 - val_accuracy: 0.7367\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9983 - val_loss: 0.6970 - val_accuracy: 0.7800\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 0.6248 - val_accuracy: 0.8267\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9958 - val_loss: 0.8761 - val_accuracy: 0.7167\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.4747 - val_accuracy: 0.8367\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.7391 - val_accuracy: 0.7800\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.7833\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.8333\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.6151 - val_accuracy: 0.8033\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.8133\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 0.6882 - val_accuracy: 0.8133\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.3585 - val_accuracy: 0.8900\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.3422 - val_accuracy: 0.8967\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.3661 - val_accuracy: 0.9133\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.6134 - val_accuracy: 0.8200\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.3363 - val_accuracy: 0.8800\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.3384 - val_accuracy: 0.9100\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.8800\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.8900\n",
      "12/12 [==============================] - 0s 542us/step - loss: 0.0787 - accuracy: 0.9786\n",
      "Fold 4 Test Accuracy: 0.9786096215248108\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.5309 - accuracy: 0.1578 - val_loss: 2.1619 - val_accuracy: 0.1767\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 1.4847 - accuracy: 0.5259 - val_loss: 2.1792 - val_accuracy: 0.3000\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.8347 - val_loss: 1.2858 - val_accuracy: 0.6133\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.2799 - accuracy: 0.9391 - val_loss: 1.0031 - val_accuracy: 0.6867\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.9725 - val_loss: 1.1029 - val_accuracy: 0.5600\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9783 - val_loss: 1.1842 - val_accuracy: 0.5500\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9825 - val_loss: 1.0663 - val_accuracy: 0.5300\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9900 - val_loss: 0.9350 - val_accuracy: 0.6467\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9933 - val_loss: 0.7533 - val_accuracy: 0.7200\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9958 - val_loss: 0.9649 - val_accuracy: 0.5967\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9950 - val_loss: 0.7835 - val_accuracy: 0.7100\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9950 - val_loss: 0.7098 - val_accuracy: 0.7400\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 0.9983 - val_loss: 0.6309 - val_accuracy: 0.8067\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9975 - val_loss: 0.5354 - val_accuracy: 0.8167\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.8800\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.5700 - val_accuracy: 0.8100\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8467\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.7508 - val_accuracy: 0.7533\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.3552 - val_accuracy: 0.8967\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8500\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.3227 - val_accuracy: 0.9167\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.4215 - val_accuracy: 0.8533\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.2917 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8400\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.3120 - val_accuracy: 0.9100\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.8667\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.2406 - val_accuracy: 0.9233\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.8900\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.6812 - val_accuracy: 0.7533\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.6277 - val_accuracy: 0.8067\n",
      "12/12 [==============================] - 0s 639us/step - loss: 0.1450 - accuracy: 0.9519\n",
      "Fold 5 Test Accuracy: 0.9518716335296631\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.9748876929283142\n",
      "12/12 [==============================] - 0s 573us/step\n",
      "operationnn.ipynb has finished\n",
      "Out_1_Nor_1_Aut_1_DR_1\n"
     ]
    }
   ],
   "source": [
    "if switch_N_3 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_1\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_1 # subject_data_full[\"Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationembeddings.ipynb\")\n",
    "    %run $tool_prediction  \n",
    "\n",
    "    print(f\"{subject_label}\")\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_1                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_1          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_1  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1- `Operation: SVM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [-0.1713259220123291, -0.1984623372554779, -0....\n",
       "1     [-0.014635225757956505, -0.4390987753868103, -...\n",
       "2     [-0.035851024091243744, -0.4263487756252289, 0...\n",
       "3     [-0.05883532762527466, -0.35421204566955566, -...\n",
       "4     [-0.37293335795402527, -0.4042693078517914, 0....\n",
       "                            ...                        \n",
       "51    [0.06260330975055695, -0.4410420358181, 0.4309...\n",
       "52    [0.05649421736598015, -0.3864367604255676, 0.3...\n",
       "53    [0.03859759122133255, -0.3970209062099457, 0.4...\n",
       "54    [0.13350529968738556, -0.4641953706741333, 0.3...\n",
       "55    [0.05018668249249458, -0.3949635326862335, 0.2...\n",
       "Name: Embeddings, Length: 1872, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subject_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_0 == 1: \n",
    "    SVM_Dict_Out_1_Nor_0_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                 y_Cell_Type              = Cell_Type, \n",
    "                                                 subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\", \n",
    "                                                 subject_outlier          = subject_outlier, \n",
    "                                                 subject_normalization    = subject_normalization, \n",
    "                                                 subject_autoencoder      = subject_autoencoder, \n",
    "                                                 subject_dimension        = subject_dimension,\n",
    "                                                 data_source = \"one\" )\n",
    "    Model_SVM_Out_1_Nor_0_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_0_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_0_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_0_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_1 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension ,\n",
    "                                           data_source = \"one\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_2 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"one\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_3 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_1 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"one\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_1                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_1          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_1  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_1           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2- `Operation: SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_0 == 1: \n",
    "    SGD_Dict_Out_1_Nor_0_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                    y_Cell_Type           = Cell_Type,\n",
    "                                                    subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                    subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"one\" )  \n",
    "    Model_SGD_Out_1_Nor_0_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_0_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_0_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_0_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_1 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"one\" )  \n",
    "    Model_SGD_Out_1_Nor_1_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"one\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_1 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension,\n",
    "                                                        data_source = \"one\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_1                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_1          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_1  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_1           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3- `Operation: Random Forest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_RF_0 == 1: \n",
    "    RF_Dict_Out_1_Nor_0_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"one\" )    \n",
    "    Model_RF_Out_1_Nor_0_Aut_0_DR_0                = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_0_Aut_0_DR_0          = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_0_Aut_0_DR_0  = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_0_Aut_0_DR_0           = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_RF_1 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension, \n",
    "                                                data_source = \"one\" )  \n",
    "    Model_RF_Out_1_Nor_1_Aut_0_DR_0                = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_0_DR_0          = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_0_DR_0  = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_0_DR_0           = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"one\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_0                = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_0          = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_0  = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_0           = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_1 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"one\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_1                = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_1          = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_1  = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_1           = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4- `Operation: Decision Tree`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_DT_0 == 1: \n",
    "    DT_Dict_Out_1_Nor_0_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                        subject_outlier       = subject_outlier, \n",
    "                                        subject_normalization = subject_normalization, \n",
    "                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                        subject_dimension     = subject_dimension,\n",
    "                                        data_source = \"one\" )   \n",
    "    Model_DT_Out_1_Nor_0_Aut_0_DR_0                = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_0_Aut_0_DR_0          = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_0_Aut_0_DR_0  = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_0_Aut_0_DR_0           = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_DT_1 == 1: \n",
    "  DT_Dict_Out_1_Nor_1_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                            subject_normalization = subject_normalization, \n",
    "                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                            subject_dimension     = subject_dimension,\n",
    "                                            data_source = \"one\" )   \n",
    "  Model_DT_Out_1_Nor_1_Aut_0_DR_0                = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "  Predictions_DT_Out_1_Nor_1_Aut_0_DR_0          = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "  Statistics_Detailed_DT_Out_1_Nor_1_Aut_0_DR_0  = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "  Statistics_DT_Out_1_Nor_1_Aut_0_DR_0           = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_DT_2 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"one\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_0                = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_0          = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_0  = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_0           = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Way A.2\n"
     ]
    }
   ],
   "source": [
    "if switch_DT_3 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_1 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"one\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_1                = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_1          = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_1  = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_1           = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5- `Operation: Gradient Boosting`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_0 == 1: \n",
    "    GB_Dict_Out_1_Nor_0_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier, \n",
    "                                                            subject_normalization = subject_normalization, \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension,\n",
    "                                                            data_source = \"one\" )    \n",
    "    Model_GB_Out_1_Nor_0_Aut_0_DR_0                = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_0_Aut_0_DR_0          = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_0_Aut_0_DR_0  = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_0_Aut_0_DR_0           = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_1 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier,\n",
    "                                                            subject_normalization = subject_normalization,  \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension, \n",
    "                                                            data_source = \"one\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_0_DR_0                = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_0_DR_0          = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_0_DR_0  = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_0_DR_0           = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_2 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"one\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_0                = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_0          = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_0  = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_0           = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_3 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_1 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"one\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_1                = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_1          = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_1  = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_1           = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4- `Operation: Combine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-) `Statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All = pd.DataFrame() \n",
    "if switch_N_0 == 1: \n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0], axis = 0) \n",
    "if switch_N_1 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0], axis = 0)\n",
    "if switch_N_2 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0], axis = 0) \n",
    "if switch_N_3 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1], axis = 0) \n",
    "\n",
    "SVM_All = pd.DataFrame() \n",
    "if switch_SVM_0 == 1: \n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "if switch_SVM_1 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SVM_2 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "if switch_SVM_3 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0) \n",
    "\n",
    "SGD_All = pd.DataFrame()\n",
    "if switch_SGD_0 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_1 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_2 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_3 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "DT_All = pd.DataFrame() \n",
    "if switch_DT_0 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_1 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_2 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_3 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "\n",
    "RF_All = pd.DataFrame()\n",
    "if switch_RF_0 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_1 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_2 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_3 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "\n",
    "GB_All = pd.DataFrame()\n",
    "if switch_GB_0 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_1 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_2 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_3 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) `Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All_Models = []\n",
    "NN_All_Encoders = [] \n",
    "if switch_N_0 == 1: \n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_0_Aut_0_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0)\n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_N_1 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_0_DR_0)\n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_N_2 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0)\n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_N_3 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_1\")  \n",
    "\n",
    "NN_All_Models_Dict = {} \n",
    "for i in range(len(NN_All_Models)):\n",
    "    NN_All_Models_Dict[f\"Model_{i}\"] = NN_All_Models[i] \n",
    "\n",
    "NN_All_Encoders_Dict = {}\n",
    "for i in range(len(NN_All_Encoders)):\n",
    "    NN_All_Encoders_Dict[f\"Encoder_{i}\"] = NN_All_Encoders[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_All_Models = []\n",
    "if switch_SVM_0 == 1: \n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_SVM_1 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SVM_2 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SVM_3 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "SVM_All_Models_Dict = {} \n",
    "for i in range(len(SVM_All_Models)):\n",
    "    SVM_All_Models_Dict[f\"Model_{i}\"] = SVM_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_All_Models = []\n",
    "if switch_SGD_0 == 1: \n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_SGD_1 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SGD_2 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SGD_3 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "SGD_All_Models_Dict = {} \n",
    "for i in range(len(SGD_All_Models)):\n",
    "    SGD_All_Models_Dict[f\"Model_{i}\"] = SGD_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_All_Models = []\n",
    "if switch_DT_0 == 1: \n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_DT_1 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_0_DR_0\")  \n",
    "if switch_DT_2 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "if switch_DT_3 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "DT_All_Models_Dict = {} \n",
    "for i in range(len(DT_All_Models)):\n",
    "    DT_All_Models_Dict[f\"Model_{i}\"] = DT_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_All_Models = []\n",
    "if switch_RF_0 == 1: \n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_RF_1 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_RF_2 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_1_DR_0\") \n",
    "if switch_RF_3 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "RF_All_Models_Dict = {} \n",
    "for i in range(len(RF_All_Models)):\n",
    "    RF_All_Models_Dict[f\"Model_{i}\"] = RF_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_All_Models = []\n",
    "if switch_GB_0 == 1:\n",
    "    try: \n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_GB_1 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_GB_2 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_0\") \n",
    "\n",
    "if switch_GB_3 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "GB_All_Models_Dict = {} \n",
    "for i in range(len(GB_All_Models)):\n",
    "    GB_All_Models_Dict[f\"Model_{i}\"] = GB_All_Models[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-) `Report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject Outlier: Free_v0\n",
      "Subject Normalization: StandardScaler\n",
      "Subject Autoencoder: Free_v0\n",
      "Subject Dimension: Free_v0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subject Outlier: {subject_outlier}\")\n",
    "print(f\"Subject Normalization: {subject_normalization}\") \n",
    "print(f\"Subject Autoencoder: {subject_autoencoder}\")\n",
    "print(f\"Subject Dimension: {subject_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.986631</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.983910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.967914</td>\n",
       "      <td>0.975892</td>\n",
       "      <td>0.967914</td>\n",
       "      <td>0.968274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.955651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.966941</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.952049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.933154</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.928680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.933154</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.928680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.933154</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.928680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.933154</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.928680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.942284</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.926168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.942284</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.926168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.942284</td>\n",
       "      <td>0.925333</td>\n",
       "      <td>0.926168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.588382</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.437347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.588382</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.437347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.588382</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.437347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Applications       Applications_Condition Model  \\\n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_0_DR_0   SGD   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_0_DR_0   SVM   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_1    RF   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_0    RF   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_0_DR_0    RF   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_0_Aut_0_DR_0    RF   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_1    DT   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_0    DT   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_0_DR_0    DT   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_0_Aut_0_DR_0    DT   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_0_Aut_0_DR_0   SGD   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_0   SGD   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_1   SGD   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_1   SVM   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_1_Aut_1_DR_0   SVM   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0       Out_1_Nor_0_Aut_0_DR_0   SVM   \n",
       "\n",
       "                                          Parameters  Accuracy  Precision  \\\n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  1.000000   1.000000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  1.000000   1.000000   \n",
       "0                                              Basic  1.000000   1.000000   \n",
       "0                                              Basic  1.000000   1.000000   \n",
       "0                                              Basic  1.000000   1.000000   \n",
       "0                                              Basic  1.000000   1.000000   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.983957   0.986631   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.967914   0.975892   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.954545   0.969529   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.951872   0.966941   \n",
       "0                                              Basic  0.928000   0.933154   \n",
       "0                                              Basic  0.928000   0.933154   \n",
       "0                                              Basic  0.928000   0.933154   \n",
       "0                                              Basic  0.928000   0.933154   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  0.925333   0.942284   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  0.925333   0.942284   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  0.925333   0.942284   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  0.480000   0.588382   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  0.480000   0.588382   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  0.480000   0.588382   \n",
       "\n",
       "     Recall        F1  \n",
       "0  1.000000  1.000000  \n",
       "0  1.000000  1.000000  \n",
       "0  1.000000  1.000000  \n",
       "0  1.000000  1.000000  \n",
       "0  1.000000  1.000000  \n",
       "0  1.000000  1.000000  \n",
       "0  0.983957  0.983910  \n",
       "0  0.967914  0.968274  \n",
       "0  0.954545  0.955651  \n",
       "0  0.951872  0.952049  \n",
       "0  0.928000  0.928680  \n",
       "0  0.928000  0.928680  \n",
       "0  0.928000  0.928680  \n",
       "0  0.928000  0.928680  \n",
       "0  0.925333  0.926168  \n",
       "0  0.925333  0.926168  \n",
       "0  0.925333  0.926168  \n",
       "0  0.480000  0.437347  \n",
       "0  0.480000  0.437347  \n",
       "0  0.480000  0.437347  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data = pd.concat([NN_All, SVM_All, DT_All, RF_All, GB_All, SGD_All], axis=0) \n",
    "All_Data.sort_values(by = [\"F1\"], ascending= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6- `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"data_raw\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(data_raw, file)   \n",
    "\n",
    "export_name = \"subject_data_full\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_data_full, file)   \n",
    "\n",
    "    \n",
    "export_name = \"subject_outlier\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier, file)   \n",
    "\n",
    "\n",
    "export_name = \"subject_normalization\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization, file)   \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_autoencoder\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder, file) \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_dimension\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension, file)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.955651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.986631</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.983910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.967914</td>\n",
       "      <td>0.975892</td>\n",
       "      <td>0.967914</td>\n",
       "      <td>0.968274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Free_v0_Free_v0_StandardScaler_Free_v0</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.966941</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.952049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Applications       Applications_Condition Model  \\\n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "0  Free_v0_Free_v0_StandardScaler_Free_v0  Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "\n",
       "                                          Parameters  Accuracy  Precision  \\\n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.954545   0.969529   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.983957   0.986631   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.967914   0.975892   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.951872   0.966941   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.954545  0.955651  \n",
       "0  0.983957  0.983910  \n",
       "0  0.967914  0.968274  \n",
       "0  0.951872  0.952049  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN\n",
    "export_name = \"NN_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All, file)\n",
    "\n",
    "# --------------------\n",
    "# GB\n",
    "export_name = \"GB_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Models, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All_Models, file) \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All_Models, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "# GB\n",
    "export_name = \"GB_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All_Models, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Encoders\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Encoders, file) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
