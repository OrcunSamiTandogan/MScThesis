{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section is bypassed as autoencoder models are worked so fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  \n",
    "\n",
    "# Dimension Reduction \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduct_dimension(target_embeddings_matrix, label_embeddings_matrix, subject_dimension_reduction): \n",
    "\n",
    "\n",
    "    if subject_dimension_reduction[:3] == \"PCA\": # Eg. PCA_n2 \n",
    "        n_components = int(subject_dimension_reduction.split(\"_n\")[1]) \n",
    "        print(f\"PCA: {n_components}\") \n",
    "        pca = PCA(n_components) \n",
    "            \n",
    "        # Target \n",
    "        target_embeddings_matrix = pca.fit_transform(target_embeddings_matrix) \n",
    "        print(f\"PCA: {target_embeddings_matrix.shape}\") \n",
    "        print(f\"PCA: {pca.explained_variance_ratio_}\") \n",
    "        print(f\"PCA: {pca.explained_variance_ratio_.sum()}\") \n",
    "        \n",
    "        \n",
    "        # Bypass Label \n",
    "        if label_embeddings_matrix == None:\n",
    "            return target_embeddings_matrix, None \n",
    "        \n",
    "        # Label \n",
    "        label_embeddings_matrix = pca.transform(label_embeddings_matrix) if label_embeddings_matrix is not None else [len(target_embeddings_matrix) * [0]] \n",
    "        \n",
    "        return target_embeddings_matrix, label_embeddings_matrix  \n",
    "\n",
    "\n",
    "    elif subject_dimension_reduction[:4] == \"TSNE\": # TSNE_nc2_p5_lr3 \n",
    "        # Extract Components \n",
    "        n_components = int(subject_dimension_reduction.split(\"_nc\")[1].split(\"_\")[0])\n",
    "        perplexity   = int(subject_dimension_reduction.split(\"_p\")[1].split(\"_\")[0])\n",
    "        learning_rate = int(subject_dimension_reduction.split(\"_lr\")[1].split(\"_\")[0]) \n",
    "        print(f\"TSNE: {n_components}, {perplexity}, {learning_rate}\")\n",
    "\n",
    "        # Preprocess: Matrix \n",
    "        if label_embeddings_matrix is not None:\n",
    "            combined_matrix = np.vstack((target_embeddings_matrix, label_embeddings_matrix))\n",
    "        else:\n",
    "            combined_matrix = target_embeddings_matrix \n",
    "\n",
    "        # Reduction\n",
    "        tsne = TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate, random_state=42, init='random')\n",
    "        # Target \n",
    "        transformed_combined_matrix = tsne.fit_transform(combined_matrix)\n",
    "\n",
    "        # Split the transformed combined matrix back into target and label matrices\n",
    "        if label_embeddings_matrix is not None:\n",
    "            transformed_target_matrix = transformed_combined_matrix[:len(target_embeddings_matrix)]\n",
    "            transformed_label_matrix = transformed_combined_matrix[len(target_embeddings_matrix):]\n",
    "        else:\n",
    "            transformed_target_matrix = transformed_combined_matrix\n",
    "            transformed_label_matrix = None  # or an appropriate placeholder if needed\n",
    "\n",
    "        # Target \n",
    "        target_embeddings_matrix = transformed_target_matrix \n",
    "        # Label \n",
    "        label_embeddings_matrix = transformed_label_matrix \n",
    "\n",
    "        return target_embeddings_matrix, label_embeddings_matrix  \n",
    "\n",
    "\n",
    "    elif subject_dimension_reduction[:4] == \"UMAP\": # Eg. UMAP_nc3_nn60_min05\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            # System \n",
    "            warnings.filterwarnings(\"ignore\", message=\"n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
    "            # Extraction of components \n",
    "            n_components = int(subject_dimension_reduction.split(\"_nc\")[1].split(\"_\")[0]) \n",
    "            n_neighbors  = int(subject_dimension_reduction.split(\"_nn\")[1].split(\"_\")[0]) \n",
    "            min_dist     = str(subject_dimension_reduction.split(\"_min\")[1]) \n",
    "            min_dist     = \"0\" + \".\" + min_dist[1] \n",
    "            min_dist     = float(min_dist) \n",
    "            print(f\"UMAP: {n_components}, {n_neighbors}, {min_dist}\") \n",
    "\n",
    "            # Target \n",
    "            umap_reducer  = UMAP(n_components = n_components, n_neighbors = n_neighbors, min_dist = min_dist, random_state = 42)\n",
    "            target_embeddings_matrix = umap_reducer.fit_transform(target_embeddings_matrix) \n",
    "            print(f\"UMAP: {target_embeddings_matrix.shape}\")\n",
    "\n",
    "\n",
    "            # Label \n",
    "            if label_embeddings_matrix is not None: \n",
    "                label_embeddings_matrix = umap_reducer.transform(label_embeddings_matrix) if label_embeddings_matrix is not None else [len(target_embeddings_matrix) * [0]]  \n",
    "            else:\n",
    "                label_embeddings_matrix = None \n",
    "\n",
    "        return target_embeddings_matrix, label_embeddings_matrix \n",
    "    \n",
    "    else:\n",
    "        print(\"No dimension reduction method selected\")\n",
    "        return target_embeddings_matrix, label_embeddings_matrix  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
