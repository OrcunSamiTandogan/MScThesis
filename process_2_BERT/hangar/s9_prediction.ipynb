{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 7: Predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n",
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n",
      "Length: 50\n",
      "Unique Cell Types: 5\n",
      "Unique Gene Markers: 50\n",
      "--------------------\n",
      "Subject Outlier 0 (Embedding): ZScore_v0\n",
      "Subject Outlier 1 (Expression): ZScore_v0\n",
      "Subject_Outlier: ZScore_v0_ZScore_v0\n",
      "Subject normalization 0 (Embedding): StandardScaler\n",
      "Subject normalization 1 (Expression): StandardScaler\n",
      "Subject Autoencoder 0 (Embedding): Basic_v1\n",
      "Subject Autoencoder 1 (Expression): Basic_v1\n",
      "Subject Dimension Reduction 0 (Embedding): PCA_n3\n",
      "Subject Dimension Reduction 1 (Expression): Free\n",
      "--------------------\n",
      "Tools of ML: Complex\n",
      "Machine Learning Models: Basic\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "except: \n",
    "    %run s0_config.ipynb \n",
    "    %run s8_preparation.ipynb \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3- `Bench`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0- `Operation: Neural Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 1536)]               0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNo  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " ise)                                                                                             \n",
      "                                                                                                  \n",
      " gaussian_noise_1 (Gaussian  (None, 1536)                 0         ['input_emb[0][0]']           \n",
      " Noise)                                                                                           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   128       ['gaussian_noise[0][0]']      \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  393472    ['gaussian_noise_1[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   2080      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 160)                  0         ['dense_1[0][0]',             \n",
      "                                                                     'dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 5)                    805       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 429381 (1.64 MB)\n",
      "Trainable params: 429381 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 1.6867 - accuracy: 0.0312 - val_loss: 1.4245 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6125 - accuracy: 0.0938 - val_loss: 1.4863 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5870 - accuracy: 0.3125 - val_loss: 1.5522 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5786 - accuracy: 0.2188 - val_loss: 1.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5413 - accuracy: 0.2500 - val_loss: 1.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4653 - accuracy: 0.4062 - val_loss: 1.7691 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4926 - accuracy: 0.2812 - val_loss: 1.8481 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4452 - accuracy: 0.3438 - val_loss: 1.9296 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4119 - accuracy: 0.4062 - val_loss: 2.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3634 - accuracy: 0.4688 - val_loss: 2.1011 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3666 - accuracy: 0.5000 - val_loss: 2.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3992 - accuracy: 0.4062 - val_loss: 2.2840 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3563 - accuracy: 0.4062 - val_loss: 2.3829 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3020 - accuracy: 0.4062 - val_loss: 2.4864 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3339 - accuracy: 0.4688 - val_loss: 2.5931 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2811 - accuracy: 0.4375 - val_loss: 2.7045 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3007 - accuracy: 0.5000 - val_loss: 2.8162 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2916 - accuracy: 0.4375 - val_loss: 2.9284 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2965 - accuracy: 0.4062 - val_loss: 3.0416 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2800 - accuracy: 0.3438 - val_loss: 3.1552 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2378 - accuracy: 0.5625 - val_loss: 3.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2104 - accuracy: 0.5312 - val_loss: 3.3840 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2134 - accuracy: 0.5938 - val_loss: 3.4990 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2129 - accuracy: 0.5000 - val_loss: 3.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.2605 - accuracy: 0.4375 - val_loss: 3.7209 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1475 - accuracy: 0.6250 - val_loss: 3.8293 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.1348 - accuracy: 0.6562 - val_loss: 3.9374 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1200 - accuracy: 0.6562 - val_loss: 4.0428 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1581 - accuracy: 0.5938 - val_loss: 4.1464 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1507 - accuracy: 0.6250 - val_loss: 4.2478 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7470 - accuracy: 0.7000\n",
      "Fold 1 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 1.7602 - accuracy: 0.0312 - val_loss: 1.4440 - val_accuracy: 0.8750\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6932 - accuracy: 0.1875 - val_loss: 1.4980 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6406 - accuracy: 0.2812 - val_loss: 1.5500 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6018 - accuracy: 0.2500 - val_loss: 1.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6473 - accuracy: 0.2500 - val_loss: 1.6610 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5637 - accuracy: 0.3125 - val_loss: 1.7195 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5384 - accuracy: 0.2812 - val_loss: 1.7797 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4802 - accuracy: 0.3438 - val_loss: 1.8411 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4833 - accuracy: 0.2500 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5030 - accuracy: 0.3125 - val_loss: 1.9703 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4285 - accuracy: 0.3125 - val_loss: 2.0364 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3972 - accuracy: 0.3750 - val_loss: 2.1020 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4156 - accuracy: 0.3750 - val_loss: 2.1686 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4431 - accuracy: 0.3125 - val_loss: 2.2362 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3382 - accuracy: 0.3750 - val_loss: 2.3049 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3335 - accuracy: 0.3125 - val_loss: 2.3726 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2822 - accuracy: 0.3750 - val_loss: 2.4410 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2921 - accuracy: 0.4375 - val_loss: 2.5095 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2963 - accuracy: 0.4062 - val_loss: 2.5793 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2996 - accuracy: 0.4688 - val_loss: 2.6495 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2773 - accuracy: 0.4688 - val_loss: 2.7207 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2589 - accuracy: 0.5312 - val_loss: 2.7908 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2585 - accuracy: 0.4688 - val_loss: 2.8607 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2296 - accuracy: 0.5000 - val_loss: 2.9304 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2391 - accuracy: 0.5000 - val_loss: 3.0006 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2089 - accuracy: 0.5000 - val_loss: 3.0709 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1774 - accuracy: 0.5938 - val_loss: 3.1419 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1521 - accuracy: 0.6250 - val_loss: 3.2135 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1283 - accuracy: 0.6875 - val_loss: 3.2843 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1604 - accuracy: 0.5625 - val_loss: 3.3532 - val_accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0680 - accuracy: 0.3000\n",
      "Fold 2 Test Accuracy: 0.30000001192092896\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 1.6398 - accuracy: 0.2188 - val_loss: 1.8032 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5610 - accuracy: 0.3125 - val_loss: 1.8442 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5435 - accuracy: 0.2812 - val_loss: 1.8869 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5984 - accuracy: 0.2812 - val_loss: 1.9316 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5441 - accuracy: 0.3438 - val_loss: 1.9771 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5168 - accuracy: 0.2500 - val_loss: 2.0231 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4724 - accuracy: 0.4062 - val_loss: 2.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5134 - accuracy: 0.3125 - val_loss: 2.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4657 - accuracy: 0.3750 - val_loss: 2.1584 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4726 - accuracy: 0.3438 - val_loss: 2.2035 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4452 - accuracy: 0.4062 - val_loss: 2.2490 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4452 - accuracy: 0.3750 - val_loss: 2.2933 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3926 - accuracy: 0.5000 - val_loss: 2.3373 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4058 - accuracy: 0.4062 - val_loss: 2.3818 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3953 - accuracy: 0.4375 - val_loss: 2.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3788 - accuracy: 0.4688 - val_loss: 2.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3562 - accuracy: 0.5000 - val_loss: 2.5151 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3585 - accuracy: 0.5312 - val_loss: 2.5590 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3364 - accuracy: 0.6250 - val_loss: 2.6037 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3196 - accuracy: 0.5938 - val_loss: 2.6478 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3251 - accuracy: 0.5000 - val_loss: 2.6920 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2956 - accuracy: 0.5938 - val_loss: 2.7360 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3005 - accuracy: 0.5938 - val_loss: 2.7792 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3065 - accuracy: 0.5625 - val_loss: 2.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2674 - accuracy: 0.5938 - val_loss: 2.8633 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2357 - accuracy: 0.6875 - val_loss: 2.9050 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2325 - accuracy: 0.5938 - val_loss: 2.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1815 - accuracy: 0.6562 - val_loss: 2.9894 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2092 - accuracy: 0.5625 - val_loss: 3.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.2099 - accuracy: 0.5938 - val_loss: 3.0714 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3451 - accuracy: 0.7000\n",
      "Fold 3 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 1.5943 - accuracy: 0.2500 - val_loss: 1.7970 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6232 - accuracy: 0.2188 - val_loss: 1.8408 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5126 - accuracy: 0.3438 - val_loss: 1.8860 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5304 - accuracy: 0.3125 - val_loss: 1.9315 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5085 - accuracy: 0.1875 - val_loss: 1.9803 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4886 - accuracy: 0.3438 - val_loss: 2.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4588 - accuracy: 0.3438 - val_loss: 2.0786 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4453 - accuracy: 0.4375 - val_loss: 2.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4083 - accuracy: 0.4375 - val_loss: 2.1841 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4503 - accuracy: 0.3125 - val_loss: 2.2400 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4208 - accuracy: 0.4062 - val_loss: 2.2971 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4096 - accuracy: 0.3438 - val_loss: 2.3563 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4054 - accuracy: 0.3125 - val_loss: 2.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3576 - accuracy: 0.4375 - val_loss: 2.4832 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4039 - accuracy: 0.3438 - val_loss: 2.5483 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3495 - accuracy: 0.5000 - val_loss: 2.6146 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3266 - accuracy: 0.5000 - val_loss: 2.6830 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2883 - accuracy: 0.5000 - val_loss: 2.7542 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3311 - accuracy: 0.5000 - val_loss: 2.8261 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3257 - accuracy: 0.4688 - val_loss: 2.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2440 - accuracy: 0.5312 - val_loss: 2.9734 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2754 - accuracy: 0.5312 - val_loss: 3.0480 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.2653 - accuracy: 0.5312 - val_loss: 3.1244 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2343 - accuracy: 0.6562 - val_loss: 3.2033 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1795 - accuracy: 0.6562 - val_loss: 3.2844 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2152 - accuracy: 0.5938 - val_loss: 3.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1779 - accuracy: 0.6250 - val_loss: 3.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1524 - accuracy: 0.6250 - val_loss: 3.5288 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1307 - accuracy: 0.6562 - val_loss: 3.6129 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1264 - accuracy: 0.6562 - val_loss: 3.6987 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6097 - accuracy: 0.8000\n",
      "Fold 4 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 1.6180 - accuracy: 0.2500 - val_loss: 1.6405 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6042 - accuracy: 0.2188 - val_loss: 1.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5672 - accuracy: 0.2812 - val_loss: 1.7270 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5673 - accuracy: 0.2500 - val_loss: 1.7700 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5109 - accuracy: 0.2188 - val_loss: 1.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5136 - accuracy: 0.2500 - val_loss: 1.8538 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4828 - accuracy: 0.2812 - val_loss: 1.8988 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4628 - accuracy: 0.3125 - val_loss: 1.9482 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4343 - accuracy: 0.3750 - val_loss: 2.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4220 - accuracy: 0.3125 - val_loss: 2.0568 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4455 - accuracy: 0.3438 - val_loss: 2.1167 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3844 - accuracy: 0.3438 - val_loss: 2.1801 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4028 - accuracy: 0.3125 - val_loss: 2.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3461 - accuracy: 0.5312 - val_loss: 2.3142 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4088 - accuracy: 0.2188 - val_loss: 2.3832 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3688 - accuracy: 0.2812 - val_loss: 2.4535 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3380 - accuracy: 0.3750 - val_loss: 2.5244 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3720 - accuracy: 0.3438 - val_loss: 2.5961 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2843 - accuracy: 0.4375 - val_loss: 2.6702 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3277 - accuracy: 0.2812 - val_loss: 2.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2847 - accuracy: 0.4688 - val_loss: 2.8229 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2617 - accuracy: 0.4375 - val_loss: 2.9012 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2711 - accuracy: 0.4688 - val_loss: 2.9806 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2702 - accuracy: 0.4062 - val_loss: 3.0601 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.2227 - accuracy: 0.5000 - val_loss: 3.1411 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2158 - accuracy: 0.6250 - val_loss: 3.2232 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2378 - accuracy: 0.4688 - val_loss: 3.3059 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1484 - accuracy: 0.5938 - val_loss: 3.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1917 - accuracy: 0.4688 - val_loss: 3.4751 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1741 - accuracy: 0.6562 - val_loss: 3.5614 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6462 - accuracy: 0.7000\n",
      "Fold 5 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.6399999976158142\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_0 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_0_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_0_Aut_0_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_0_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_0_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_0_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 1536)]               0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_10 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_11 (Gaussia  (None, 1536)                 0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 64)                   128       ['gaussian_noise_10[0][0]']   \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 256)                  393472    ['gaussian_noise_11[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 64)                   0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 256)                  0         ['dense_27[0][0]']            \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 32)                   2080      ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 128)                  32896     ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 160)                  0         ['dense_26[0][0]',            \n",
      " )                                                                   'dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 5)                    805       ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 429381 (1.64 MB)\n",
      "Trainable params: 429381 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 2.0278 - accuracy: 0.1875 - val_loss: 1.2342 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2383 - accuracy: 1.0000 - val_loss: 1.1783 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2584 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.1149e-04 - accuracy: 1.0000 - val_loss: 1.3063 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0658e-04 - accuracy: 1.0000 - val_loss: 1.3546 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.3899e-05 - accuracy: 1.0000 - val_loss: 1.4063 - val_accuracy: 0.3750\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1583e-05 - accuracy: 1.0000 - val_loss: 1.4601 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.2592e-05 - accuracy: 1.0000 - val_loss: 1.5119 - val_accuracy: 0.3750\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 8.3552e-06 - accuracy: 1.0000 - val_loss: 1.5635 - val_accuracy: 0.3750\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6863e-06 - accuracy: 1.0000 - val_loss: 1.6125 - val_accuracy: 0.3750\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 2.1942e-06 - accuracy: 1.0000 - val_loss: 1.6598 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8664e-06 - accuracy: 1.0000 - val_loss: 1.7036 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4230e-06 - accuracy: 1.0000 - val_loss: 1.7454 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.5332e-07 - accuracy: 1.0000 - val_loss: 1.7850 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.5565e-07 - accuracy: 1.0000 - val_loss: 1.8230 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7993e-06 - accuracy: 1.0000 - val_loss: 1.8582 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 1.8912 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8254e-07 - accuracy: 1.0000 - val_loss: 1.9221 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8254e-07 - accuracy: 1.0000 - val_loss: 1.9508 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.4273e-07 - accuracy: 1.0000 - val_loss: 1.9779 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5646e-07 - accuracy: 1.0000 - val_loss: 2.0032 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3039e-07 - accuracy: 1.0000 - val_loss: 2.0266 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 2.0479 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.1607e-07 - accuracy: 1.0000 - val_loss: 2.0677 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.6822e-07 - accuracy: 1.0000 - val_loss: 2.0862 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.7881e-07 - accuracy: 1.0000 - val_loss: 2.1032 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4901e-07 - accuracy: 1.0000 - val_loss: 2.1187 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.4703e-08 - accuracy: 1.0000 - val_loss: 2.1331 - val_accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4461 - accuracy: 0.8000\n",
      "Fold 1 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.6021 - accuracy: 0.2500 - val_loss: 2.4002 - val_accuracy: 0.1250\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2313 - accuracy: 1.0000 - val_loss: 2.3612 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 2.3929 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.4472 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5159 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5894 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.2703e-04 - accuracy: 1.0000 - val_loss: 2.6678 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7696e-04 - accuracy: 1.0000 - val_loss: 2.7449 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3997e-04 - accuracy: 1.0000 - val_loss: 2.8163 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1432e-04 - accuracy: 1.0000 - val_loss: 2.8834 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.6474e-05 - accuracy: 1.0000 - val_loss: 2.9501 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.5069e-05 - accuracy: 1.0000 - val_loss: 3.0122 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.7259e-05 - accuracy: 1.0000 - val_loss: 3.0725 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0587e-04 - accuracy: 1.0000 - val_loss: 3.1292 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0283e-04 - accuracy: 1.0000 - val_loss: 3.1825 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.9495e-06 - accuracy: 1.0000 - val_loss: 3.2325 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0911e-05 - accuracy: 1.0000 - val_loss: 3.2784 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7208e-05 - accuracy: 1.0000 - val_loss: 3.3211 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.3957e-06 - accuracy: 1.0000 - val_loss: 3.3608 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0270e-05 - accuracy: 1.0000 - val_loss: 3.3976 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7695e-06 - accuracy: 1.0000 - val_loss: 3.4312 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5798e-06 - accuracy: 1.0000 - val_loss: 3.4616 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.1723e-07 - accuracy: 1.0000 - val_loss: 3.4901 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.3805e-05 - accuracy: 1.0000 - val_loss: 3.5165 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0925e-05 - accuracy: 1.0000 - val_loss: 3.5408 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9227e-05 - accuracy: 1.0000 - val_loss: 3.5632 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8153e-05 - accuracy: 1.0000 - val_loss: 3.5836 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2178e-05 - accuracy: 1.0000 - val_loss: 3.6023 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.1483e-06 - accuracy: 1.0000 - val_loss: 3.6195 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.1547e-05 - accuracy: 1.0000 - val_loss: 3.6354 - val_accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2314 - accuracy: 0.7000\n",
      "Fold 2 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 2.3621 - accuracy: 0.1875 - val_loss: 3.5072 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4952 - accuracy: 0.8125 - val_loss: 2.9723 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 2.4480 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.9558 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.5910 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1246 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9530e-04 - accuracy: 1.0000 - val_loss: 0.9793 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.4284e-04 - accuracy: 1.0000 - val_loss: 0.8599 - val_accuracy: 0.6250\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2026e-04 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.6250\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.9708e-04 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 6.1656e-05 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.6269e-05 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.8750\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0013e-05 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8750\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.0954e-05 - accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.8750\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.8963e-05 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8750\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2228e-05 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8750\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.9336e-05 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.8750\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5645e-05 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9214e-05 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.8750\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.9848e-06 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3921e-05 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.8750\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.4396e-05 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.8750\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.2997e-06 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.8750\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6159e-05 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.0111e-05 - accuracy: 1.0000 - val_loss: 0.3060 - val_accuracy: 0.8750\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7517e-05 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.8750\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1596e-05 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.4177e-06 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7770e-06 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Fold 3 Test Accuracy: 1.0\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 353ms/step - loss: 2.0750 - accuracy: 0.3125 - val_loss: 2.3627 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3632 - accuracy: 1.0000 - val_loss: 2.5454 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 2.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.8782 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.9843e-04 - accuracy: 1.0000 - val_loss: 3.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3858e-04 - accuracy: 1.0000 - val_loss: 3.3039 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2346e-04 - accuracy: 1.0000 - val_loss: 3.4353 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.8869e-05 - accuracy: 1.0000 - val_loss: 3.5562 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.7139e-04 - accuracy: 1.0000 - val_loss: 3.6717 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3479e-05 - accuracy: 1.0000 - val_loss: 3.7792 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.3759e-05 - accuracy: 1.0000 - val_loss: 3.8794 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3314e-05 - accuracy: 1.0000 - val_loss: 3.9714 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0911e-05 - accuracy: 1.0000 - val_loss: 4.0550 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4595e-04 - accuracy: 1.0000 - val_loss: 4.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8240e-04 - accuracy: 1.0000 - val_loss: 4.2061 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7290e-06 - accuracy: 1.0000 - val_loss: 4.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8025e-05 - accuracy: 1.0000 - val_loss: 4.3336 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.6321e-06 - accuracy: 1.0000 - val_loss: 4.3905 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.4946e-06 - accuracy: 1.0000 - val_loss: 4.4427 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.2972e-06 - accuracy: 1.0000 - val_loss: 4.4914 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2921e-05 - accuracy: 1.0000 - val_loss: 4.5362 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.9134e-06 - accuracy: 1.0000 - val_loss: 4.5774 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1234e-06 - accuracy: 1.0000 - val_loss: 4.6154 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6906e-05 - accuracy: 1.0000 - val_loss: 4.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6799e-07 - accuracy: 1.0000 - val_loss: 4.6822 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7732e-06 - accuracy: 1.0000 - val_loss: 4.7116 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0286e-05 - accuracy: 1.0000 - val_loss: 4.7385 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4994e-07 - accuracy: 1.0000 - val_loss: 4.7629 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3523e-06 - accuracy: 1.0000 - val_loss: 4.7852 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9144 - accuracy: 0.8000\n",
      "Fold 4 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 1.6733 - accuracy: 0.2812 - val_loss: 2.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2204 - accuracy: 1.0000 - val_loss: 2.6393 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.9513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1025 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4897e-04 - accuracy: 1.0000 - val_loss: 3.2520 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.1828e-05 - accuracy: 1.0000 - val_loss: 3.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7643e-04 - accuracy: 1.0000 - val_loss: 3.5256 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7100e-05 - accuracy: 1.0000 - val_loss: 3.6510 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.5015e-05 - accuracy: 1.0000 - val_loss: 3.7670 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.6404e-06 - accuracy: 1.0000 - val_loss: 3.8730 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.0361e-06 - accuracy: 1.0000 - val_loss: 3.9679 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0452e-06 - accuracy: 1.0000 - val_loss: 4.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2352e-07 - accuracy: 1.0000 - val_loss: 4.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.1781e-07 - accuracy: 1.0000 - val_loss: 4.2118 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.9371e-07 - accuracy: 1.0000 - val_loss: 4.2798 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 4.8429e-08 - accuracy: 1.0000 - val_loss: 4.3432 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 7.5995e-07 - accuracy: 1.0000 - val_loss: 4.4015 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.1159e-06 - accuracy: 1.0000 - val_loss: 4.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.0393e-06 - accuracy: 1.0000 - val_loss: 4.5053 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.5682e-08 - accuracy: 1.0000 - val_loss: 4.5520 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1176e-07 - accuracy: 1.0000 - val_loss: 4.5945 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.8626e-08 - accuracy: 1.0000 - val_loss: 4.6334 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2352e-08 - accuracy: 1.0000 - val_loss: 4.6688 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.5879e-08 - accuracy: 1.0000 - val_loss: 4.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.0978e-08 - accuracy: 1.0000 - val_loss: 4.7305 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.1234e-07 - accuracy: 1.0000 - val_loss: 4.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 4.7815 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8626e-07 - accuracy: 1.0000 - val_loss: 4.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.8241 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1426 - accuracy: 0.8000\n",
      "Fold 5 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.8200000047683715\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_1 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_0_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 1536)]               0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_20 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_21 (Gaussia  (None, 1536)                 0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_50 (Dense)            (None, 64)                   128       ['gaussian_noise_20[0][0]']   \n",
      "                                                                                                  \n",
      " dense_52 (Dense)            (None, 256)                  393472    ['gaussian_noise_21[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 64)                   0         ['dense_50[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 256)                  0         ['dense_52[0][0]']            \n",
      "                                                                                                  \n",
      " dense_51 (Dense)            (None, 32)                   2080      ['dropout_20[0][0]']          \n",
      "                                                                                                  \n",
      " dense_53 (Dense)            (None, 128)                  32896     ['dropout_21[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 160)                  0         ['dense_51[0][0]',            \n",
      " e)                                                                  'dense_53[0][0]']            \n",
      "                                                                                                  \n",
      " dense_54 (Dense)            (None, 5)                    805       ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 429381 (1.64 MB)\n",
      "Trainable params: 429381 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 341ms/step - loss: 1.6097 - accuracy: 0.1875 - val_loss: 1.8057 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5772 - accuracy: 0.3125 - val_loss: 1.8695 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5794 - accuracy: 0.1875 - val_loss: 1.9362 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5260 - accuracy: 0.2812 - val_loss: 2.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5498 - accuracy: 0.1875 - val_loss: 2.0857 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5181 - accuracy: 0.1875 - val_loss: 2.1686 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5130 - accuracy: 0.1875 - val_loss: 2.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4832 - accuracy: 0.3125 - val_loss: 2.3486 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4426 - accuracy: 0.3750 - val_loss: 2.4450 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4473 - accuracy: 0.2812 - val_loss: 2.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4189 - accuracy: 0.2812 - val_loss: 2.6452 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4441 - accuracy: 0.2500 - val_loss: 2.7501 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4631 - accuracy: 0.3125 - val_loss: 2.8545 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4153 - accuracy: 0.2188 - val_loss: 2.9630 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3762 - accuracy: 0.2812 - val_loss: 3.0752 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3913 - accuracy: 0.3438 - val_loss: 3.1888 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3728 - accuracy: 0.3125 - val_loss: 3.3042 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3701 - accuracy: 0.3125 - val_loss: 3.4194 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3913 - accuracy: 0.2500 - val_loss: 3.5323 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3608 - accuracy: 0.2812 - val_loss: 3.6421 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4369 - accuracy: 0.2188 - val_loss: 3.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3927 - accuracy: 0.2188 - val_loss: 3.8604 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3658 - accuracy: 0.3438 - val_loss: 3.9706 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3611 - accuracy: 0.2812 - val_loss: 4.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3783 - accuracy: 0.2500 - val_loss: 4.1891 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3848 - accuracy: 0.2500 - val_loss: 4.2928 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3399 - accuracy: 0.2812 - val_loss: 4.3918 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3584 - accuracy: 0.2500 - val_loss: 4.4861 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3822 - accuracy: 0.2500 - val_loss: 4.5785 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3246 - accuracy: 0.3438 - val_loss: 4.6671 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0804 - accuracy: 0.1000\n",
      "Fold 1 Test Accuracy: 0.10000000149011612\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 1.6857 - accuracy: 0.2500 - val_loss: 1.6172 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.6593 - accuracy: 0.2188 - val_loss: 1.6921 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.6530 - accuracy: 0.2812 - val_loss: 1.7707 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6294 - accuracy: 0.2500 - val_loss: 1.8558 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6134 - accuracy: 0.0938 - val_loss: 1.9451 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5684 - accuracy: 0.0938 - val_loss: 2.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5066 - accuracy: 0.1250 - val_loss: 2.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5321 - accuracy: 0.1562 - val_loss: 2.2388 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4902 - accuracy: 0.1875 - val_loss: 2.3487 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4724 - accuracy: 0.2812 - val_loss: 2.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5057 - accuracy: 0.2812 - val_loss: 2.5847 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4349 - accuracy: 0.3125 - val_loss: 2.7061 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4995 - accuracy: 0.3125 - val_loss: 2.8261 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4331 - accuracy: 0.2812 - val_loss: 2.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4165 - accuracy: 0.2812 - val_loss: 3.0646 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4788 - accuracy: 0.2812 - val_loss: 3.1793 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3867 - accuracy: 0.3125 - val_loss: 3.2875 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3974 - accuracy: 0.3125 - val_loss: 3.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3511 - accuracy: 0.3750 - val_loss: 3.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3239 - accuracy: 0.2500 - val_loss: 3.5969 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3593 - accuracy: 0.2812 - val_loss: 3.6935 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3920 - accuracy: 0.3125 - val_loss: 3.7865 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3573 - accuracy: 0.2812 - val_loss: 3.8776 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3397 - accuracy: 0.3125 - val_loss: 3.9642 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3861 - accuracy: 0.2188 - val_loss: 4.0459 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3734 - accuracy: 0.3438 - val_loss: 4.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4042 - accuracy: 0.2500 - val_loss: 4.2006 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3057 - accuracy: 0.3438 - val_loss: 4.2742 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3161 - accuracy: 0.3750 - val_loss: 4.3470 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3336 - accuracy: 0.3750 - val_loss: 4.4196 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.4797 - accuracy: 0.1000\n",
      "Fold 2 Test Accuracy: 0.10000000149011612\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 1.5867 - accuracy: 0.1250 - val_loss: 1.7365 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5652 - accuracy: 0.3438 - val_loss: 1.8065 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5247 - accuracy: 0.2812 - val_loss: 1.8812 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5325 - accuracy: 0.3125 - val_loss: 1.9652 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5283 - accuracy: 0.3438 - val_loss: 2.0534 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5178 - accuracy: 0.2812 - val_loss: 2.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4857 - accuracy: 0.3125 - val_loss: 2.2240 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5017 - accuracy: 0.3125 - val_loss: 2.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4370 - accuracy: 0.4688 - val_loss: 2.4007 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4922 - accuracy: 0.3750 - val_loss: 2.4875 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4552 - accuracy: 0.4375 - val_loss: 2.5717 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4644 - accuracy: 0.2812 - val_loss: 2.6555 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4274 - accuracy: 0.4375 - val_loss: 2.7350 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4446 - accuracy: 0.3438 - val_loss: 2.8124 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4406 - accuracy: 0.3125 - val_loss: 2.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4641 - accuracy: 0.3438 - val_loss: 2.9565 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4569 - accuracy: 0.3125 - val_loss: 3.0244 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4378 - accuracy: 0.3438 - val_loss: 3.0912 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4890 - accuracy: 0.3438 - val_loss: 3.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4006 - accuracy: 0.4688 - val_loss: 3.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4423 - accuracy: 0.3750 - val_loss: 3.2540 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4304 - accuracy: 0.2812 - val_loss: 3.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3857 - accuracy: 0.5625 - val_loss: 3.3387 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4703 - accuracy: 0.3438 - val_loss: 3.3754 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4628 - accuracy: 0.3438 - val_loss: 3.4081 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4023 - accuracy: 0.3750 - val_loss: 3.4345 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4163 - accuracy: 0.3750 - val_loss: 3.4567 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3403 - accuracy: 0.4375 - val_loss: 3.4772 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4171 - accuracy: 0.3125 - val_loss: 3.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4150 - accuracy: 0.4062 - val_loss: 3.5075 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.6101 - accuracy: 0.3000\n",
      "Fold 3 Test Accuracy: 0.30000001192092896\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.7190 - accuracy: 0.0000e+00 - val_loss: 1.4251 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7110 - accuracy: 0.0938 - val_loss: 1.5205 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6270 - accuracy: 0.2500 - val_loss: 1.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5965 - accuracy: 0.3125 - val_loss: 1.7295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5839 - accuracy: 0.3438 - val_loss: 1.8464 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5683 - accuracy: 0.2812 - val_loss: 1.9733 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5345 - accuracy: 0.2500 - val_loss: 2.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4976 - accuracy: 0.3125 - val_loss: 2.2517 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4796 - accuracy: 0.4062 - val_loss: 2.4012 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4403 - accuracy: 0.2500 - val_loss: 2.5569 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4896 - accuracy: 0.2812 - val_loss: 2.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4062 - accuracy: 0.3750 - val_loss: 2.8702 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3565 - accuracy: 0.4062 - val_loss: 3.0274 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3605 - accuracy: 0.3438 - val_loss: 3.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4257 - accuracy: 0.2812 - val_loss: 3.3433 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4210 - accuracy: 0.1875 - val_loss: 3.4946 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3347 - accuracy: 0.3750 - val_loss: 3.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4240 - accuracy: 0.3438 - val_loss: 3.7838 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4020 - accuracy: 0.3438 - val_loss: 3.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3425 - accuracy: 0.4062 - val_loss: 4.0466 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3503 - accuracy: 0.4688 - val_loss: 4.1716 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4082 - accuracy: 0.2188 - val_loss: 4.2883 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3365 - accuracy: 0.4688 - val_loss: 4.4023 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3101 - accuracy: 0.5000 - val_loss: 4.5141 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3454 - accuracy: 0.3438 - val_loss: 4.6190 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3529 - accuracy: 0.4062 - val_loss: 4.7170 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3229 - accuracy: 0.3438 - val_loss: 4.8148 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3536 - accuracy: 0.4062 - val_loss: 4.9053 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3557 - accuracy: 0.3125 - val_loss: 4.9908 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3653 - accuracy: 0.2500 - val_loss: 5.0750 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0926 - accuracy: 0.2000\n",
      "Fold 4 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 1.6457 - accuracy: 0.4375 - val_loss: 1.7811 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5299 - accuracy: 0.2812 - val_loss: 1.8567 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5805 - accuracy: 0.2812 - val_loss: 1.9376 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5890 - accuracy: 0.1562 - val_loss: 2.0265 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5449 - accuracy: 0.2188 - val_loss: 2.1210 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5183 - accuracy: 0.2188 - val_loss: 2.2204 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4803 - accuracy: 0.2812 - val_loss: 2.3246 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4302 - accuracy: 0.3438 - val_loss: 2.4352 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4752 - accuracy: 0.2500 - val_loss: 2.5503 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.4370 - accuracy: 0.3125 - val_loss: 2.6664 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4786 - accuracy: 0.2188 - val_loss: 2.7795 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 1.4056 - accuracy: 0.2500 - val_loss: 2.8934 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4154 - accuracy: 0.2500 - val_loss: 3.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4193 - accuracy: 0.3125 - val_loss: 3.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4064 - accuracy: 0.2812 - val_loss: 3.2143 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3852 - accuracy: 0.3438 - val_loss: 3.3189 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4156 - accuracy: 0.1875 - val_loss: 3.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4031 - accuracy: 0.2812 - val_loss: 3.5196 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3916 - accuracy: 0.2812 - val_loss: 3.6169 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4308 - accuracy: 0.2500 - val_loss: 3.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4084 - accuracy: 0.2500 - val_loss: 3.8032 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3975 - accuracy: 0.2500 - val_loss: 3.8921 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3694 - accuracy: 0.3750 - val_loss: 3.9774 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3778 - accuracy: 0.2812 - val_loss: 4.0606 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3932 - accuracy: 0.2500 - val_loss: 4.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3728 - accuracy: 0.2188 - val_loss: 4.2246 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3798 - accuracy: 0.1562 - val_loss: 4.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3644 - accuracy: 0.4062 - val_loss: 4.3789 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4081 - accuracy: 0.1562 - val_loss: 4.4554 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3973 - accuracy: 0.2500 - val_loss: 4.5279 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.0160 - accuracy: 0.2000\n",
      "Fold 5 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.18000000417232515\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_2 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0              = encoder\n",
    "    \n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_30 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_31 (Gaussia  (None, 3)                    0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_75 (Dense)            (None, 64)                   128       ['gaussian_noise_30[0][0]']   \n",
      "                                                                                                  \n",
      " dense_77 (Dense)            (None, 256)                  1024      ['gaussian_noise_31[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 64)                   0         ['dense_75[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)        (None, 256)                  0         ['dense_77[0][0]']            \n",
      "                                                                                                  \n",
      " dense_76 (Dense)            (None, 32)                   2080      ['dropout_30[0][0]']          \n",
      "                                                                                                  \n",
      " dense_78 (Dense)            (None, 128)                  32896     ['dropout_31[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenat  (None, 160)                  0         ['dense_76[0][0]',            \n",
      " e)                                                                  'dense_78[0][0]']            \n",
      "                                                                                                  \n",
      " dense_79 (Dense)            (None, 5)                    805       ['concatenate_15[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36933 (144.27 KB)\n",
      "Trainable params: 36933 (144.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.6491 - accuracy: 0.1875 - val_loss: 1.5196 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6585 - accuracy: 0.2188 - val_loss: 1.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6266 - accuracy: 0.2500 - val_loss: 1.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5728 - accuracy: 0.2812 - val_loss: 1.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5852 - accuracy: 0.2500 - val_loss: 1.6577 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6121 - accuracy: 0.2812 - val_loss: 1.6886 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5506 - accuracy: 0.2812 - val_loss: 1.7189 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5640 - accuracy: 0.2188 - val_loss: 1.7501 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5252 - accuracy: 0.2500 - val_loss: 1.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5715 - accuracy: 0.2812 - val_loss: 1.8164 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4717 - accuracy: 0.3750 - val_loss: 1.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4970 - accuracy: 0.2188 - val_loss: 1.8888 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5120 - accuracy: 0.3125 - val_loss: 1.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4780 - accuracy: 0.2812 - val_loss: 1.9686 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4668 - accuracy: 0.2812 - val_loss: 2.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4619 - accuracy: 0.4062 - val_loss: 2.0568 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4468 - accuracy: 0.4062 - val_loss: 2.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4479 - accuracy: 0.2500 - val_loss: 2.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4357 - accuracy: 0.4375 - val_loss: 2.2062 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3823 - accuracy: 0.3750 - val_loss: 2.2603 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3888 - accuracy: 0.4062 - val_loss: 2.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4076 - accuracy: 0.3125 - val_loss: 2.3754 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4129 - accuracy: 0.3125 - val_loss: 2.4361 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3661 - accuracy: 0.4375 - val_loss: 2.4988 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3909 - accuracy: 0.3750 - val_loss: 2.5631 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4144 - accuracy: 0.3125 - val_loss: 2.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3421 - accuracy: 0.3125 - val_loss: 2.6952 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3848 - accuracy: 0.3750 - val_loss: 2.7623 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2928 - accuracy: 0.4062 - val_loss: 2.8306 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2983 - accuracy: 0.4375 - val_loss: 2.9018 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7518 - accuracy: 0.0000e+00\n",
      "Fold 1 Test Accuracy: 0.0\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 1.7021 - accuracy: 0.1250 - val_loss: 1.4416 - val_accuracy: 0.8750\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7294 - accuracy: 0.0000e+00 - val_loss: 1.4738 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6822 - accuracy: 0.0938 - val_loss: 1.5062 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5996 - accuracy: 0.1562 - val_loss: 1.5401 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6421 - accuracy: 0.0938 - val_loss: 1.5732 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5827 - accuracy: 0.4375 - val_loss: 1.6081 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6009 - accuracy: 0.2500 - val_loss: 1.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5642 - accuracy: 0.1875 - val_loss: 1.6814 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5196 - accuracy: 0.2812 - val_loss: 1.7211 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5753 - accuracy: 0.2188 - val_loss: 1.7610 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5212 - accuracy: 0.3125 - val_loss: 1.8018 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5053 - accuracy: 0.2500 - val_loss: 1.8439 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4789 - accuracy: 0.4062 - val_loss: 1.8874 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4768 - accuracy: 0.3125 - val_loss: 1.9322 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4583 - accuracy: 0.2812 - val_loss: 1.9786 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4718 - accuracy: 0.2812 - val_loss: 2.0260 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4042 - accuracy: 0.3125 - val_loss: 2.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4684 - accuracy: 0.3125 - val_loss: 2.1256 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4542 - accuracy: 0.3125 - val_loss: 2.1767 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4236 - accuracy: 0.3750 - val_loss: 2.2281 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4344 - accuracy: 0.3125 - val_loss: 2.2803 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4192 - accuracy: 0.2812 - val_loss: 2.3328 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3698 - accuracy: 0.3750 - val_loss: 2.3856 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.3665 - accuracy: 0.3125 - val_loss: 2.4391 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.3365 - accuracy: 0.3750 - val_loss: 2.4937 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3655 - accuracy: 0.4062 - val_loss: 2.5493 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 1.3251 - accuracy: 0.3438 - val_loss: 2.6058 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.3092 - accuracy: 0.4062 - val_loss: 2.6631 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.3003 - accuracy: 0.4688 - val_loss: 2.7220 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.2948 - accuracy: 0.5312 - val_loss: 2.7827 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.9896 - accuracy: 0.1000\n",
      "Fold 2 Test Accuracy: 0.10000000149011612\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7134 - accuracy: 0.2812 - val_loss: 1.7753 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6900 - accuracy: 0.3125 - val_loss: 1.7963 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6201 - accuracy: 0.3438 - val_loss: 1.8200 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.6152 - accuracy: 0.2500 - val_loss: 1.8457 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6136 - accuracy: 0.2188 - val_loss: 1.8733 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5731 - accuracy: 0.3438 - val_loss: 1.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5924 - accuracy: 0.2500 - val_loss: 1.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5985 - accuracy: 0.3125 - val_loss: 1.9742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5603 - accuracy: 0.4062 - val_loss: 2.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5783 - accuracy: 0.2812 - val_loss: 2.0509 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.5095 - accuracy: 0.2812 - val_loss: 2.0904 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.5376 - accuracy: 0.3125 - val_loss: 2.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4887 - accuracy: 0.3750 - val_loss: 2.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.5382 - accuracy: 0.2500 - val_loss: 2.2150 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5414 - accuracy: 0.3125 - val_loss: 2.2586 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 1.4904 - accuracy: 0.3750 - val_loss: 2.3028 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5077 - accuracy: 0.2812 - val_loss: 2.3480 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4344 - accuracy: 0.3438 - val_loss: 2.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4369 - accuracy: 0.3750 - val_loss: 2.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.4261 - accuracy: 0.2812 - val_loss: 2.4888 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5285 - accuracy: 0.2812 - val_loss: 2.5361 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4641 - accuracy: 0.1875 - val_loss: 2.5836 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4416 - accuracy: 0.4062 - val_loss: 2.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4394 - accuracy: 0.3750 - val_loss: 2.6799 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 1.4542 - accuracy: 0.2500 - val_loss: 2.7272 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.4452 - accuracy: 0.3125 - val_loss: 2.7737 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4479 - accuracy: 0.3125 - val_loss: 2.8210 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4058 - accuracy: 0.4062 - val_loss: 2.8679 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3964 - accuracy: 0.4375 - val_loss: 2.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3986 - accuracy: 0.3438 - val_loss: 2.9595 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4905 - accuracy: 0.6000\n",
      "Fold 3 Test Accuracy: 0.6000000238418579\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 759ms/step - loss: 1.7454 - accuracy: 0.0000e+00 - val_loss: 1.3905 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.7248 - accuracy: 0.0312 - val_loss: 1.4234 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7037 - accuracy: 0.0000e+00 - val_loss: 1.4561 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6622 - accuracy: 0.0938 - val_loss: 1.4876 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6790 - accuracy: 0.0312 - val_loss: 1.5205 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6491 - accuracy: 0.2500 - val_loss: 1.5546 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6458 - accuracy: 0.2188 - val_loss: 1.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6186 - accuracy: 0.2500 - val_loss: 1.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.6089 - accuracy: 0.2500 - val_loss: 1.6636 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 1.6182 - accuracy: 0.2812 - val_loss: 1.7019 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5769 - accuracy: 0.4688 - val_loss: 1.7414 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6044 - accuracy: 0.3125 - val_loss: 1.7829 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5517 - accuracy: 0.3438 - val_loss: 1.8262 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5497 - accuracy: 0.3750 - val_loss: 1.8715 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5253 - accuracy: 0.3125 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5591 - accuracy: 0.1875 - val_loss: 1.9682 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5547 - accuracy: 0.3125 - val_loss: 2.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4984 - accuracy: 0.3750 - val_loss: 2.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4839 - accuracy: 0.4375 - val_loss: 2.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 1.4898 - accuracy: 0.2188 - val_loss: 2.1882 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4861 - accuracy: 0.1562 - val_loss: 2.2486 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4675 - accuracy: 0.3438 - val_loss: 2.3117 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4640 - accuracy: 0.3125 - val_loss: 2.3773 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4394 - accuracy: 0.3750 - val_loss: 2.4456 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4314 - accuracy: 0.3438 - val_loss: 2.5163 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4390 - accuracy: 0.3750 - val_loss: 2.5896 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4235 - accuracy: 0.3750 - val_loss: 2.6642 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4178 - accuracy: 0.4062 - val_loss: 2.7411 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4113 - accuracy: 0.2812 - val_loss: 2.8202 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.3981 - accuracy: 0.4375 - val_loss: 2.9011 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6971 - accuracy: 0.1000\n",
      "Fold 4 Test Accuracy: 0.10000000149011612\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 1.6132 - accuracy: 0.2500 - val_loss: 1.7150 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5684 - accuracy: 0.3438 - val_loss: 1.7499 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5847 - accuracy: 0.2500 - val_loss: 1.7866 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5305 - accuracy: 0.2500 - val_loss: 1.8249 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5760 - accuracy: 0.1875 - val_loss: 1.8667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5903 - accuracy: 0.1562 - val_loss: 1.9112 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5309 - accuracy: 0.2812 - val_loss: 1.9572 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5025 - accuracy: 0.3125 - val_loss: 2.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4852 - accuracy: 0.3750 - val_loss: 2.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4544 - accuracy: 0.3125 - val_loss: 2.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4415 - accuracy: 0.3438 - val_loss: 2.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4881 - accuracy: 0.2188 - val_loss: 2.2033 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4589 - accuracy: 0.4062 - val_loss: 2.2549 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4348 - accuracy: 0.3438 - val_loss: 2.3081 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4592 - accuracy: 0.2812 - val_loss: 2.3607 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4518 - accuracy: 0.2500 - val_loss: 2.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4827 - accuracy: 0.2188 - val_loss: 2.4689 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4170 - accuracy: 0.2812 - val_loss: 2.5259 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3723 - accuracy: 0.4062 - val_loss: 2.5850 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 1.3484 - accuracy: 0.4062 - val_loss: 2.6460 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.4095 - accuracy: 0.3125 - val_loss: 2.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3648 - accuracy: 0.4062 - val_loss: 2.7706 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3880 - accuracy: 0.2500 - val_loss: 2.8356 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3489 - accuracy: 0.4375 - val_loss: 2.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3284 - accuracy: 0.3750 - val_loss: 2.9681 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3348 - accuracy: 0.4375 - val_loss: 3.0368 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3733 - accuracy: 0.3125 - val_loss: 3.1065 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3161 - accuracy: 0.3438 - val_loss: 3.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3115 - accuracy: 0.4062 - val_loss: 3.2482 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3214 - accuracy: 0.3750 - val_loss: 3.3187 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7854 - accuracy: 0.2000\n",
      "Fold 5 Test Accuracy: 0.20000000298023224\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.20000000596046447\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "operationnn.ipynb has finished\n",
      "Out_1_Nor_1_Aut_1_DR_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_3 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_1\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_1 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    print(f\"{subject_label}\")\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_1                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_1          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_1  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1- `Operation: SVM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [6.496516227722168, [-0.023179981857538223, -0...\n",
       "1     [7.216111660003662, [-0.02709014154970646, 0.0...\n",
       "2     [4.820352077484131, [-0.027561485767364502, 0....\n",
       "3     [3.285065174102783, [-0.017391610890626907, 0....\n",
       "4     [2.013909101486206, [-0.02618575282394886, -0....\n",
       "5     [2.750776767730713, [-0.02786310203373432, 0.0...\n",
       "6     [1.8918119668960571, [-0.016522565856575966, 0...\n",
       "7     [5.782482147216797, [-0.020461147651076317, 0....\n",
       "8     [5.027541160583496, [-0.019330058246850967, 0....\n",
       "9     [1.8539708852767944, [-0.018260912969708443, -...\n",
       "10    [3.9321811199188232, [-0.012247681617736816, 0...\n",
       "11    [3.068100929260254, [-0.02337650954723358, -0....\n",
       "12    [2.01381778717041, [-0.030698079615831375, -0....\n",
       "13    [1.693952560424805, [-0.029411470517516136, -0...\n",
       "14    [1.7035424709320068, [-0.00034768227487802505,...\n",
       "15    [2.4735491275787354, [-0.017089633271098137, -...\n",
       "16    [1.9176887273788452, [-0.008595016784965992, -...\n",
       "17    [2.430889844894409, [-0.008053204976022243, -0...\n",
       "18    [1.6459747552871704, [-0.018414746969938278, -...\n",
       "19    [1.318286657333374, [-0.02043631114065647, 0.0...\n",
       "20    [3.4722657203674316, [-0.03089701570570469, -0...\n",
       "21    [4.7200236320495605, [-0.03779100999236107, 0....\n",
       "22    [4.3272175788879395, [-0.036703381687402725, 0...\n",
       "23    [4.4580535888671875, [-0.032608307898044586, 0...\n",
       "24    [4.602021217346191, [-0.03874512389302254, 0.0...\n",
       "25    [4.8144941329956055, [-0.03462428227066994, 0....\n",
       "26    [4.9346489906311035, [-0.02666221372783184, 0....\n",
       "27    [3.1254734992980957, [-0.022845221683382988, -...\n",
       "28    [4.516481399536133, [-0.03620649501681328, 0.0...\n",
       "29    [4.090731620788574, [-0.025632625445723534, 0....\n",
       "30    [2.4618544578552246, [-0.01764203980565071, 0....\n",
       "31    [5.273684501647949, [-0.02164112590253353, -0....\n",
       "32    [4.290997505187988, [-0.01618216373026371, 0.0...\n",
       "33    [1.679938554763794, [-0.0021745830308645964, 0...\n",
       "34    [2.607694149017334, [-0.010331124998629093, 0....\n",
       "35    [1.9697431325912476, [-0.009212559089064598, -...\n",
       "36    [3.9581973552703857, [-0.017974235117435455, 0...\n",
       "37    [3.8590359687805176, [-0.031197870150208473, -...\n",
       "38    [2.568978786468506, [0.0010776142589747906, 0....\n",
       "39    [1.8100850582122805, [-0.009785622358322144, -...\n",
       "40    [2.185464382171631, [-0.021880967542529106, -0...\n",
       "41    [2.8507373332977295, [0.006584431044757366, -0...\n",
       "42    [2.999174118041992, [-0.00319025875069201, -0....\n",
       "43    [3.1167471408843994, [0.00498313270509243, 0.0...\n",
       "44    [2.5410046577453613, [-0.01442825049161911, -0...\n",
       "45    [2.421492576599121, [-0.014833754859864712, -0...\n",
       "46    [3.1219165325164795, [0.001740546664223075, 0....\n",
       "47    [3.2749857902526855, [-0.016992609947919846, -...\n",
       "48    [3.203280210494995, [-0.0013845551293343306, -...\n",
       "49    [2.97369647026062, [-0.008292808197438717, -0....\n",
       "Name: Expression_Embeddings, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subject_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_0 == 1: \n",
    "    SVM_Dict_Out_1_Nor_0_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                 y_Cell_Type              = Cell_Type, \n",
    "                                                 subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\", \n",
    "                                                 subject_outlier          = subject_outlier, \n",
    "                                                 subject_normalization    = subject_normalization, \n",
    "                                                 subject_autoencoder      = subject_autoencoder, \n",
    "                                                 subject_dimension        = subject_dimension,\n",
    "                                                 data_source = \"list\" )\n",
    "    Model_SVM_Out_1_Nor_0_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_0_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_0_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_0_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_1 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_2 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_3 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_1 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_1                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_1          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_1  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_1           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2- `Operation: SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_0 == 1: \n",
    "    SGD_Dict_Out_1_Nor_0_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                    y_Cell_Type           = Cell_Type,\n",
    "                                                    subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                    subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )  \n",
    "    Model_SGD_Out_1_Nor_0_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_0_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_0_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_0_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_1 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )  \n",
    "    Model_SGD_Out_1_Nor_1_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_1 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension,\n",
    "                                                        data_source = \"list\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_1                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_1          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_1  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_1           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3- `Operation: Random Forest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_0 == 1: \n",
    "    RF_Dict_Out_1_Nor_0_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )    \n",
    "    Model_RF_Out_1_Nor_0_Aut_0_DR_0                = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_0_Aut_0_DR_0          = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_0_Aut_0_DR_0  = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_0_Aut_0_DR_0           = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_1 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension, \n",
    "                                                data_source = \"list\" )  \n",
    "    Model_RF_Out_1_Nor_1_Aut_0_DR_0                = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_0_DR_0          = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_0_DR_0  = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_0_DR_0           = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_0                = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_0          = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_0  = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_0           = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_1 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_1                = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_1          = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_1  = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_1           = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4- `Operation: Decision Tree`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_0 == 1: \n",
    "    DT_Dict_Out_1_Nor_0_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                        subject_outlier       = subject_outlier, \n",
    "                                        subject_normalization = subject_normalization, \n",
    "                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                        subject_dimension     = subject_dimension,\n",
    "                                        data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_0_Aut_0_DR_0                = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_0_Aut_0_DR_0          = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_0_Aut_0_DR_0  = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_0_Aut_0_DR_0           = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_1 == 1: \n",
    "  DT_Dict_Out_1_Nor_1_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                            subject_normalization = subject_normalization, \n",
    "                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                            subject_dimension     = subject_dimension,\n",
    "                                            data_source = \"list\" )   \n",
    "  Model_DT_Out_1_Nor_1_Aut_0_DR_0                = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "  Predictions_DT_Out_1_Nor_1_Aut_0_DR_0          = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "  Statistics_Detailed_DT_Out_1_Nor_1_Aut_0_DR_0  = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "  Statistics_DT_Out_1_Nor_1_Aut_0_DR_0           = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_2 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_0                = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_0          = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_0  = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_0           = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_3 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_1 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_1                = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_1          = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_1  = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_1           = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5- `Operation: Gradient Boosting`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_0 == 1: \n",
    "    GB_Dict_Out_1_Nor_0_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier, \n",
    "                                                            subject_normalization = subject_normalization, \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension,\n",
    "                                                            data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_0_Aut_0_DR_0                = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_0_Aut_0_DR_0          = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_0_Aut_0_DR_0  = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_0_Aut_0_DR_0           = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_1 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier,\n",
    "                                                            subject_normalization = subject_normalization,  \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension, \n",
    "                                                            data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_0_DR_0                = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_0_DR_0          = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_0_DR_0  = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_0_DR_0           = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_2 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_0                = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_0          = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_0  = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_0           = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_GB_3 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_1 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_1                = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_1          = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_1  = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_1           = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4- `Operation: Combine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-) `Statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All = pd.DataFrame() \n",
    "if switch_N_0 == 1: \n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0], axis = 0) \n",
    "if switch_N_1 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0], axis = 0)\n",
    "if switch_N_2 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0], axis = 0) \n",
    "if switch_N_3 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1], axis = 0) \n",
    "\n",
    "SVM_All = pd.DataFrame() \n",
    "if switch_SVM_0 == 1: \n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "if switch_SVM_1 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SVM_2 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "if switch_SVM_3 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0) \n",
    "\n",
    "SGD_All = pd.DataFrame()\n",
    "if switch_SGD_0 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_1 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_2 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_3 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "DT_All = pd.DataFrame() \n",
    "if switch_DT_0 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_1 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_2 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_3 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "\n",
    "RF_All = pd.DataFrame()\n",
    "if switch_RF_0 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_1 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_2 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_3 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "\n",
    "GB_All = pd.DataFrame()\n",
    "if switch_GB_0 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_1 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_2 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_3 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) `Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All_Models = []\n",
    "NN_All_Encoders = [] \n",
    "if switch_N_0 == 1: \n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_0_Aut_0_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0)\n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_N_1 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_0_DR_0)\n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_N_2 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0)\n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_N_3 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_1\")  \n",
    "\n",
    "NN_All_Models_Dict = {} \n",
    "for i in range(len(NN_All_Models)):\n",
    "    NN_All_Models_Dict[f\"Model_{i}\"] = NN_All_Models[i] \n",
    "\n",
    "NN_All_Encoders_Dict = {}\n",
    "for i in range(len(NN_All_Encoders)):\n",
    "    NN_All_Encoders_Dict[f\"Encoder_{i}\"] = NN_All_Encoders[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_All_Models = []\n",
    "if switch_SVM_0 == 1: \n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_SVM_1 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SVM_2 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SVM_3 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "SVM_All_Models_Dict = {} \n",
    "for i in range(len(SVM_All_Models)):\n",
    "    SVM_All_Models_Dict[f\"Model_{i}\"] = SVM_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_All_Models = []\n",
    "if switch_SGD_0 == 1: \n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_SGD_1 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SGD_2 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SGD_3 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "SGD_All_Models_Dict = {} \n",
    "for i in range(len(SGD_All_Models)):\n",
    "    SGD_All_Models_Dict[f\"Model_{i}\"] = SGD_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_All_Models = []\n",
    "if switch_DT_0 == 1: \n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_DT_1 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_0_DR_0\")  \n",
    "if switch_DT_2 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "if switch_DT_3 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "DT_All_Models_Dict = {} \n",
    "for i in range(len(DT_All_Models)):\n",
    "    DT_All_Models_Dict[f\"Model_{i}\"] = DT_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_All_Models = []\n",
    "if switch_RF_0 == 1: \n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_RF_1 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_RF_2 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_1_DR_0\") \n",
    "if switch_RF_3 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading |RF_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "RF_All_Models_Dict = {} \n",
    "for i in range(len(RF_All_Models)):\n",
    "    RF_All_Models_Dict[f\"Model_{i}\"] = RF_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_All_Models = []\n",
    "if switch_GB_0 == 1:\n",
    "    try: \n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading |GB_Dict_Out_1_Nor_0_Aut_0_DR_0\") \n",
    "if switch_GB_1 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_GB_2 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_0\") \n",
    "\n",
    "if switch_GB_3 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "GB_All_Models_Dict = {} \n",
    "for i in range(len(GB_All_Models)):\n",
    "    GB_All_Models_Dict[f\"Model_{i}\"] = GB_All_Models[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-) `Report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject Outlier: ZScore_v0_ZScore_v0\n",
      "Subject Normalization: StandardScaler_StandardScaler\n",
      "Subject Autoencoder: Basic_v1_Basic_v1\n",
      "Subject Dimension: PCA_n3_Free\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subject Outlier: {subject_outlier}\")\n",
    "print(f\"Subject Normalization: {subject_normalization}\") \n",
    "print(f\"Subject Autoencoder: {subject_autoencoder}\")\n",
    "print(f\"Subject Dimension: {subject_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.354286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.088889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.068571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Applications  \\\n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "\n",
       "        Applications_Condition Model  \\\n",
       "0       Out_1_Nor_1_Aut_1_DR_0    DT   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0    RF   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0   SGD   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1    RF   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0   SVM   \n",
       "0       Out_1_Nor_1_Aut_1_DR_0    RF   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0    RF   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1    DT   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0   SGD   \n",
       "0  Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0    DT   \n",
       "0       Out_1_Nor_1_Aut_0_DR_0    DT   \n",
       "0  Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "0       Out_1_Nor_1_Aut_1_DR_0   SGD   \n",
       "0       Out_1_Nor_0_Aut_0_DR_0   SVM   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1   SVM   \n",
       "0       Out_1_Nor_1_Aut_1_DR_1   SGD   \n",
       "0  Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "0       Out_1_Nor_1_Aut_1_DR_0   SVM   \n",
       "0  Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "\n",
       "                                          Parameters  Accuracy  Precision  \\\n",
       "0                                              Basic      1.00   1.000000   \n",
       "0                                              Basic      1.00   1.000000   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      1.00   1.000000   \n",
       "0                                              Basic      1.00   1.000000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      1.00   1.000000   \n",
       "0                                              Basic      1.00   1.000000   \n",
       "0                                              Basic      1.00   1.000000   \n",
       "0                                              Basic      0.90   1.000000   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      0.80   0.800000   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.82   0.733333   \n",
       "0                                              Basic      0.70   0.833333   \n",
       "0                                              Basic      0.70   0.833333   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.64   0.683333   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      0.40   0.480000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      0.40   0.380000   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      0.40   0.300000   \n",
       "0     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001      0.30   0.300000   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.20   0.111111   \n",
       "0     kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale      0.20   0.057143   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.18   0.041667   \n",
       "\n",
       "   Recall        F1  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     1.0  1.000000  \n",
       "0     0.9  0.940000  \n",
       "0     0.8  0.800000  \n",
       "0     0.8  0.750000  \n",
       "0     0.7  0.710000  \n",
       "0     0.7  0.710000  \n",
       "0     0.7  0.656667  \n",
       "0     0.4  0.375000  \n",
       "0     0.4  0.354286  \n",
       "0     0.4  0.333333  \n",
       "0     0.3  0.300000  \n",
       "0     0.2  0.120000  \n",
       "0     0.2  0.088889  \n",
       "0     0.2  0.068571  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data = pd.concat([NN_All, SVM_All, DT_All, RF_All, GB_All, SGD_All], axis=0) \n",
    "All_Data.sort_values(by = [\"F1\"], ascending= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6- `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"data_raw\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(data_raw, file)   \n",
    "\n",
    "export_name = \"subject_data_full\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_data_full, file)   \n",
    "\n",
    "    \n",
    "export_name = \"subject_outlier_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_0, file)   \n",
    "\n",
    "export_name = \"subject_outlier_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_1, file)   \n",
    "\n",
    "export_name = \"subject_outlier\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier, file)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_normalization_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_0, file)   \n",
    "\n",
    "export_name = \"subject_normalization_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_1, file)   \n",
    "\n",
    "export_name = \"subject_normalization\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization, file)   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_autoencoder_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_0, file)   \n",
    "\n",
    "export_name = \"subject_autoencoder_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_1, file) \n",
    "\n",
    "export_name = \"subject_autoencoder\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder, file)   \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_dimension_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_0, file)   \n",
    "\n",
    "export_name = \"subject_dimension_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_1, file)   \n",
    "\n",
    "export_name = \"subject_dimension\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension, file)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.068571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Applications  \\\n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "\n",
       "        Applications_Condition Model  \\\n",
       "0  Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "\n",
       "                                          Parameters  Accuracy  Precision  \\\n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.64   0.683333   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.82   0.733333   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.18   0.041667   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...      0.20   0.111111   \n",
       "\n",
       "   Recall        F1  \n",
       "0     0.7  0.656667  \n",
       "0     0.8  0.750000  \n",
       "0     0.2  0.068571  \n",
       "0     0.2  0.120000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#NN\n",
    "export_name = \"NN_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All, file) \n",
    "\n",
    "# --------------------\n",
    "#SVM \n",
    "export_name = \"SVM_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All, file) \n",
    "\n",
    "# --------------------\n",
    "#SGD\n",
    "export_name = \"SGD_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "#DT\n",
    "export_name = \"DT_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All, file)\n",
    "\n",
    "# --------------------\n",
    "#RF\n",
    "export_name = \"RF_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All, file)\n",
    "\n",
    "# --------------------\n",
    "#GB\n",
    "export_name = \"GB_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#NN \n",
    "export_name = \"NN_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Models, file) \n",
    "\n",
    "# --------------------\n",
    "#SVM \n",
    "export_name = \"SVM_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All_Models, file) \n",
    "\n",
    "\n",
    "# --------------------\n",
    "#SGD\n",
    "export_name = \"SGD_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All_Models, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "#DT\n",
    "export_name = \"DT_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "#RF\n",
    "export_name = \"RF_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "#GB\n",
    "export_name = \"GB_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All_Models, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#NN \n",
    "export_name = \"NN_All_Encoders\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Encoders, file) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
