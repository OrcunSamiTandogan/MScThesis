{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 7: Predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s0_config.ipynb | Started\n",
      "s0_config.ipynb | Finished\n",
      "Length: 47\n",
      "Unique Cell Types: 5\n",
      "Unique Gene Markers: 47\n",
      "--------------------\n",
      "Subject Outlier 0 (Embedding): ZScore_v0\n",
      "Subject Outlier 1 (Expression): ZScore_v0\n",
      "Subject_Outlier: ZScore_v0_ZScore_v0\n",
      "Subject normalization 0 (Embedding): StandardScaler\n",
      "Subject normalization 1 (Expression): StandardScaler\n",
      "Subject Autoencoder 0 (Embedding): Basic_v1\n",
      "Subject Autoencoder 1 (Expression): Basic_v1\n",
      "Subject Dimension Reduction 0 (Embedding): PCA_n3\n",
      "Subject Dimension Reduction 1 (Expression): Free\n",
      "--------------------\n",
      "Tools of ML: Complex\n",
      "Machine Learning Models: Basic\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "except: \n",
    "    %run s0_config.ipynb \n",
    "    %run s8_preparation.ipynb \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3- `Bench`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0- `Operation: Neural Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 768)]                0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNo  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " ise)                                                                                             \n",
      "                                                                                                  \n",
      " gaussian_noise_1 (Gaussian  (None, 768)                  0         ['input_emb[0][0]']           \n",
      " Noise)                                                                                           \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   128       ['gaussian_noise[0][0]']      \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 256)                  196864    ['gaussian_noise_1[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64)                   0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   2080      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 160)                  0         ['dense_1[0][0]',             \n",
      "                                                                     'dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 5)                    805       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 232773 (909.27 KB)\n",
      "Trainable params: 232773 (909.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 1.7599 - accuracy: 0.0690 - val_loss: 2.9533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2132 - accuracy: 0.3793 - val_loss: 4.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1571 - accuracy: 0.5172 - val_loss: 4.6802 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1168 - accuracy: 0.4483 - val_loss: 5.0795 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9782 - accuracy: 0.6897 - val_loss: 5.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9081 - accuracy: 0.6207 - val_loss: 5.7729 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0661 - accuracy: 0.5172 - val_loss: 6.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8675 - accuracy: 0.6207 - val_loss: 6.2750 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8647 - accuracy: 0.6552 - val_loss: 6.5541 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8517 - accuracy: 0.6897 - val_loss: 6.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9512 - accuracy: 0.5517 - val_loss: 6.9813 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8025 - accuracy: 0.6552 - val_loss: 7.1660 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7396 - accuracy: 0.6897 - val_loss: 7.3248 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6375 - accuracy: 0.7241 - val_loss: 7.5045 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8500 - accuracy: 0.6207 - val_loss: 7.6382 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8421 - accuracy: 0.7586 - val_loss: 7.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7124 - accuracy: 0.6552 - val_loss: 7.7688 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7338 - accuracy: 0.7586 - val_loss: 7.8165 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8359 - accuracy: 0.6207 - val_loss: 7.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6915 - accuracy: 0.6897 - val_loss: 7.9883 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6828 - accuracy: 0.7586 - val_loss: 8.0518 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6770 - accuracy: 0.6552 - val_loss: 7.9593 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6094 - accuracy: 0.7931 - val_loss: 7.7745 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6086 - accuracy: 0.7241 - val_loss: 7.5881 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6785 - accuracy: 0.7931 - val_loss: 7.4948 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5343 - accuracy: 0.8276 - val_loss: 7.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5179 - accuracy: 0.7931 - val_loss: 7.5145 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5651 - accuracy: 0.7931 - val_loss: 7.5274 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5611 - accuracy: 0.7241 - val_loss: 7.5507 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5296 - accuracy: 0.8276 - val_loss: 7.5394 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.3644 - accuracy: 0.6000\n",
      "Fold 1 Test Accuracy: 0.6000000238418579\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 546ms/step - loss: 1.7651 - accuracy: 0.1724 - val_loss: 2.5573 - val_accuracy: 0.1250\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4318 - accuracy: 0.4138 - val_loss: 3.1793 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3553 - accuracy: 0.3103 - val_loss: 3.5409 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1371 - accuracy: 0.6207 - val_loss: 3.7487 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1335 - accuracy: 0.4828 - val_loss: 3.9478 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0450 - accuracy: 0.6207 - val_loss: 4.1829 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0112 - accuracy: 0.5862 - val_loss: 4.4756 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9519 - accuracy: 0.5862 - val_loss: 4.7651 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9947 - accuracy: 0.5862 - val_loss: 5.0550 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8274 - accuracy: 0.6897 - val_loss: 5.3367 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9381 - accuracy: 0.5172 - val_loss: 5.5945 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7456 - accuracy: 0.7241 - val_loss: 5.8577 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7984 - accuracy: 0.6897 - val_loss: 6.1214 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7768 - accuracy: 0.6552 - val_loss: 6.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7235 - accuracy: 0.6897 - val_loss: 6.4523 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6589 - accuracy: 0.7586 - val_loss: 6.6536 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7095 - accuracy: 0.6897 - val_loss: 6.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6320 - accuracy: 0.8276 - val_loss: 6.9563 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5887 - accuracy: 0.7931 - val_loss: 7.1685 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5989 - accuracy: 0.7586 - val_loss: 7.3245 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6335 - accuracy: 0.6897 - val_loss: 7.3949 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5624 - accuracy: 0.6897 - val_loss: 7.4065 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5392 - accuracy: 0.7241 - val_loss: 7.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5551 - accuracy: 0.7586 - val_loss: 7.4354 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5491 - accuracy: 0.8276 - val_loss: 7.5182 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5310 - accuracy: 0.7241 - val_loss: 7.6361 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6670 - accuracy: 0.6552 - val_loss: 7.5971 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5287 - accuracy: 0.7931 - val_loss: 7.5111 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5174 - accuracy: 0.7586 - val_loss: 7.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4173 - accuracy: 0.8621 - val_loss: 7.4834 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.5403 - accuracy: 0.3000\n",
      "Fold 2 Test Accuracy: 0.30000001192092896\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 1.7240 - accuracy: 0.0333 - val_loss: 3.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4306 - accuracy: 0.3667 - val_loss: 3.7889 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3947 - accuracy: 0.4000 - val_loss: 4.3090 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2130 - accuracy: 0.4667 - val_loss: 4.7420 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2862 - accuracy: 0.4333 - val_loss: 5.1452 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1693 - accuracy: 0.4333 - val_loss: 5.4729 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9678 - accuracy: 0.6667 - val_loss: 5.8627 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0908 - accuracy: 0.5667 - val_loss: 6.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0627 - accuracy: 0.6000 - val_loss: 6.3470 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.9163 - accuracy: 0.6000 - val_loss: 6.5597 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9120 - accuracy: 0.7000 - val_loss: 6.7771 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7815 - accuracy: 0.7333 - val_loss: 7.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0436 - accuracy: 0.5667 - val_loss: 7.3222 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7052 - accuracy: 0.7333 - val_loss: 7.5572 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.8130 - accuracy: 0.6333 - val_loss: 7.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7035 - accuracy: 0.8000 - val_loss: 7.7864 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7206 - accuracy: 0.6667 - val_loss: 7.8065 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6271 - accuracy: 0.8000 - val_loss: 7.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6481 - accuracy: 0.7333 - val_loss: 7.9754 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6827 - accuracy: 0.8000 - val_loss: 8.0946 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6366 - accuracy: 0.8000 - val_loss: 8.2648 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6108 - accuracy: 0.7667 - val_loss: 8.5158 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.8384 - accuracy: 0.6333 - val_loss: 8.7263 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6467 - accuracy: 0.7667 - val_loss: 8.8414 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.6496 - accuracy: 0.7333 - val_loss: 8.8718 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6437 - accuracy: 0.7667 - val_loss: 8.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6442 - accuracy: 0.7667 - val_loss: 8.9279 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5448 - accuracy: 0.8000 - val_loss: 8.9390 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5992 - accuracy: 0.7333 - val_loss: 8.9487 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6189 - accuracy: 0.7667 - val_loss: 9.0315 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.8365 - accuracy: 0.6667\n",
      "Fold 3 Test Accuracy: 0.6666666865348816\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 1.6190 - accuracy: 0.2333 - val_loss: 3.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2680 - accuracy: 0.4667 - val_loss: 4.5885 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1306 - accuracy: 0.5667 - val_loss: 5.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1580 - accuracy: 0.5667 - val_loss: 6.2901 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2644 - accuracy: 0.3667 - val_loss: 6.9743 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0554 - accuracy: 0.6000 - val_loss: 7.3661 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0554 - accuracy: 0.6333 - val_loss: 7.6167 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9630 - accuracy: 0.6667 - val_loss: 7.8943 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9622 - accuracy: 0.6000 - val_loss: 8.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8217 - accuracy: 0.6667 - val_loss: 8.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9495 - accuracy: 0.5333 - val_loss: 8.6092 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8456 - accuracy: 0.6000 - val_loss: 8.7172 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7621 - accuracy: 0.8333 - val_loss: 8.8222 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8250 - accuracy: 0.7000 - val_loss: 8.8741 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8026 - accuracy: 0.7000 - val_loss: 8.8636 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6798 - accuracy: 0.7000 - val_loss: 8.8462 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7133 - accuracy: 0.7000 - val_loss: 8.8273 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6738 - accuracy: 0.7667 - val_loss: 8.8210 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6525 - accuracy: 0.7333 - val_loss: 8.8793 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6806 - accuracy: 0.7667 - val_loss: 8.9630 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6370 - accuracy: 0.8333 - val_loss: 9.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7286 - accuracy: 0.7667 - val_loss: 9.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5818 - accuracy: 0.8333 - val_loss: 8.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6298 - accuracy: 0.7667 - val_loss: 9.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6126 - accuracy: 0.7667 - val_loss: 9.0524 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6750 - accuracy: 0.7333 - val_loss: 8.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5435 - accuracy: 0.8333 - val_loss: 8.7959 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4725 - accuracy: 0.8333 - val_loss: 8.7284 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4630 - accuracy: 0.8333 - val_loss: 8.7028 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6283 - accuracy: 0.8333 - val_loss: 8.7078 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7147 - accuracy: 0.5556\n",
      "Fold 4 Test Accuracy: 0.5555555820465088\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 1.9575 - accuracy: 0.0333 - val_loss: 2.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4467 - accuracy: 0.3667 - val_loss: 3.3032 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2660 - accuracy: 0.4667 - val_loss: 3.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2292 - accuracy: 0.5333 - val_loss: 4.1033 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1580 - accuracy: 0.5667 - val_loss: 4.4945 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9027 - accuracy: 0.6667 - val_loss: 4.8884 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0992 - accuracy: 0.5000 - val_loss: 5.1860 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9645 - accuracy: 0.7000 - val_loss: 5.3766 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9647 - accuracy: 0.6000 - val_loss: 5.5457 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8498 - accuracy: 0.7000 - val_loss: 5.6821 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9906 - accuracy: 0.5667 - val_loss: 5.7890 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6628 - accuracy: 0.7667 - val_loss: 5.9625 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8177 - accuracy: 0.6667 - val_loss: 6.1426 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8026 - accuracy: 0.6000 - val_loss: 6.2582 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6775 - accuracy: 0.7667 - val_loss: 6.3737 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6172 - accuracy: 0.7667 - val_loss: 6.4548 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7579 - accuracy: 0.7333 - val_loss: 6.5061 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6001 - accuracy: 0.8000 - val_loss: 6.5702 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6331 - accuracy: 0.7667 - val_loss: 6.6147 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6722 - accuracy: 0.7333 - val_loss: 6.5599 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5581 - accuracy: 0.8000 - val_loss: 6.4822 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.8468 - accuracy: 0.6000 - val_loss: 6.3908 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6949 - accuracy: 0.8000 - val_loss: 6.3370 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5072 - accuracy: 0.7667 - val_loss: 6.3150 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5492 - accuracy: 0.8000 - val_loss: 6.3001 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5144 - accuracy: 0.8333 - val_loss: 6.2753 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6881 - accuracy: 0.7667 - val_loss: 6.2984 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6270 - accuracy: 0.7333 - val_loss: 6.3252 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5390 - accuracy: 0.8000 - val_loss: 6.3352 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4859 - accuracy: 0.8000 - val_loss: 6.2674 - val_accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8158 - accuracy: 0.5556\n",
      "Fold 5 Test Accuracy: 0.5555555820465088\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.5355555772781372\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_0 == 1: \n",
    "    \n",
    "\n",
    "    subject_label = \"Out_1_Nor_0_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_0_Aut_0_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_0_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_0_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_0_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 768)]                0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_10 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_11 (Gaussia  (None, 768)                  0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 64)                   128       ['gaussian_noise_10[0][0]']   \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 256)                  196864    ['gaussian_noise_11[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 64)                   0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 256)                  0         ['dense_27[0][0]']            \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 32)                   2080      ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 128)                  32896     ['dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 160)                  0         ['dense_26[0][0]',            \n",
      " )                                                                   'dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 5)                    805       ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 232773 (909.27 KB)\n",
      "Trainable params: 232773 (909.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.5777 - accuracy: 0.3793 - val_loss: 2.1857 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8128 - accuracy: 0.8621 - val_loss: 2.4478 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6498 - accuracy: 0.8276 - val_loss: 2.7617 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3752 - accuracy: 0.8966 - val_loss: 3.0884 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2038 - accuracy: 0.9310 - val_loss: 3.3981 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1343 - accuracy: 0.9655 - val_loss: 3.7180 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1075 - accuracy: 0.9310 - val_loss: 4.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 4.2823 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 4.5613 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 4.8271 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 5.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 5.3510 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 5.5929 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.8242 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 6.0446 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 6.2599 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0270 - accuracy: 0.9655 - val_loss: 6.4721 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 6.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 7.0292 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.1938 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.3481 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 7.4915 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.4125e-04 - accuracy: 1.0000 - val_loss: 7.6229 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.5286e-04 - accuracy: 1.0000 - val_loss: 7.7433 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8.3902e-04 - accuracy: 1.0000 - val_loss: 7.8539 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 7.9494 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 8.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 8.1808 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6360 - accuracy: 0.7000\n",
      "Fold 1 Test Accuracy: 0.699999988079071\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 2.0118 - accuracy: 0.2759 - val_loss: 2.2261 - val_accuracy: 0.1250\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8820 - accuracy: 0.7241 - val_loss: 2.8876 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4935 - accuracy: 0.8621 - val_loss: 3.5737 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2617 - accuracy: 0.9655 - val_loss: 4.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1604 - accuracy: 0.9655 - val_loss: 4.7240 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1164 - accuracy: 1.0000 - val_loss: 5.2339 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 5.6850 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 6.0880 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 6.4475 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 6.7849 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 7.0882 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 7.3637 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 7.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 7.8667 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 8.0896 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 8.2966 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 8.5017 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 8.6957 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.0933e-04 - accuracy: 1.0000 - val_loss: 8.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 9.0362 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 9.2559 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 9.4708 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.6720 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 9.8606 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.1299e-04 - accuracy: 1.0000 - val_loss: 10.0374 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 7.1397e-04 - accuracy: 1.0000 - val_loss: 10.1996 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.5992e-04 - accuracy: 1.0000 - val_loss: 10.3483 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 10.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 10.6166 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8887e-04 - accuracy: 1.0000 - val_loss: 10.7338 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7354 - accuracy: 0.8000\n",
      "Fold 2 Test Accuracy: 0.800000011920929\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4779 - accuracy: 0.3000 - val_loss: 2.4777 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6575 - accuracy: 0.8000 - val_loss: 3.2659 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3993 - accuracy: 0.8333 - val_loss: 3.7733 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3410 - accuracy: 0.9333 - val_loss: 4.1791 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2115 - accuracy: 0.9667 - val_loss: 4.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1649 - accuracy: 0.9333 - val_loss: 4.8265 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0852 - accuracy: 0.9667 - val_loss: 5.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 5.6128 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 5.9906 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0509 - accuracy: 0.9667 - val_loss: 6.3479 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0520 - accuracy: 0.9667 - val_loss: 6.6881 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 7.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 7.3081 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 7.5903 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 7.8554 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 8.0946 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 8.3198 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 8.5296 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 8.7253 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 8.8969 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.0587 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 9.2076 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.3450 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.9342e-04 - accuracy: 1.0000 - val_loss: 9.5915 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.5790e-04 - accuracy: 1.0000 - val_loss: 9.7016 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.8050 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.5082e-04 - accuracy: 1.0000 - val_loss: 9.9010 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 3.3022e-04 - accuracy: 1.0000 - val_loss: 9.9888 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 10.0745 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1674 - accuracy: 0.7778\n",
      "Fold 3 Test Accuracy: 0.7777777910232544\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 2.1184 - accuracy: 0.0667 - val_loss: 3.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9508 - accuracy: 0.7000 - val_loss: 3.6493 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4948 - accuracy: 0.8667 - val_loss: 4.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3234 - accuracy: 0.9333 - val_loss: 4.6796 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2245 - accuracy: 0.9333 - val_loss: 5.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1995 - accuracy: 0.9333 - val_loss: 5.5238 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 5.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 6.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 6.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 6.8827 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 7.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 7.4083 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 7.6216 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 7.8231 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1233 - accuracy: 0.9667 - val_loss: 7.9943 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 8.1583 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 8.3139 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 8.4622 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 8.6017 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.8659 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.9908 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 9.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 9.2847 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 9.3605 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.5865e-04 - accuracy: 1.0000 - val_loss: 9.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 9.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.0201e-04 - accuracy: 1.0000 - val_loss: 9.5661 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.2365e-04 - accuracy: 1.0000 - val_loss: 9.6248 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6614 - accuracy: 0.7778\n",
      "Fold 4 Test Accuracy: 0.7777777910232544\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 2.0017 - accuracy: 0.1333 - val_loss: 2.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.8489 - accuracy: 0.7667 - val_loss: 2.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4949 - accuracy: 0.8333 - val_loss: 3.4126 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3500 - accuracy: 0.8667 - val_loss: 3.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1925 - accuracy: 0.9667 - val_loss: 4.2929 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1677 - accuracy: 0.9667 - val_loss: 4.6428 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 4.9417 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 5.2274 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 5.5064 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 5.7748 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 6.0057 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 6.2236 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 6.4263 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 6.6185 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 6.8108 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 6.9968 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 7.1708 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 7.3351 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 7.4964 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 7.6930 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.8773 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 8.0578 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 8.2291 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0482 - accuracy: 0.9667 - val_loss: 8.3943 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.5479 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 8.6932 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 8.8429 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 8.9829 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0367 - accuracy: 0.9667 - val_loss: 9.1178 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 9.2499 - val_accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9011 - accuracy: 0.6667\n",
      "Fold 5 Test Accuracy: 0.6666666865348816\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.7444444537162781\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_1 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_0_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_0_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_0_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_0_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_0_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 768)]                0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_20 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_21 (Gaussia  (None, 768)                  0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_50 (Dense)            (None, 64)                   128       ['gaussian_noise_20[0][0]']   \n",
      "                                                                                                  \n",
      " dense_52 (Dense)            (None, 256)                  196864    ['gaussian_noise_21[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 64)                   0         ['dense_50[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 256)                  0         ['dense_52[0][0]']            \n",
      "                                                                                                  \n",
      " dense_51 (Dense)            (None, 32)                   2080      ['dropout_20[0][0]']          \n",
      "                                                                                                  \n",
      " dense_53 (Dense)            (None, 128)                  32896     ['dropout_21[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenat  (None, 160)                  0         ['dense_51[0][0]',            \n",
      " e)                                                                  'dense_53[0][0]']            \n",
      "                                                                                                  \n",
      " dense_54 (Dense)            (None, 5)                    805       ['concatenate_10[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 232773 (909.27 KB)\n",
      "Trainable params: 232773 (909.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 352ms/step - loss: 1.5243 - accuracy: 0.3448 - val_loss: 1.8189 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5945 - accuracy: 0.2759 - val_loss: 1.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4881 - accuracy: 0.3448 - val_loss: 1.9305 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5141 - accuracy: 0.2759 - val_loss: 1.9923 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4947 - accuracy: 0.2414 - val_loss: 2.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5047 - accuracy: 0.1724 - val_loss: 2.1222 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4664 - accuracy: 0.1724 - val_loss: 2.1896 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.4125 - accuracy: 0.3793 - val_loss: 2.2608 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4859 - accuracy: 0.2414 - val_loss: 2.3355 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4505 - accuracy: 0.3448 - val_loss: 2.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4262 - accuracy: 0.3793 - val_loss: 2.4900 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4405 - accuracy: 0.3103 - val_loss: 2.5705 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3819 - accuracy: 0.4138 - val_loss: 2.6531 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3641 - accuracy: 0.5172 - val_loss: 2.7362 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3645 - accuracy: 0.3448 - val_loss: 2.8193 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3784 - accuracy: 0.3793 - val_loss: 2.9028 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3560 - accuracy: 0.3793 - val_loss: 2.9854 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4232 - accuracy: 0.3103 - val_loss: 3.0653 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3798 - accuracy: 0.3448 - val_loss: 3.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3717 - accuracy: 0.2414 - val_loss: 3.2237 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3214 - accuracy: 0.4483 - val_loss: 3.3018 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4057 - accuracy: 0.2759 - val_loss: 3.3771 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3609 - accuracy: 0.3103 - val_loss: 3.4498 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3279 - accuracy: 0.3448 - val_loss: 3.5209 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2852 - accuracy: 0.5172 - val_loss: 3.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3694 - accuracy: 0.2759 - val_loss: 3.6588 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3635 - accuracy: 0.3103 - val_loss: 3.7232 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3789 - accuracy: 0.3793 - val_loss: 3.7831 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3206 - accuracy: 0.3103 - val_loss: 3.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.2884 - accuracy: 0.3793 - val_loss: 3.9023 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0309 - accuracy: 0.1000\n",
      "Fold 1 Test Accuracy: 0.10000000149011612\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 1.7507 - accuracy: 0.1034 - val_loss: 1.5727 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6731 - accuracy: 0.2759 - val_loss: 1.6234 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6661 - accuracy: 0.1724 - val_loss: 1.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5726 - accuracy: 0.1724 - val_loss: 1.7256 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5394 - accuracy: 0.3103 - val_loss: 1.7825 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5193 - accuracy: 0.3103 - val_loss: 1.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5509 - accuracy: 0.1724 - val_loss: 1.9103 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4810 - accuracy: 0.3793 - val_loss: 1.9796 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4720 - accuracy: 0.3448 - val_loss: 2.0553 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4474 - accuracy: 0.3448 - val_loss: 2.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4653 - accuracy: 0.3793 - val_loss: 2.2202 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4417 - accuracy: 0.3793 - val_loss: 2.3089 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4121 - accuracy: 0.3793 - val_loss: 2.3995 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3748 - accuracy: 0.3793 - val_loss: 2.4892 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3376 - accuracy: 0.3448 - val_loss: 2.5801 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4086 - accuracy: 0.4483 - val_loss: 2.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4208 - accuracy: 0.3448 - val_loss: 2.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4081 - accuracy: 0.3793 - val_loss: 2.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3141 - accuracy: 0.4138 - val_loss: 2.9294 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2877 - accuracy: 0.3793 - val_loss: 3.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3868 - accuracy: 0.3448 - val_loss: 3.0856 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3661 - accuracy: 0.3448 - val_loss: 3.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3496 - accuracy: 0.3448 - val_loss: 3.2253 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3723 - accuracy: 0.3793 - val_loss: 3.2898 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3180 - accuracy: 0.4138 - val_loss: 3.3524 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3440 - accuracy: 0.3793 - val_loss: 3.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3498 - accuracy: 0.4138 - val_loss: 3.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3369 - accuracy: 0.3793 - val_loss: 3.5276 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3395 - accuracy: 0.4138 - val_loss: 3.5848 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3112 - accuracy: 0.4483 - val_loss: 3.6435 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.0859 - accuracy: 0.0000e+00\n",
      "Fold 2 Test Accuracy: 0.0\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 1.7138 - accuracy: 0.2000 - val_loss: 1.5237 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7312 - accuracy: 0.2000 - val_loss: 1.5732 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6597 - accuracy: 0.2333 - val_loss: 1.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6992 - accuracy: 0.2000 - val_loss: 1.6809 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6292 - accuracy: 0.3000 - val_loss: 1.7380 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6462 - accuracy: 0.1333 - val_loss: 1.7972 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6028 - accuracy: 0.2000 - val_loss: 1.8603 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5589 - accuracy: 0.2000 - val_loss: 1.9283 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5611 - accuracy: 0.1000 - val_loss: 2.0011 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.4746 - accuracy: 0.3000 - val_loss: 2.0794 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5626 - accuracy: 0.1333 - val_loss: 2.1621 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4199 - accuracy: 0.3333 - val_loss: 2.2513 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4840 - accuracy: 0.2000 - val_loss: 2.3449 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4081 - accuracy: 0.3667 - val_loss: 2.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4563 - accuracy: 0.3000 - val_loss: 2.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4226 - accuracy: 0.3000 - val_loss: 2.6480 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4133 - accuracy: 0.3333 - val_loss: 2.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.3651 - accuracy: 0.3333 - val_loss: 2.8524 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4090 - accuracy: 0.3333 - val_loss: 2.9526 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3969 - accuracy: 0.3333 - val_loss: 3.0475 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3751 - accuracy: 0.3333 - val_loss: 3.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3759 - accuracy: 0.3333 - val_loss: 3.2322 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4367 - accuracy: 0.3333 - val_loss: 3.3194 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3764 - accuracy: 0.3667 - val_loss: 3.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3616 - accuracy: 0.3333 - val_loss: 3.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3858 - accuracy: 0.3333 - val_loss: 3.5581 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3803 - accuracy: 0.3333 - val_loss: 3.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3447 - accuracy: 0.3667 - val_loss: 3.7069 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3635 - accuracy: 0.3000 - val_loss: 3.7809 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3445 - accuracy: 0.3000 - val_loss: 3.8536 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7865 - accuracy: 0.0000e+00\n",
      "Fold 3 Test Accuracy: 0.0\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 1.6409 - accuracy: 0.1000 - val_loss: 1.5612 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.6341 - accuracy: 0.2000 - val_loss: 1.6225 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.6262 - accuracy: 0.1000 - val_loss: 1.6746 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6020 - accuracy: 0.1333 - val_loss: 1.7240 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6008 - accuracy: 0.1000 - val_loss: 1.7766 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.5899 - accuracy: 0.2333 - val_loss: 1.8308 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5153 - accuracy: 0.3333 - val_loss: 1.8863 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.5507 - accuracy: 0.1000 - val_loss: 1.9430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5192 - accuracy: 0.2333 - val_loss: 2.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.4622 - accuracy: 0.2667 - val_loss: 2.0669 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.4881 - accuracy: 0.3000 - val_loss: 2.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.4693 - accuracy: 0.2000 - val_loss: 2.2046 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.4730 - accuracy: 0.2333 - val_loss: 2.2788 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.4391 - accuracy: 0.2333 - val_loss: 2.3548 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4476 - accuracy: 0.3000 - val_loss: 2.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4357 - accuracy: 0.3000 - val_loss: 2.5134 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4504 - accuracy: 0.3333 - val_loss: 2.5958 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 1.3923 - accuracy: 0.4333 - val_loss: 2.6787 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3794 - accuracy: 0.2667 - val_loss: 2.7629 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3994 - accuracy: 0.2667 - val_loss: 2.8488 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.3820 - accuracy: 0.4000 - val_loss: 2.9353 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.3929 - accuracy: 0.3333 - val_loss: 3.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3624 - accuracy: 0.5000 - val_loss: 3.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3553 - accuracy: 0.4000 - val_loss: 3.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.3634 - accuracy: 0.3667 - val_loss: 3.2782 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4199 - accuracy: 0.2333 - val_loss: 3.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 1.3810 - accuracy: 0.3667 - val_loss: 3.4469 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.4067 - accuracy: 0.3667 - val_loss: 3.5276 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3730 - accuracy: 0.3333 - val_loss: 3.6060 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.3797 - accuracy: 0.2667 - val_loss: 3.6826 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.6353 - accuracy: 0.2222\n",
      "Fold 4 Test Accuracy: 0.2222222238779068\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6796 - accuracy: 0.0000e+00 - val_loss: 1.4382 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.6545 - accuracy: 0.1667 - val_loss: 1.4840 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6312 - accuracy: 0.1333 - val_loss: 1.5319 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6285 - accuracy: 0.2667 - val_loss: 1.5834 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5664 - accuracy: 0.2000 - val_loss: 1.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.6026 - accuracy: 0.2000 - val_loss: 1.6922 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 1.5208 - accuracy: 0.3667 - val_loss: 1.7492 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 1.4847 - accuracy: 0.3667 - val_loss: 1.8093 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 1.5159 - accuracy: 0.3000 - val_loss: 1.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 1.4984 - accuracy: 0.2333 - val_loss: 1.9437 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.4712 - accuracy: 0.2667 - val_loss: 2.0177 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.4890 - accuracy: 0.1333 - val_loss: 2.0932 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.4017 - accuracy: 0.4000 - val_loss: 2.1697 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.4174 - accuracy: 0.3000 - val_loss: 2.2474 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4084 - accuracy: 0.3000 - val_loss: 2.3261 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.4020 - accuracy: 0.2667 - val_loss: 2.4064 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 1.4065 - accuracy: 0.2333 - val_loss: 2.4874 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.3472 - accuracy: 0.4333 - val_loss: 2.5674 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.3759 - accuracy: 0.4000 - val_loss: 2.6506 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.3795 - accuracy: 0.3333 - val_loss: 2.7330 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 1.3216 - accuracy: 0.4333 - val_loss: 2.8174 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 1.3516 - accuracy: 0.3333 - val_loss: 2.9017 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.3624 - accuracy: 0.5000 - val_loss: 2.9842 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.3644 - accuracy: 0.3667 - val_loss: 3.0652 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 1.3973 - accuracy: 0.2667 - val_loss: 3.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.3465 - accuracy: 0.3333 - val_loss: 3.2176 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 1.3230 - accuracy: 0.3667 - val_loss: 3.2912 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.3801 - accuracy: 0.3000 - val_loss: 3.3599 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.3704 - accuracy: 0.4000 - val_loss: 3.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.3581 - accuracy: 0.3333 - val_loss: 3.4903 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 2.2395 - accuracy: 0.4444\n",
      "Fold 5 Test Accuracy: 0.4444444477558136\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.1533333346247673\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "operationnn.ipynb has finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_2 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_0\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_0 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_0                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0              = encoder\n",
    "    \n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_0          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_0  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operationnn.ipynb working\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_expr (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_emb (InputLayer)      [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " gaussian_noise_30 (Gaussia  (None, 1)                    0         ['input_expr[0][0]']          \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " gaussian_noise_31 (Gaussia  (None, 3)                    0         ['input_emb[0][0]']           \n",
      " nNoise)                                                                                          \n",
      "                                                                                                  \n",
      " dense_75 (Dense)            (None, 64)                   128       ['gaussian_noise_30[0][0]']   \n",
      "                                                                                                  \n",
      " dense_77 (Dense)            (None, 256)                  1024      ['gaussian_noise_31[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 64)                   0         ['dense_75[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)        (None, 256)                  0         ['dense_77[0][0]']            \n",
      "                                                                                                  \n",
      " dense_76 (Dense)            (None, 32)                   2080      ['dropout_30[0][0]']          \n",
      "                                                                                                  \n",
      " dense_78 (Dense)            (None, 128)                  32896     ['dropout_31[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenat  (None, 160)                  0         ['dense_76[0][0]',            \n",
      " e)                                                                  'dense_78[0][0]']            \n",
      "                                                                                                  \n",
      " dense_79 (Dense)            (None, 5)                    805       ['concatenate_15[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36933 (144.27 KB)\n",
      "Trainable params: 36933 (144.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "Training on fold 1...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.6599 - accuracy: 0.1034 - val_loss: 1.6133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 1.6188 - accuracy: 0.2414 - val_loss: 1.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 1.5944 - accuracy: 0.2414 - val_loss: 1.6505 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 1.5897 - accuracy: 0.2069 - val_loss: 1.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 1.5566 - accuracy: 0.3103 - val_loss: 1.6929 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.5618 - accuracy: 0.3448 - val_loss: 1.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.5678 - accuracy: 0.3103 - val_loss: 1.7392 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.5528 - accuracy: 0.3103 - val_loss: 1.7640 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.5563 - accuracy: 0.2414 - val_loss: 1.7899 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.5344 - accuracy: 0.2759 - val_loss: 1.8171 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5124 - accuracy: 0.3448 - val_loss: 1.8456 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5187 - accuracy: 0.2414 - val_loss: 1.8753 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5274 - accuracy: 0.3448 - val_loss: 1.9064 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 1.5061 - accuracy: 0.2759 - val_loss: 1.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.4901 - accuracy: 0.2414 - val_loss: 1.9727 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 1.5038 - accuracy: 0.2414 - val_loss: 2.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4732 - accuracy: 0.3448 - val_loss: 2.0459 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.4803 - accuracy: 0.2759 - val_loss: 2.0849 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.4642 - accuracy: 0.3793 - val_loss: 2.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4763 - accuracy: 0.3103 - val_loss: 2.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4693 - accuracy: 0.3448 - val_loss: 2.2134 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4337 - accuracy: 0.3448 - val_loss: 2.2600 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4364 - accuracy: 0.3793 - val_loss: 2.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4069 - accuracy: 0.3448 - val_loss: 2.3585 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4284 - accuracy: 0.3793 - val_loss: 2.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4136 - accuracy: 0.3103 - val_loss: 2.4626 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4389 - accuracy: 0.2414 - val_loss: 2.5164 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4145 - accuracy: 0.2069 - val_loss: 2.5714 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.3780 - accuracy: 0.2759 - val_loss: 2.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3858 - accuracy: 0.2759 - val_loss: 2.6856 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.8719 - accuracy: 0.1000\n",
      "Fold 1 Test Accuracy: 0.10000000149011612\n",
      "\n",
      "\n",
      "Training on fold 2...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 1.5857 - accuracy: 0.2759 - val_loss: 1.7114 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.6167 - accuracy: 0.2414 - val_loss: 1.7299 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.5736 - accuracy: 0.2759 - val_loss: 1.7501 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5660 - accuracy: 0.2759 - val_loss: 1.7725 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5559 - accuracy: 0.2759 - val_loss: 1.7960 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5744 - accuracy: 0.1379 - val_loss: 1.8198 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.5316 - accuracy: 0.2069 - val_loss: 1.8442 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5151 - accuracy: 0.2759 - val_loss: 1.8684 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4879 - accuracy: 0.3793 - val_loss: 1.8965 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4871 - accuracy: 0.3793 - val_loss: 1.9260 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4384 - accuracy: 0.4483 - val_loss: 1.9566 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4613 - accuracy: 0.3793 - val_loss: 1.9883 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.4509 - accuracy: 0.4138 - val_loss: 2.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.4527 - accuracy: 0.3103 - val_loss: 2.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4332 - accuracy: 0.4138 - val_loss: 2.0923 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 1.4187 - accuracy: 0.3448 - val_loss: 2.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4262 - accuracy: 0.3103 - val_loss: 2.1691 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4056 - accuracy: 0.3448 - val_loss: 2.2096 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3855 - accuracy: 0.3448 - val_loss: 2.2514 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4082 - accuracy: 0.3448 - val_loss: 2.2944 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3813 - accuracy: 0.3448 - val_loss: 2.3384 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.3347 - accuracy: 0.3793 - val_loss: 2.3830 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3830 - accuracy: 0.3448 - val_loss: 2.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3851 - accuracy: 0.3448 - val_loss: 2.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.3565 - accuracy: 0.3448 - val_loss: 2.5205 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3820 - accuracy: 0.3448 - val_loss: 2.5682 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3299 - accuracy: 0.3448 - val_loss: 2.6159 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3725 - accuracy: 0.3448 - val_loss: 2.6630 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3431 - accuracy: 0.3793 - val_loss: 2.7108 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3477 - accuracy: 0.3448 - val_loss: 2.7587 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0192 - accuracy: 0.0000e+00\n",
      "Fold 2 Test Accuracy: 0.0\n",
      "\n",
      "\n",
      "Training on fold 3...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6536 - accuracy: 0.1333 - val_loss: 1.5565 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.6357 - accuracy: 0.0667 - val_loss: 1.5778 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.6252 - accuracy: 0.1333 - val_loss: 1.5986 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.6376 - accuracy: 0.0667 - val_loss: 1.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5903 - accuracy: 0.1667 - val_loss: 1.6418 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6014 - accuracy: 0.1333 - val_loss: 1.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5653 - accuracy: 0.3667 - val_loss: 1.6884 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5727 - accuracy: 0.2667 - val_loss: 1.7129 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.5538 - accuracy: 0.3000 - val_loss: 1.7386 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 1.5400 - accuracy: 0.4333 - val_loss: 1.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.5187 - accuracy: 0.3000 - val_loss: 1.7968 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.5545 - accuracy: 0.3000 - val_loss: 1.8276 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 1.5271 - accuracy: 0.3000 - val_loss: 1.8600 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 1.5326 - accuracy: 0.3000 - val_loss: 1.8939 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.4691 - accuracy: 0.3333 - val_loss: 1.9274 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5180 - accuracy: 0.3333 - val_loss: 1.9630 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4773 - accuracy: 0.3667 - val_loss: 2.0004 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.4446 - accuracy: 0.3333 - val_loss: 2.0400 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.4832 - accuracy: 0.3333 - val_loss: 2.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4933 - accuracy: 0.3000 - val_loss: 2.1256 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.4673 - accuracy: 0.3333 - val_loss: 2.1712 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.4530 - accuracy: 0.3333 - val_loss: 2.2192 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 1.4398 - accuracy: 0.3333 - val_loss: 2.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.4086 - accuracy: 0.3333 - val_loss: 2.3224 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.3986 - accuracy: 0.3333 - val_loss: 2.3773 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4206 - accuracy: 0.3333 - val_loss: 2.4345 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3969 - accuracy: 0.3333 - val_loss: 2.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.3898 - accuracy: 0.3333 - val_loss: 2.5548 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.3883 - accuracy: 0.3333 - val_loss: 2.6174 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.3792 - accuracy: 0.3333 - val_loss: 2.6812 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7712 - accuracy: 0.0000e+00\n",
      "Fold 3 Test Accuracy: 0.0\n",
      "\n",
      "\n",
      "Training on fold 4...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5360 - accuracy: 0.1000 - val_loss: 1.9874 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.4917 - accuracy: 0.3000 - val_loss: 2.0207 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.5103 - accuracy: 0.2333 - val_loss: 2.0555 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.5002 - accuracy: 0.3333 - val_loss: 2.0908 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 388ms/step - loss: 1.4728 - accuracy: 0.3000 - val_loss: 2.1260 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4951 - accuracy: 0.3000 - val_loss: 2.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 1.4872 - accuracy: 0.2000 - val_loss: 2.1986 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.4963 - accuracy: 0.2667 - val_loss: 2.2357 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 339ms/step - loss: 1.5048 - accuracy: 0.2667 - val_loss: 2.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.5015 - accuracy: 0.2667 - val_loss: 2.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.4692 - accuracy: 0.2667 - val_loss: 2.3509 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.4620 - accuracy: 0.2333 - val_loss: 2.3901 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.4484 - accuracy: 0.3000 - val_loss: 2.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.4549 - accuracy: 0.2333 - val_loss: 2.4711 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.4352 - accuracy: 0.2333 - val_loss: 2.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.4341 - accuracy: 0.3000 - val_loss: 2.5542 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 1.4012 - accuracy: 0.2667 - val_loss: 2.5968 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 1.3995 - accuracy: 0.2667 - val_loss: 2.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.4177 - accuracy: 0.3000 - val_loss: 2.6839 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 299ms/step - loss: 1.4156 - accuracy: 0.2667 - val_loss: 2.7284 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.4047 - accuracy: 0.3000 - val_loss: 2.7733 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.3961 - accuracy: 0.2667 - val_loss: 2.8188 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.3547 - accuracy: 0.3667 - val_loss: 2.8645 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.3737 - accuracy: 0.3000 - val_loss: 2.9100 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.4278 - accuracy: 0.3000 - val_loss: 2.9556 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.3786 - accuracy: 0.3667 - val_loss: 3.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.3817 - accuracy: 0.3000 - val_loss: 3.0474 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3594 - accuracy: 0.3667 - val_loss: 3.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3703 - accuracy: 0.4000 - val_loss: 3.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.3413 - accuracy: 0.4667 - val_loss: 3.1898 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.5860 - accuracy: 0.2222\n",
      "Fold 4 Test Accuracy: 0.2222222238779068\n",
      "\n",
      "\n",
      "Training on fold 5...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.5783 - accuracy: 0.3000 - val_loss: 1.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 302ms/step - loss: 1.6112 - accuracy: 0.2667 - val_loss: 1.8198 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.5843 - accuracy: 0.2333 - val_loss: 1.8393 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.6261 - accuracy: 0.2333 - val_loss: 1.8590 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 1.5700 - accuracy: 0.3000 - val_loss: 1.8795 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.5271 - accuracy: 0.2333 - val_loss: 1.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.5416 - accuracy: 0.3000 - val_loss: 1.9230 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.5291 - accuracy: 0.3667 - val_loss: 1.9444 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.5515 - accuracy: 0.2333 - val_loss: 1.9661 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.5727 - accuracy: 0.2000 - val_loss: 1.9886 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.5153 - accuracy: 0.2667 - val_loss: 2.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.5176 - accuracy: 0.3000 - val_loss: 2.0378 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 1.5380 - accuracy: 0.3000 - val_loss: 2.0640 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.5204 - accuracy: 0.3000 - val_loss: 2.0912 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.4922 - accuracy: 0.3333 - val_loss: 2.1194 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5059 - accuracy: 0.2333 - val_loss: 2.1486 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4761 - accuracy: 0.3333 - val_loss: 2.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.4815 - accuracy: 0.2667 - val_loss: 2.2105 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4851 - accuracy: 0.2667 - val_loss: 2.2436 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.4745 - accuracy: 0.2333 - val_loss: 2.2783 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4704 - accuracy: 0.2333 - val_loss: 2.3143 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4586 - accuracy: 0.1667 - val_loss: 2.3520 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4087 - accuracy: 0.3000 - val_loss: 2.3912 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4351 - accuracy: 0.2667 - val_loss: 2.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.4113 - accuracy: 0.4000 - val_loss: 2.4729 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4106 - accuracy: 0.2333 - val_loss: 2.5157 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4170 - accuracy: 0.2333 - val_loss: 2.5598 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3891 - accuracy: 0.3667 - val_loss: 2.6057 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4158 - accuracy: 0.2000 - val_loss: 2.6514 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3476 - accuracy: 0.3000 - val_loss: 2.6986 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.9064 - accuracy: 0.2222\n",
      "Fold 5 Test Accuracy: 0.2222222238779068\n",
      "\n",
      "\n",
      "Average Test Accuracy across 5 folds: 0.10888888984918595\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "operationnn.ipynb has finished\n",
      "Out_1_Nor_1_Aut_1_DR_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/miniconda3/envs/bilimnn/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if switch_N_3 == 1: \n",
    "\n",
    "    subject_label = \"Out_1_Nor_1_Aut_1_DR_1\" \n",
    "\n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = Subject_Out_1_Nor_1_Aut_1_DR_1 # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    print(f\"{subject_label}\")\n",
    "    Model_NeNe_Out_1_Nor_1_Aut_1_DR_1                = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1              = encoder\n",
    "\n",
    "    Predictions_NeNe_Out_1_Nor_1_Aut_1_DR_1          = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Out_1_Nor_1_Aut_1_DR_1  = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1           = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1- `Operation: SVM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     [7.216111660003662, [-0.8811989426612854, -0.2...\n",
       "2     [4.820352077484131, [-0.9042707085609436, -0.2...\n",
       "3     [3.285065174102783, [-0.9259941577911377, -0.2...\n",
       "4     [2.013909101486206, [-0.9140456914901733, -0.3...\n",
       "5     [2.750776767730713, [-0.8847323060035706, -0.2...\n",
       "6     [1.8918119668960571, [-0.8730267286300659, -0....\n",
       "7     [5.782482147216797, [-0.9126942157745361, -0.3...\n",
       "8     [5.027541160583496, [-0.9183965921401978, -0.2...\n",
       "9     [1.8539708852767944, [-0.9144101738929749, -0....\n",
       "10    [3.9321811199188232, [-0.8665366768836975, -0....\n",
       "11    [3.068100929260254, [-0.8456717133522034, -0.2...\n",
       "12    [2.01381778717041, [-0.8563892841339111, -0.43...\n",
       "14    [1.7035424709320068, [-0.8430359959602356, -0....\n",
       "15    [2.4735491275787354, [-0.7731654047966003, -0....\n",
       "16    [1.9176887273788452, [-0.8152227401733398, -0....\n",
       "17    [2.430889844894409, [-0.8900861740112305, -0.3...\n",
       "18    [1.6459747552871704, [-0.7824556827545166, -0....\n",
       "19    [1.318286657333374, [-0.8672002553939819, -0.3...\n",
       "20    [3.4722657203674316, [-0.7698777914047241, -0....\n",
       "21    [4.7200236320495605, [-0.841616153717041, -0.1...\n",
       "22    [4.3272175788879395, [-0.8560453653335571, -0....\n",
       "23    [4.4580535888671875, [-0.8329973816871643, -0....\n",
       "24    [4.602021217346191, [-0.896698534488678, -0.22...\n",
       "25    [4.8144941329956055, [-0.8892493844032288, -0....\n",
       "26    [4.9346489906311035, [-0.917271077632904, -0.2...\n",
       "27    [3.1254734992980957, [-0.8619669675827026, -0....\n",
       "28    [4.516481399536133, [-0.8446433544158936, -0.1...\n",
       "29    [4.090731620788574, [-0.8632316589355469, -0.1...\n",
       "30    [2.4618544578552246, [-0.8268725275993347, -0....\n",
       "31    [5.273684501647949, [-0.8789443969726562, -0.2...\n",
       "32    [4.290997505187988, [-0.8713956475257874, -0.3...\n",
       "33    [1.679938554763794, [-0.8656217455863953, -0.1...\n",
       "34    [2.607694149017334, [-0.8361717462539673, -0.2...\n",
       "35    [1.9697431325912476, [-0.8512041568756104, -0....\n",
       "36    [3.9581973552703857, [-0.8823409676551819, -0....\n",
       "37    [3.8590359687805176, [-0.90473473072052, -0.21...\n",
       "38    [2.568978786468506, [-0.9106586575508118, -0.2...\n",
       "39    [1.8100850582122805, [-0.8967411518096924, -0....\n",
       "40    [2.185464382171631, [-0.891177773475647, -0.28...\n",
       "41    [2.8507373332977295, [-0.9047838449478149, -0....\n",
       "42    [2.999174118041992, [-0.89850252866745, -0.468...\n",
       "43    [3.1167471408843994, [-0.9202572107315063, -0....\n",
       "44    [2.5410046577453613, [-0.9222267270088196, -0....\n",
       "45    [2.421492576599121, [-0.9192697405815125, -0.3...\n",
       "46    [3.1219165325164795, [-0.954107940196991, -0.4...\n",
       "47    [3.2749857902526855, [-0.8829483389854431, -0....\n",
       "49    [2.97369647026062, [-0.8921160697937012, -0.19...\n",
       "Name: Expression_Embeddings, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subject_Out_1_Nor_0_Aut_0_DR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_0 == 1: \n",
    "    SVM_Dict_Out_1_Nor_0_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                 y_Cell_Type              = Cell_Type, \n",
    "                                                 subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\", \n",
    "                                                 subject_outlier          = subject_outlier, \n",
    "                                                 subject_normalization    = subject_normalization, \n",
    "                                                 subject_autoencoder      = subject_autoencoder, \n",
    "                                                 subject_dimension        = subject_dimension,\n",
    "                                                 data_source = \"list\" )\n",
    "    Model_SVM_Out_1_Nor_0_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_0_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_0_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_0_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_1 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_0_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_0_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_0_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_0_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_0_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_2 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_0 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_0                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_0          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_0  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_0           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n",
      "kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale\n"
     ]
    }
   ],
   "source": [
    "if switch_SVM_3 == 1: \n",
    "    SVM_Dict_Out_1_Nor_1_Aut_1_DR_1 = SVM_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                           y_Cell_Type              = Cell_Type, \n",
    "                                           subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\", \n",
    "                                           subject_outlier          = subject_outlier, \n",
    "                                           subject_normalization    = subject_normalization, \n",
    "                                           subject_autoencoder      = subject_autoencoder, \n",
    "                                           subject_dimension        = subject_dimension  ,\n",
    "                                           data_source = \"list\" ) \n",
    "    Model_SVM_Out_1_Nor_1_Aut_1_DR_1                = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SVM_Out_1_Nor_1_Aut_1_DR_1          = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Out_1_Nor_1_Aut_1_DR_1  = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SVM_Out_1_Nor_1_Aut_1_DR_1           = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2- `Operation: SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_0 == 1: \n",
    "    SGD_Dict_Out_1_Nor_0_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                    y_Cell_Type           = Cell_Type,\n",
    "                                                    subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                    subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )  \n",
    "    Model_SGD_Out_1_Nor_0_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_0_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_0_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_0_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_1 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_0_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )  \n",
    "    Model_SGD_Out_1_Nor_1_Aut_0_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_0_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_0_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_0_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_0 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_0                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_0          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_0  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_0           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n",
      "Debug 1.4\n",
      "alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001\n"
     ]
    }
   ],
   "source": [
    "if switch_SGD_2 == 1: \n",
    "    SGD_Dict_Out_1_Nor_1_Aut_1_DR_1 = SGD_Method(X_Gene_Marker_Embeddings           = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension,\n",
    "                                                        data_source = \"list\" )   \n",
    "    Model_SGD_Out_1_Nor_1_Aut_1_DR_1                = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_SGD_Out_1_Nor_1_Aut_1_DR_1          = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Out_1_Nor_1_Aut_1_DR_1  = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_SGD_Out_1_Nor_1_Aut_1_DR_1           = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3- `Operation: Random Forest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_0 == 1: \n",
    "    RF_Dict_Out_1_Nor_0_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )    \n",
    "    Model_RF_Out_1_Nor_0_Aut_0_DR_0                = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_0_Aut_0_DR_0          = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_0_Aut_0_DR_0  = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_0_Aut_0_DR_0           = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_1 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_0_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension, \n",
    "                                                data_source = \"list\" )  \n",
    "    Model_RF_Out_1_Nor_1_Aut_0_DR_0                = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_0_DR_0          = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_0_DR_0  = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_0_DR_0           = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_0 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_0                = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_0          = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_0  = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_0           = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_2 == 1: \n",
    "    RF_Dict_Out_1_Nor_1_Aut_1_DR_1 = RF_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                            y_Cell_Type           = Cell_Type,\n",
    "                                            subject_label         = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                                subject_outlier       = subject_outlier, \n",
    "                                                subject_normalization = subject_normalization, \n",
    "                                                subject_autoencoder   = subject_autoencoder,\n",
    "                                                subject_dimension     = subject_dimension,\n",
    "                                                data_source = \"list\" )   \n",
    "    Model_RF_Out_1_Nor_1_Aut_1_DR_1                = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_RF_Out_1_Nor_1_Aut_1_DR_1          = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Out_1_Nor_1_Aut_1_DR_1  = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_RF_Out_1_Nor_1_Aut_1_DR_1           = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4- `Operation: Decision Tree`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_0 == 1: \n",
    "    DT_Dict_Out_1_Nor_0_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_0_Aut_0_DR_0\",\n",
    "                                        subject_outlier       = subject_outlier, \n",
    "                                        subject_normalization = subject_normalization, \n",
    "                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                        subject_dimension     = subject_dimension,\n",
    "                                        data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_0_Aut_0_DR_0                = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_0_Aut_0_DR_0          = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_0_Aut_0_DR_0  = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_0_Aut_0_DR_0           = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_1 == 1: \n",
    "  DT_Dict_Out_1_Nor_1_Aut_0_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0,\n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_0_DR_0\",\n",
    "                                            subject_outlier       = subject_outlier, \n",
    "                                            subject_normalization = subject_normalization, \n",
    "                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                            subject_dimension     = subject_dimension,\n",
    "                                            data_source = \"list\" )   \n",
    "  Model_DT_Out_1_Nor_1_Aut_0_DR_0                = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "  Predictions_DT_Out_1_Nor_1_Aut_0_DR_0          = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "  Statistics_Detailed_DT_Out_1_Nor_1_Aut_0_DR_0  = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "  Statistics_DT_Out_1_Nor_1_Aut_0_DR_0           = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_2 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_0 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_0\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_0                = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_0          = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_0  = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_0           = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_3 == 1: \n",
    "    DT_Dict_Out_1_Nor_1_Aut_1_DR_1 = DT_Method(\n",
    "                                        X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                        y_Cell_Type              = Cell_Type,\n",
    "                                        subject_label            = \"Out_1_Nor_1_Aut_1_DR_1\",\n",
    "                                          subject_outlier       = subject_outlier, \n",
    "                                          subject_normalization = subject_normalization, \n",
    "                                          subject_autoencoder   = subject_autoencoder,\n",
    "                                          subject_dimension     = subject_dimension, \n",
    "                                          data_source = \"list\" )   \n",
    "    Model_DT_Out_1_Nor_1_Aut_1_DR_1                = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_DT_Out_1_Nor_1_Aut_1_DR_1          = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Out_1_Nor_1_Aut_1_DR_1  = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_DT_Out_1_Nor_1_Aut_1_DR_1           = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5- `Operation: Gradient Boosting`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n",
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n"
     ]
    }
   ],
   "source": [
    "if switch_GB_0 == 1: \n",
    "    GB_Dict_Out_1_Nor_0_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_0_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_0_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier, \n",
    "                                                            subject_normalization = subject_normalization, \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension,\n",
    "                                                            data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_0_Aut_0_DR_0                = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_0_Aut_0_DR_0          = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_0_Aut_0_DR_0  = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_0_Aut_0_DR_0           = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n",
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n"
     ]
    }
   ],
   "source": [
    "if switch_GB_1 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_0_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_0_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_0_DR_0\" ,\n",
    "                                                            subject_outlier       = subject_outlier,\n",
    "                                                            subject_normalization = subject_normalization,  \n",
    "                                                            subject_autoencoder   = subject_autoencoder,\n",
    "                                                            subject_dimension     = subject_dimension, \n",
    "                                                            data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_0_DR_0                = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_0_DR_0          = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_0_DR_0  = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_0_DR_0           = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Main`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n",
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n"
     ]
    }
   ],
   "source": [
    "if switch_GB_2 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_0 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_0, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_0\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_0                = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_0          = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_0  = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_0           = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n",
      "learning_rate_0.2_max_depth_7_min_samples_leaf_1_min_samples_split_2_n_estimators_100\n"
     ]
    }
   ],
   "source": [
    "if switch_GB_3 == 1: \n",
    "    GB_Dict_Out_1_Nor_1_Aut_1_DR_1 = GB_Method(X_Gene_Marker_Embeddings = Subject_Out_1_Nor_1_Aut_1_DR_1, \n",
    "                                                        y_Cell_Type           = Cell_Type,\n",
    "                                                        subject_label         =\"Out_1_Nor_1_Aut_1_DR_1\" ,\n",
    "                                                        subject_outlier       = subject_outlier, \n",
    "                                                        subject_normalization = subject_normalization, \n",
    "                                                        subject_autoencoder   = subject_autoencoder,\n",
    "                                                        subject_dimension     = subject_dimension, \n",
    "                                                        data_source = \"list\" )    \n",
    "    Model_GB_Out_1_Nor_1_Aut_1_DR_1                = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"] \n",
    "    Predictions_GB_Out_1_Nor_1_Aut_1_DR_1          = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Predictions\"]\n",
    "    Statistics_Detailed_GB_Out_1_Nor_1_Aut_1_DR_1  = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics\"]\n",
    "    Statistics_GB_Out_1_Nor_1_Aut_1_DR_1           = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4- `Operation: Combine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-) `Statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All = pd.DataFrame() \n",
    "if switch_N_0 == 1: \n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_0_Aut_0_DR_0], axis = 0) \n",
    "if switch_N_1 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_0_DR_0], axis = 0)\n",
    "if switch_N_2 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_0], axis = 0) \n",
    "if switch_N_3 == 1:\n",
    "    NN_All = pd.concat([NN_All, Statistics_NeNe_Out_1_Nor_1_Aut_1_DR_1], axis = 0) \n",
    "\n",
    "SVM_All = pd.DataFrame() \n",
    "if switch_SVM_0 == 1: \n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "if switch_SVM_1 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SVM_2 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0) \n",
    "if switch_SVM_3 == 1:\n",
    "    SVM_All = pd.concat([SVM_All, SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0) \n",
    "\n",
    "SGD_All = pd.DataFrame()\n",
    "if switch_SGD_0 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_1 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_2 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_SGD_3 == 1:\n",
    "    SGD_All = pd.concat([SGD_All, SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "DT_All = pd.DataFrame() \n",
    "if switch_DT_0 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_1 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_2 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_DT_3 == 1:\n",
    "    DT_All = pd.concat([DT_All, DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "\n",
    "RF_All = pd.DataFrame()\n",
    "if switch_RF_0 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_1 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_2 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_RF_3 == 1:\n",
    "    RF_All = pd.concat([RF_All, RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n",
    "\n",
    "GB_All = pd.DataFrame()\n",
    "if switch_GB_0 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_1 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_2 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Statistics_DF\"]], axis = 0)\n",
    "if switch_GB_3 == 1:\n",
    "    GB_All = pd.concat([GB_All, GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Statistics_DF\"]], axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) `Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_NN_Models_Dict = {} \n",
    "\n",
    "\n",
    "NN_All_Models = []\n",
    "NN_All_Encoders = [] \n",
    "if switch_N_0 == 1: \n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_0_Aut_0_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0)\n",
    "\n",
    "        Barcode_NN_Models_Dict[\"Model_0\"]   = Model_NeNe_Out_1_Nor_0_Aut_0_DR_0\n",
    "        Barcode_NN_Models_Dict[\"Encoder_0\"] = Encoder_NeNe_Out_1_Nor_0_Aut_0_DR_0 \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_N_1 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_0_DR_0)\n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0) \n",
    "\n",
    "        Barcode_NN_Models_Dict[\"Model_1\"]   = Model_NeNe_Out_1_Nor_1_Aut_0_DR_0\n",
    "        Barcode_NN_Models_Dict[\"Encoder_1\"] = Encoder_NeNe_Out_1_Nor_1_Aut_0_DR_0 \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_N_2 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_0) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0)\n",
    "\n",
    "        Barcode_NN_Models_Dict[\"Model_2\"]   = Model_NeNe_Out_1_Nor_1_Aut_1_DR_0\n",
    "        Barcode_NN_Models_Dict[\"Encoder_2\"] = Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_0\n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_N_3 == 1:\n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1) \n",
    "\n",
    "        Barcode_NN_Models_Dict[\"Model_3\"]   = Model_NeNe_Out_1_Nor_1_Aut_1_DR_1\n",
    "        Barcode_NN_Models_Dict[\"Encoder_3\"] = Encoder_NeNe_Out_1_Nor_1_Aut_1_DR_1 \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Out_1_Nor_1_Aut_1_DR_1\")  \n",
    "\n",
    "NN_All_Models_Dict = {} \n",
    "for i in range(len(NN_All_Models)):\n",
    "    NN_All_Models_Dict[f\"Model_{i}\"] = NN_All_Models[i] \n",
    "\n",
    "NN_All_Encoders_Dict = {}\n",
    "for i in range(len(NN_All_Encoders)):\n",
    "    NN_All_Encoders_Dict[f\"Encoder_{i}\"] = NN_All_Encoders[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_SVM_Models_Dict = {} \n",
    "\n",
    "SVM_All_Models = []\n",
    "if switch_SVM_0 == 1: \n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "        Barcode_SVM_Models_Dict[\"Model_0\"] = SVM_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_SVM_1 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "        Barcode_SVM_Models_Dict[\"Model_1\"] = SVM_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SVM_2 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "        Barcode_SVM_Models_Dict[\"Model_2\"] = SVM_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SVM_3 == 1:\n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "        Barcode_SVM_Models_Dict[\"Model_3\"] = SVM_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "\n",
    "SVM_All_Models_Dict = {} \n",
    "for i in range(len(SVM_All_Models)):\n",
    "    SVM_All_Models_Dict[f\"Model_{i}\"] = SVM_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_SGD_Models_Dict = {} \n",
    "\n",
    "SGD_All_Models = []\n",
    "if switch_SGD_0 == 1: \n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "        Barcode_SGD_Models_Dict[\"Model_0\"] = SGD_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_SGD_1 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "        Barcode_SGD_Models_Dict[\"Model_1\"] = SGD_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_SGD_2 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "        Barcode_SGD_Models_Dict[\"Model_2\"] = SGD_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_SGD_3 == 1:\n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "        Barcode_SGD_Models_Dict[\"Model_3\"] = SGD_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "\n",
    "SGD_All_Models_Dict = {} \n",
    "for i in range(len(SGD_All_Models)):\n",
    "    SGD_All_Models_Dict[f\"Model_{i}\"] = SGD_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_DT_Models_Dict = {} \n",
    "\n",
    "DT_All_Models = []\n",
    "if switch_DT_0 == 1: \n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "        Barcode_DT_Models_Dict[\"Model_0\"] = DT_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_DT_1 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "        Barcode_DT_Models_Dict[\"Model_1\"] = DT_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_DT_2 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "        Barcode_DT_Models_Dict[\"Model_2\"] = DT_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_DT_3 == 1:\n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "        Barcode_DT_Models_Dict[\"Model_3\"] = DT_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "\n",
    "DT_All_Models_Dict = {} \n",
    "for i in range(len(DT_All_Models)):\n",
    "    DT_All_Models_Dict[f\"Model_{i}\"] = DT_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_RF_Models_Dict = {} \n",
    "\n",
    "RF_All_Models = []\n",
    "if switch_RF_0 == 1: \n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "        Barcode_RF_Models_Dict[\"Model_0\"] = RF_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_RF_1 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "        Barcode_RF_Models_Dict[\"Model_1\"] = RF_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_RF_2 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "        Barcode_RF_Models_Dict[\"Model_2\"] = RF_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_RF_3 == 1:\n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "        Barcode_RF_Models_Dict[\"Model_3\"] = RF_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "\n",
    "RF_All_Models_Dict = {} \n",
    "for i in range(len(RF_All_Models)):\n",
    "    RF_All_Models_Dict[f\"Model_{i}\"] = RF_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_GB_Models_Dict = {} \n",
    "\n",
    "GB_All_Models = []\n",
    "if switch_GB_0 == 1: \n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]) \n",
    "        Barcode_GB_Models_Dict[\"Model_0\"] = GB_Dict_Out_1_Nor_0_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_0_Aut_0_DR_0\")  \n",
    "if switch_GB_1 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"])\n",
    "        Barcode_GB_Models_Dict[\"Model_1\"] = GB_Dict_Out_1_Nor_1_Aut_0_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_0_DR_0\") \n",
    "if switch_GB_2 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]) \n",
    "        Barcode_GB_Models_Dict[\"Model_2\"] = GB_Dict_Out_1_Nor_1_Aut_1_DR_0[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_0\")  \n",
    "\n",
    "if switch_GB_3 == 1:\n",
    "    try:\n",
    "        GB_All_Models.append(GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]) \n",
    "        Barcode_GB_Models_Dict[\"Model_3\"] = GB_Dict_Out_1_Nor_1_Aut_1_DR_1[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | GB_Dict_Out_1_Nor_1_Aut_1_DR_1\") \n",
    "\n",
    "\n",
    "GB_All_Models_Dict = {} \n",
    "for i in range(len(GB_All_Models)):\n",
    "    GB_All_Models_Dict[f\"Model_{i}\"] = GB_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_0': <keras.src.engine.functional.Functional at 0x31cb53e50>,\n",
       " 'Model_1': <keras.src.engine.functional.Functional at 0x3200a97d0>,\n",
       " 'Model_2': <keras.src.engine.functional.Functional at 0x325292c90>,\n",
       " 'Model_3': <keras.src.engine.functional.Functional at 0x31b507dd0>}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_All_Models_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-) `Report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject Outlier: ZScore_v0_ZScore_v0\n",
      "Subject Normalization: StandardScaler_StandardScaler\n",
      "Subject Autoencoder: Basic_v1_Basic_v1\n",
      "Subject Dimension: PCA_n3_Free\n"
     ]
    }
   ],
   "source": [
    "print(f\"Subject Outlier: {subject_outlier}\")\n",
    "print(f\"Subject Normalization: {subject_normalization}\") \n",
    "print(f\"Subject Autoencoder: {subject_autoencoder}\")\n",
    "print(f\"Subject Dimension: {subject_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>GB</td>\n",
       "      <td>learning_rate_0.2_max_depth_7_min_samples_leaf...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>GB</td>\n",
       "      <td>learning_rate_0.2_max_depth_7_min_samples_leaf...</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.808333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>GB</td>\n",
       "      <td>learning_rate_0.2_max_depth_7_min_samples_leaf...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.771111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.645714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.608333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.608333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>RF</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.608333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>GB</td>\n",
       "      <td>learning_rate_0.2_max_depth_7_min_samples_leaf...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.602381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.546296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>DT</td>\n",
       "      <td>Basic</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.535556</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.470370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.359788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.161905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.108889</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>SGD</td>\n",
       "      <td>alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Applications  \\\n",
       "21  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "16  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "17  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "10  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "18  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "11  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "5   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "15  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "20  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "12  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "13  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "14  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "19  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "1   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "8   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "9   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "2   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "4   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "3   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "22  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "7   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "23  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "6   ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "\n",
       "         Applications_Condition Model  \\\n",
       "21       Out_1_Nor_1_Aut_0_DR_0   SGD   \n",
       "16       Out_1_Nor_0_Aut_0_DR_0    GB   \n",
       "17       Out_1_Nor_1_Aut_0_DR_0    GB   \n",
       "10       Out_1_Nor_1_Aut_1_DR_0    DT   \n",
       "18       Out_1_Nor_1_Aut_1_DR_0    GB   \n",
       "11       Out_1_Nor_1_Aut_1_DR_1    DT   \n",
       "5        Out_1_Nor_1_Aut_0_DR_0   SVM   \n",
       "15       Out_1_Nor_1_Aut_1_DR_1    RF   \n",
       "20       Out_1_Nor_0_Aut_0_DR_0   SGD   \n",
       "12       Out_1_Nor_0_Aut_0_DR_0    RF   \n",
       "13       Out_1_Nor_1_Aut_0_DR_0    RF   \n",
       "14       Out_1_Nor_1_Aut_1_DR_0    RF   \n",
       "19       Out_1_Nor_1_Aut_1_DR_1    GB   \n",
       "1   Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "8        Out_1_Nor_0_Aut_0_DR_0    DT   \n",
       "9        Out_1_Nor_1_Aut_0_DR_0    DT   \n",
       "0   Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "2   Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "4        Out_1_Nor_0_Aut_0_DR_0   SVM   \n",
       "3   Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "22       Out_1_Nor_1_Aut_1_DR_0   SGD   \n",
       "7        Out_1_Nor_1_Aut_1_DR_1   SVM   \n",
       "23       Out_1_Nor_1_Aut_1_DR_1   SGD   \n",
       "6        Out_1_Nor_1_Aut_1_DR_0   SVM   \n",
       "\n",
       "                                           Parameters  Accuracy  Precision  \\\n",
       "21     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  1.000000   1.000000   \n",
       "16  learning_rate_0.2_max_depth_7_min_samples_leaf...  0.900000   0.950000   \n",
       "17  learning_rate_0.2_max_depth_7_min_samples_leaf...  0.900000   0.950000   \n",
       "10                                              Basic  0.800000   0.900000   \n",
       "18  learning_rate_0.2_max_depth_7_min_samples_leaf...  0.800000   0.783333   \n",
       "11                                              Basic  0.700000   0.850000   \n",
       "5      kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  0.700000   0.883333   \n",
       "15                                              Basic  0.600000   0.833333   \n",
       "20     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  0.600000   0.775000   \n",
       "12                                              Basic  0.600000   0.700000   \n",
       "13                                              Basic  0.600000   0.700000   \n",
       "14                                              Basic  0.600000   0.700000   \n",
       "19  learning_rate_0.2_max_depth_7_min_samples_leaf...  0.600000   0.833333   \n",
       "1   exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.744444   0.477778   \n",
       "8                                               Basic  0.500000   0.608333   \n",
       "9                                               Basic  0.500000   0.608333   \n",
       "0   exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.535556   0.481481   \n",
       "2   exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.153333   0.305556   \n",
       "4      kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  0.300000   0.116667   \n",
       "3   exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.108889   0.129630   \n",
       "22     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  0.200000   0.111111   \n",
       "7      kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  0.100000   0.033333   \n",
       "23     alpha_0.01_max_iter_1000_penalty_l2_tol_0.0001  0.100000   0.033333   \n",
       "6      kernel_poly_degree_2_coef0_0.5_C_1_gamma_scale  0.100000   0.020000   \n",
       "\n",
       "      Recall        F1  \n",
       "21  1.000000  1.000000  \n",
       "16  0.900000  0.911111  \n",
       "17  0.900000  0.911111  \n",
       "10  0.800000  0.808333  \n",
       "18  0.800000  0.771111  \n",
       "11  0.700000  0.741667  \n",
       "5   0.700000  0.725000  \n",
       "15  0.600000  0.645714  \n",
       "20  0.600000  0.615000  \n",
       "12  0.600000  0.608333  \n",
       "13  0.600000  0.608333  \n",
       "14  0.600000  0.608333  \n",
       "19  0.600000  0.602381  \n",
       "1   0.666667  0.546296  \n",
       "8   0.500000  0.516667  \n",
       "9   0.500000  0.516667  \n",
       "0   0.555556  0.470370  \n",
       "2   0.444444  0.359788  \n",
       "4   0.300000  0.161905  \n",
       "3   0.222222  0.142857  \n",
       "22  0.200000  0.120000  \n",
       "7   0.100000  0.050000  \n",
       "23  0.100000  0.050000  \n",
       "6   0.100000  0.033333  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Data = pd.concat([NN_All, SVM_All, DT_All, RF_All, GB_All, SGD_All], axis=0) \n",
    "All_Data.reset_index(drop=True, inplace=True) \n",
    "All_Data.sort_values(by = [\"F1\"], ascending= False, inplace = True)  \n",
    "All_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2a6e455e_e875'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid \n",
    "\n",
    "unique_label = \"_\".join(str(uuid.uuid4()).split(\"-\")[0:2] )\n",
    "unique_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Models = {} \n",
    "All_Models[\"NN\"]  = [Barcode_NN_Models_Dict, NN_All_Encoders_Dict] \n",
    "All_Models[\"SVM\"] = [Barcode_SVM_Models_Dict, \"None\"] \n",
    "All_Models[\"SGD\"] = [Barcode_SGD_Models_Dict, \"None\"]\n",
    "All_Models[\"DT\"]  = [Barcode_DT_Models_Dict, \"None\"]\n",
    "All_Models[\"RF\"]  = [Barcode_RF_Models_Dict, \"None\"]\n",
    "All_Models[\"GB\"]  = [Barcode_GB_Models_Dict, \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>process</th>\n",
       "      <th>model_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>applications_condition</th>\n",
       "      <th>applications</th>\n",
       "      <th>model</th>\n",
       "      <th>encoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40af00a1_b0ce</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.535556</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>&lt;keras.src.engine.functional.Functional object...</td>\n",
       "      <td>LabelEncoder()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d98030a1_05c2</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>&lt;keras.src.engine.functional.Functional object...</td>\n",
       "      <td>LabelEncoder()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211f492_628b</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>&lt;keras.src.engine.functional.Functional object...</td>\n",
       "      <td>LabelEncoder()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2e1208e5_896a</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.108889</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>&lt;keras.src.engine.functional.Functional object...</td>\n",
       "      <td>LabelEncoder()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8d8ff70a_e03b</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff54cf6e_81fb</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e7e61604_2b93</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b7c9047_b373</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8aee1c8d_90f3</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58e8b4a0_78c0</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4c03967b_c533</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886b37e0_3ad9</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61aa1221_be11</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3c7b9790_ec84</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24062299_8350</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211707b_62cc</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f0175dbc_3039</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c88fde04_119b</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2cd0e9f7_6540</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34a48988_6495</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9a83e717_044d</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SGDClassifier(alpha=0.01, random_state=42, tol...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7bdb1dc7_a435</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SGD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SGDClassifier(alpha=0.01, random_state=42, tol...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9da2483d_4d9d</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SGDClassifier(alpha=0.01, random_state=42, tol...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6103eb2f_ae70</th>\n",
       "      <td>process_2_BERT</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1</td>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>SGDClassifier(alpha=0.01, random_state=42, tol...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      process model_type  accuracy  \\\n",
       "40af00a1_b0ce  process_2_BERT         NN  0.535556   \n",
       "d98030a1_05c2  process_2_BERT         NN  0.744444   \n",
       "3211f492_628b  process_2_BERT         NN  0.153333   \n",
       "2e1208e5_896a  process_2_BERT         NN  0.108889   \n",
       "8d8ff70a_e03b  process_2_BERT        SVM       0.3   \n",
       "ff54cf6e_81fb  process_2_BERT        SVM       0.7   \n",
       "e7e61604_2b93  process_2_BERT        SVM       0.1   \n",
       "1b7c9047_b373  process_2_BERT        SVM       0.1   \n",
       "8aee1c8d_90f3  process_2_BERT         DT       0.5   \n",
       "58e8b4a0_78c0  process_2_BERT         DT       0.5   \n",
       "4c03967b_c533  process_2_BERT         DT       0.8   \n",
       "886b37e0_3ad9  process_2_BERT         DT       0.7   \n",
       "61aa1221_be11  process_2_BERT         RF       0.6   \n",
       "3c7b9790_ec84  process_2_BERT         RF       0.6   \n",
       "24062299_8350  process_2_BERT         RF       0.6   \n",
       "6211707b_62cc  process_2_BERT         RF       0.6   \n",
       "f0175dbc_3039  process_2_BERT         GB       0.9   \n",
       "c88fde04_119b  process_2_BERT         GB       0.9   \n",
       "2cd0e9f7_6540  process_2_BERT         GB       0.8   \n",
       "34a48988_6495  process_2_BERT         GB       0.6   \n",
       "9a83e717_044d  process_2_BERT        SGD       0.6   \n",
       "7bdb1dc7_a435  process_2_BERT        SGD       1.0   \n",
       "9da2483d_4d9d  process_2_BERT        SGD       0.2   \n",
       "6103eb2f_ae70  process_2_BERT        SGD       0.1   \n",
       "\n",
       "                    applications_condition  \\\n",
       "40af00a1_b0ce  Out_1_Nor_0_Aut_0_DR_0_NeNe   \n",
       "d98030a1_05c2  Out_1_Nor_1_Aut_0_DR_0_NeNe   \n",
       "3211f492_628b  Out_1_Nor_1_Aut_1_DR_0_NeNe   \n",
       "2e1208e5_896a  Out_1_Nor_1_Aut_1_DR_1_NeNe   \n",
       "8d8ff70a_e03b       Out_1_Nor_0_Aut_0_DR_0   \n",
       "ff54cf6e_81fb       Out_1_Nor_1_Aut_0_DR_0   \n",
       "e7e61604_2b93       Out_1_Nor_1_Aut_1_DR_0   \n",
       "1b7c9047_b373       Out_1_Nor_1_Aut_1_DR_1   \n",
       "8aee1c8d_90f3       Out_1_Nor_0_Aut_0_DR_0   \n",
       "58e8b4a0_78c0       Out_1_Nor_1_Aut_0_DR_0   \n",
       "4c03967b_c533       Out_1_Nor_1_Aut_1_DR_0   \n",
       "886b37e0_3ad9       Out_1_Nor_1_Aut_1_DR_1   \n",
       "61aa1221_be11       Out_1_Nor_0_Aut_0_DR_0   \n",
       "3c7b9790_ec84       Out_1_Nor_1_Aut_0_DR_0   \n",
       "24062299_8350       Out_1_Nor_1_Aut_1_DR_0   \n",
       "6211707b_62cc       Out_1_Nor_1_Aut_1_DR_1   \n",
       "f0175dbc_3039       Out_1_Nor_0_Aut_0_DR_0   \n",
       "c88fde04_119b       Out_1_Nor_1_Aut_0_DR_0   \n",
       "2cd0e9f7_6540       Out_1_Nor_1_Aut_1_DR_0   \n",
       "34a48988_6495       Out_1_Nor_1_Aut_1_DR_1   \n",
       "9a83e717_044d       Out_1_Nor_0_Aut_0_DR_0   \n",
       "7bdb1dc7_a435       Out_1_Nor_1_Aut_0_DR_0   \n",
       "9da2483d_4d9d       Out_1_Nor_1_Aut_1_DR_0   \n",
       "6103eb2f_ae70       Out_1_Nor_1_Aut_1_DR_1   \n",
       "\n",
       "                                                    applications  \\\n",
       "40af00a1_b0ce  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "d98030a1_05c2  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "3211f492_628b  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "2e1208e5_896a  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "8d8ff70a_e03b  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "ff54cf6e_81fb  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "e7e61604_2b93  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "1b7c9047_b373  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "8aee1c8d_90f3  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "58e8b4a0_78c0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "4c03967b_c533  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "886b37e0_3ad9  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "61aa1221_be11  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "3c7b9790_ec84  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "24062299_8350  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "6211707b_62cc  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "f0175dbc_3039  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "c88fde04_119b  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "2cd0e9f7_6540  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "34a48988_6495  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "9a83e717_044d  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "7bdb1dc7_a435  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "9da2483d_4d9d  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "6103eb2f_ae70  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "\n",
       "                                                           model  \\\n",
       "40af00a1_b0ce  <keras.src.engine.functional.Functional object...   \n",
       "d98030a1_05c2  <keras.src.engine.functional.Functional object...   \n",
       "3211f492_628b  <keras.src.engine.functional.Functional object...   \n",
       "2e1208e5_896a  <keras.src.engine.functional.Functional object...   \n",
       "8d8ff70a_e03b  SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...   \n",
       "ff54cf6e_81fb  SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...   \n",
       "e7e61604_2b93  SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...   \n",
       "1b7c9047_b373  SVC(C=1, coef0=0.5, degree=2, kernel='poly', r...   \n",
       "8aee1c8d_90f3            DecisionTreeClassifier(random_state=42)   \n",
       "58e8b4a0_78c0            DecisionTreeClassifier(random_state=42)   \n",
       "4c03967b_c533            DecisionTreeClassifier(random_state=42)   \n",
       "886b37e0_3ad9            DecisionTreeClassifier(random_state=42)   \n",
       "61aa1221_be11  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "3c7b9790_ec84  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "24062299_8350  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "6211707b_62cc  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "f0175dbc_3039  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "c88fde04_119b  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "2cd0e9f7_6540  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "34a48988_6495  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "9a83e717_044d  SGDClassifier(alpha=0.01, random_state=42, tol...   \n",
       "7bdb1dc7_a435  SGDClassifier(alpha=0.01, random_state=42, tol...   \n",
       "9da2483d_4d9d  SGDClassifier(alpha=0.01, random_state=42, tol...   \n",
       "6103eb2f_ae70  SGDClassifier(alpha=0.01, random_state=42, tol...   \n",
       "\n",
       "                      encoder  \n",
       "40af00a1_b0ce  LabelEncoder()  \n",
       "d98030a1_05c2  LabelEncoder()  \n",
       "3211f492_628b  LabelEncoder()  \n",
       "2e1208e5_896a  LabelEncoder()  \n",
       "8d8ff70a_e03b            None  \n",
       "ff54cf6e_81fb            None  \n",
       "e7e61604_2b93            None  \n",
       "1b7c9047_b373            None  \n",
       "8aee1c8d_90f3            None  \n",
       "58e8b4a0_78c0            None  \n",
       "4c03967b_c533            None  \n",
       "886b37e0_3ad9            None  \n",
       "61aa1221_be11            None  \n",
       "3c7b9790_ec84            None  \n",
       "24062299_8350            None  \n",
       "6211707b_62cc            None  \n",
       "f0175dbc_3039            None  \n",
       "c88fde04_119b            None  \n",
       "2cd0e9f7_6540            None  \n",
       "34a48988_6495            None  \n",
       "9a83e717_044d            None  \n",
       "7bdb1dc7_a435            None  \n",
       "9da2483d_4d9d            None  \n",
       "6103eb2f_ae70            None  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid \n",
    "\n",
    "model_dict = {}\n",
    "for i in range(len(All_Data)):\n",
    "    unique_label = \"_\".join(str(uuid.uuid4()).split(\"-\")[0:2] ) \n",
    "    # Take the accuracy by i\n",
    "    process    = process_barcode\n",
    "    accuracy   = All_Data[\"Accuracy\"][i] \n",
    "    model_name = All_Data[\"Model\"][i] \n",
    "\n",
    "    applications_condition = All_Data[\"Applications_Condition\"][i]  \n",
    "    applications = All_Data[\"Applications\"][i]  \n",
    "\n",
    "    try: \n",
    "        #print(f\"Model Name: {model_name}\") \n",
    "        if model_name == \"NeNe\":\n",
    "            model_name = \"NN\"\n",
    "            if applications_condition == \"Out_1_Nor_0_Aut_0_DR_0_NeNe\":\n",
    "                model   = All_Models[ \"NN\" ][0][\"Model_0\"] \n",
    "                encoder = All_Models[ \"NN\" ][0][\"Encoder_0\"] \n",
    "            elif applications_condition == \"Out_1_Nor_1_Aut_0_DR_0_NeNe\":\n",
    "                model   = All_Models[ \"NN\" ][0][\"Model_1\"] \n",
    "                encoder = All_Models[ \"NN\" ][0][\"Encoder_1\"]\n",
    "            elif applications_condition == \"Out_1_Nor_1_Aut_1_DR_0_NeNe\":\n",
    "                model   = All_Models[ \"NN\" ][0][\"Model_2\"] \n",
    "                encoder = All_Models[ \"NN\" ][0][\"Encoder_2\"]\n",
    "            elif applications_condition == \"Out_1_Nor_1_Aut_1_DR_1_NeNe\":\n",
    "                model   = All_Models[ \"NN\" ][0][\"Model_3\"] \n",
    "                encoder = All_Models[ \"NN\" ][0][\"Encoder_3\"]\n",
    "        else:\n",
    "            pass \n",
    "        \n",
    "            if applications_condition == \"Out_1_Nor_0_Aut_0_DR_0\":\n",
    "                model   = All_Models[ model_name ][0][\"Model_0\"] \n",
    "                encoder = \"None\"\n",
    "            elif applications_condition == \"Out_1_Nor_1_Aut_0_DR_0\":\n",
    "                model   = All_Models[ model_name ][0][\"Model_1\"]\n",
    "                encoder = \"None\"\n",
    "            elif applications_condition == \"Out_1_Nor_1_Aut_1_DR_0\":\n",
    "                model   = All_Models[ model_name ][0][\"Model_2\"]\n",
    "                encoder = \"None\"\n",
    "            elif applications_condition == \"Out_1_Nor_1_Aut_1_DR_1\":\n",
    "                model   = All_Models[ model_name ][0][\"Model_3\"]\n",
    "                encoder = \"None\" \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\") \n",
    "\n",
    "\n",
    "    attributes_dict = { \"process\": process,\n",
    "                        \"model_type\": model_name,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"applications_condition\":applications_condition, \n",
    "                        \"applications\": applications, \n",
    "                        \"model\": model,\n",
    "                         \"encoder\": encoder }  \n",
    "    \n",
    "    \n",
    "    model_dict[unique_label] = attributes_dict \n",
    "    \n",
    "model_Library_Current = pd.DataFrame(model_dict).T \n",
    "model_Library_Current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6- `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"data_raw\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(data_raw, file)   \n",
    "\n",
    "export_name = \"subject_data_full\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_data_full, file)   \n",
    "\n",
    "    \n",
    "export_name = \"subject_outlier_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_0, file)   \n",
    "\n",
    "export_name = \"subject_outlier_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_1, file)   \n",
    "\n",
    "export_name = \"subject_outlier\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier, file)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_normalization_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_0, file)   \n",
    "\n",
    "export_name = \"subject_normalization_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_1, file)   \n",
    "\n",
    "export_name = \"subject_normalization\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization, file)   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_autoencoder_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_0, file)   \n",
    "\n",
    "export_name = \"subject_autoencoder_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_1, file) \n",
    "\n",
    "export_name = \"subject_autoencoder\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder, file)   \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_dimension_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_0, file)   \n",
    "\n",
    "export_name = \"subject_dimension_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_1, file)   \n",
    "\n",
    "export_name = \"subject_dimension\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension, file)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Applications</th>\n",
       "      <th>Applications_Condition</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_0_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.535556</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.470370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_0_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.546296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_0_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.359788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...</td>\n",
       "      <td>Out_1_Nor_1_Aut_1_DR_1_NeNe</td>\n",
       "      <td>NeNe</td>\n",
       "      <td>exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...</td>\n",
       "      <td>0.108889</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Applications  \\\n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "0  ZScore_v0_ZScore_v0_Basic_v1_Basic_v1_Standard...   \n",
       "\n",
       "        Applications_Condition Model  \\\n",
       "0  Out_1_Nor_0_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_0_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_1_DR_0_NeNe  NeNe   \n",
       "0  Out_1_Nor_1_Aut_1_DR_1_NeNe  NeNe   \n",
       "\n",
       "                                          Parameters  Accuracy  Precision  \\\n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.535556   0.481481   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.744444   0.477778   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.153333   0.305556   \n",
       "0  exp_p0: {'GaussianNoise': 0.1}, exp_p1: {'Dens...  0.108889   0.129630   \n",
       "\n",
       "     Recall        F1  \n",
       "0  0.555556  0.470370  \n",
       "0  0.666667  0.546296  \n",
       "0  0.444444  0.359788  \n",
       "0  0.222222  0.142857  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#NN\n",
    "export_name = \"NN_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All, file) \n",
    "\n",
    "# --------------------\n",
    "#SVM \n",
    "export_name = \"SVM_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All, file) \n",
    "\n",
    "# --------------------\n",
    "#SGD\n",
    "export_name = \"SGD_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "#DT\n",
    "export_name = \"DT_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All, file)\n",
    "\n",
    "# --------------------\n",
    "#RF\n",
    "export_name = \"RF_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All, file)\n",
    "\n",
    "# --------------------\n",
    "#GB\n",
    "export_name = \"GB_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#NN \n",
    "export_name = \"NN_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Models, file) \n",
    "\n",
    "# --------------------\n",
    "#SVM \n",
    "export_name = \"SVM_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All_Models, file) \n",
    "\n",
    "\n",
    "# --------------------\n",
    "#SGD\n",
    "export_name = \"SGD_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All_Models, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "#DT\n",
    "export_name = \"DT_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "#RF\n",
    "export_name = \"RF_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "#GB\n",
    "export_name = \"GB_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(GB_All_Models, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#NN \n",
    "export_name = \"NN_All_Encoders\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Encoders, file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"model_Library_Current\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model/library\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(model_Library_Current, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
