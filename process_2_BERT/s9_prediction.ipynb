{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 7: Predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "except: \n",
    "    %run s0_config.ipynb \n",
    "    %run s8_preparation.ipynb \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3- `Bench`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_label  = subject_outlier_0     + \"_\" + subject_outlier_1     + \"_\" + subject_normalization_0 + \"_\" + subject_normalization_1 + \"_\" \n",
    "subject_label += subject_autoencoder_0 + \"_\" + subject_autoencoder_1 + \"_\" + subject_dimension_0     + \"_\" + subject_dimension_1 + \"_\" \n",
    "subject_label = \"Out_1_Nor_1_Aut_1_DR_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0- `Operation: Neural Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_N_0 == 1: \n",
    "    \n",
    "    subject_data = pd.DataFrame() \n",
    "    subject_data[\"Expression_Embeddings\"] = subject_data_full[\"Expression_Embeddings_Final\"] # subject_data_full[\"Expression_Embeddings\"] \n",
    "    subject_data[\"Cell_Type\"]             = subject_data_full[\"Cell_Type\"] \n",
    "\n",
    "    tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"operationnn.ipynb\")     \n",
    "    %run $tool_prediction  \n",
    "\n",
    "    Model_NeNe_Final               = Subject_Process_Dict[\"Model\"] \n",
    "    Encoder_NeNe_Final             = encoder\n",
    "\n",
    "    Predictions_NeNe_Final         = Subject_Process_Dict[\"Predictions\"]\n",
    "    Statistics_Detailed_NeNe_Final = Subject_Process_Dict[\"Statistics\"]\n",
    "    Statistics_NeNe_Final          = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "    Statistics_NeNe_Final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1- `Operation: SVM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_SVM_0 == 1: \n",
    "    SVM_Dict_Final = SVM_Method(X_Gene_Marker_Embeddings = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type              = Cell_Type, \n",
    "                                subject_label            = subject_label, \n",
    "                                subject_outlier          = subject_outlier, \n",
    "                                subject_normalization    = subject_normalization, \n",
    "                                subject_autoencoder      = subject_autoencoder, \n",
    "                                subject_dimension        = subject_dimension,\n",
    "                                data_source = \"list\" )\n",
    "    Model_SVM_Final                = SVM_Dict_Final[\"Model\"] \n",
    "    Predictions_SVM_Final          = SVM_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Final  = SVM_Dict_Final[\"Statistics\"]\n",
    "    Statistics_SVM_Final           = SVM_Dict_Final[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data_full[\"Expression_Embeddings_Final\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    SVM_Dict_Final = prediction_model_SVM_with_GridSearch(X_Gene_Marker_Embeddings = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type              = Cell_Type, \n",
    "                                subject_label            = subject_label, \n",
    "                                subject_outlier          = subject_outlier, \n",
    "                                subject_normalization    = subject_normalization, \n",
    "                                subject_autoencoder      = subject_autoencoder, \n",
    "                                subject_dimension        = subject_dimension,\n",
    "                                 )\n",
    "    Model_SVM_Final                = SVM_Dict_Final[\"Model\"] \n",
    "    Predictions_SVM_Final          = SVM_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Final  = SVM_Dict_Final[\"Statistics\"]\n",
    "    Statistics_SVM_Final           = SVM_Dict_Final[\"Statistics_DF\"] \n",
    "    SVM_Dict_Final[\"Statistics_DF\"]  = SVM_Dict_Final[\"All_Results\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM_Dict_Final[\"All_Results\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2- `Operation: SGD`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_SGD_0 == 1: \n",
    "    SGD_Dict_Final = SGD_Method(X_Gene_Marker_Embeddings           = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type           = Cell_Type,\n",
    "                                subject_label         = subject_label,\n",
    "                                subject_outlier       = subject_outlier, \n",
    "                                subject_normalization = subject_normalization, \n",
    "                                subject_autoencoder   = subject_autoencoder,\n",
    "                                subject_dimension     = subject_dimension, \n",
    "                                data_source = \"list\" )  \n",
    "    Model_SGD_Final                = SGD_Dict_Final[\"Model\"] \n",
    "    Predictions_SGD_Final          = SGD_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Final  = SGD_Dict_Final[\"Statistics\"]\n",
    "    Statistics_SGD_Final           = SGD_Dict_Final[\"Statistics_DF\"] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_complex_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    SGD_Dict_Final = prediction_model_SGD_multilabel(X_Gene_Marker_Embeddings = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type              = Cell_Type, \n",
    "                                subject_label            = subject_label, \n",
    "                                subject_outlier          = subject_outlier, \n",
    "                                subject_normalization    = subject_normalization, \n",
    "                                subject_autoencoder      = subject_autoencoder, \n",
    "                                subject_dimension        = subject_dimension,\n",
    "                                 )\n",
    "    Model_SGD_Final                = SGD_Dict_Final[\"Model\"] \n",
    "    Predictions_SGD_Final          = SGD_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Final  = SGD_Dict_Final[\"Statistics\"]\n",
    "    Statistics_SGD_Final           = SGD_Dict_Final[\"Statistics_DF\"] \n",
    "    SGD_Dict_Final[\"Statistics_DF\"]  = SGD_Dict_Final[\"All_Results\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD_Dict_Final[\"All_Results\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3- `Operation: Random Forest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_RF_0 == 1: \n",
    "    RF_Dict_Final = RF_Method(X_Gene_Marker_Embeddings = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type              = Cell_Type, \n",
    "                                subject_label            = subject_label, \n",
    "                                subject_outlier          = subject_outlier, \n",
    "                                subject_normalization    = subject_normalization, \n",
    "                                subject_autoencoder      = subject_autoencoder, \n",
    "                                subject_dimension        = subject_dimension,\n",
    "                                data_source = \"list\" )\n",
    "    Model_RF_Final                = RF_Dict_Final[\"Model\"] \n",
    "    Predictions_RF_Final          = RF_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Final  = RF_Dict_Final[\"Statistics\"]\n",
    "    Statistics_RF_Final           = RF_Dict_Final[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    RF_Dict_Final = prediction_model_RF_multilabel(X_Gene_Marker_Embeddings = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type              = Cell_Type, \n",
    "                                subject_label            = subject_label, \n",
    "                                subject_outlier          = subject_outlier, \n",
    "                                subject_normalization    = subject_normalization, \n",
    "                                subject_autoencoder      = subject_autoencoder, \n",
    "                                subject_dimension        = subject_dimension,\n",
    "                                 )\n",
    "    Model_RF_Final                = RF_Dict_Final[\"Model\"] \n",
    "    Predictions_RF_Final          = RF_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Final  = RF_Dict_Final[\"Statistics\"]\n",
    "    Statistics_RF_Final           = RF_Dict_Final[\"Statistics_DF\"] \n",
    "    RF_Dict_Final[\"Statistics_DF\"]  = RF_Dict_Final[\"All_Results\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistics_RF_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF_Dict_Final[\"All_Results\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4- `Operation: Decision Tree`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Detailed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_DT_0 == 1: \n",
    "    DT_Dict_Final = DT_Method(X_Gene_Marker_Embeddings = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type              = Cell_Type, \n",
    "                                subject_label            = subject_label, \n",
    "                                subject_outlier          = subject_outlier, \n",
    "                                subject_normalization    = subject_normalization, \n",
    "                                subject_autoencoder      = subject_autoencoder, \n",
    "                                subject_dimension        = subject_dimension,\n",
    "                                data_source = \"list\" )\n",
    "    Model_DT_Final                = DT_Dict_Final[\"Model\"] \n",
    "    Predictions_DT_Final          = DT_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Final  = DT_Dict_Final[\"Statistics\"]\n",
    "    Statistics_DT_Final           = DT_Dict_Final[\"Statistics_DF\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    DT_Dict_Final = prediction_model_DT_multilabel(X_Gene_Marker_Embeddings = subject_data_full[\"Expression_Embeddings_Final\"], \n",
    "                                y_Cell_Type              = Cell_Type, \n",
    "                                subject_label            = subject_label, \n",
    "                                subject_outlier          = subject_outlier, \n",
    "                                subject_normalization    = subject_normalization, \n",
    "                                subject_autoencoder      = subject_autoencoder, \n",
    "                                subject_dimension        = subject_dimension,\n",
    "                                 )\n",
    "    Model_DT_Final                = DT_Dict_Final[\"Model\"] \n",
    "    Predictions_DT_Final          = DT_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Final  = DT_Dict_Final[\"Statistics\"]\n",
    "    Statistics_DT_Final           = DT_Dict_Final[\"Statistics_DF\"] \n",
    "    DT_Dict_Final[\"Statistics_DF\"]  = DT_Dict_Final[\"All_Results\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Statistics_DT_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT_Dict_Final[\"All_Results\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4- `Operation: Combine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-) `Statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_N_0 == 1: \n",
    "        NN_All = pd.concat([NN_All, Statistics_NeNe_Final], axis = 0) \n",
    "except:\n",
    "    pass \n",
    "\n",
    "SVM_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_SVM_0 == 1: \n",
    "        SVM_All = pd.concat([SVM_All, SVM_Dict_Final[\"Statistics_DF\"]], axis = 0) \n",
    "except:\n",
    "    pass \n",
    "\n",
    "SGD_All = pd.DataFrame()\n",
    "try: \n",
    "    if switch_SGD_0 == 1:\n",
    "        SGD_All = pd.concat([SGD_All, SGD_Dict_Final[\"Statistics_DF\"]], axis = 0)\n",
    "    pass \n",
    "except:\n",
    "    pass \n",
    "\n",
    "DT_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_DT_0 == 1:\n",
    "        DT_All = pd.concat([DT_All, DT_Dict_Final[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "RF_All = pd.DataFrame()\n",
    "try:\n",
    "    if switch_RF_0 == 1:\n",
    "        RF_All = pd.concat([RF_All, RF_Dict_Final[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) `Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_NN_Models_Dict = {} \n",
    "\n",
    "\n",
    "NN_All_Models   = [] \n",
    "NN_All_Encoders = [] \n",
    "if switch_N_0 == 1: \n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Final) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Final)\n",
    "\n",
    "        Barcode_NN_Models_Dict[\"Model_0\"]   = Model_NeNe_Final \n",
    "        Barcode_NN_Models_Dict[\"Encoder_0\"] = Encoder_NeNe_Final \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Final\")  \n",
    "\n",
    "NN_All_Models_Dict = {} \n",
    "for i in range(len(NN_All_Models)): \n",
    "    NN_All_Models_Dict[f\"Model_{i}\"] = NN_All_Models[i] \n",
    "\n",
    "NN_All_Encoders_Dict = {}\n",
    "for i in range(len(NN_All_Encoders)):\n",
    "    NN_All_Encoders_Dict[f\"Encoder_{i}\"] = NN_All_Encoders[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_SVM_Models_Dict = {} \n",
    "\n",
    "SVM_All_Models = []\n",
    "if switch_SVM_0 == 1: \n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Final[\"Model\"]) \n",
    "        Barcode_SVM_Models_Dict[\"Model_0\"] = SVM_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Final\")  \n",
    "\n",
    "\n",
    "SVM_All_Models_Dict = {} \n",
    "for i in range(len(SVM_All_Models)):\n",
    "    SVM_All_Models_Dict[f\"Model_{i}\"] = SVM_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_SGD_Models_Dict = {} \n",
    "\n",
    "SGD_All_Models = []\n",
    "if switch_SGD_0 == 1: \n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Final[\"Model\"]) \n",
    "        Barcode_SGD_Models_Dict[\"Model_0\"] = SGD_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Final\")  \n",
    "\n",
    "\n",
    "SGD_All_Models_Dict = {} \n",
    "for i in range(len(SGD_All_Models)):\n",
    "    SGD_All_Models_Dict[f\"Model_{i}\"] = SGD_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_DT_Models_Dict = {} \n",
    "\n",
    "DT_All_Models = []\n",
    "if switch_DT_0 == 1: \n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Final[\"Model\"]) \n",
    "        Barcode_DT_Models_Dict[\"Model_0\"] = DT_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Final\")  \n",
    "\n",
    "\n",
    "\n",
    "DT_All_Models_Dict = {} \n",
    "for i in range(len(DT_All_Models)):\n",
    "    DT_All_Models_Dict[f\"Model_{i}\"] = DT_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_RF_Models_Dict = {} \n",
    "\n",
    "RF_All_Models = []\n",
    "if switch_RF_0 == 1: \n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Final[\"Model\"]) \n",
    "        Barcode_RF_Models_Dict[\"Model_0\"] = RF_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Final\")  \n",
    "\n",
    "RF_All_Models_Dict = {} \n",
    "for i in range(len(RF_All_Models)):\n",
    "    RF_All_Models_Dict[f\"Model_{i}\"] = RF_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All_Models_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-) `Report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Subject Outlier: {subject_outlier}\")\n",
    "print(f\"Subject Normalization: {subject_normalization}\") \n",
    "print(f\"Subject Autoencoder: {subject_autoencoder}\")\n",
    "print(f\"Subject Dimension: {subject_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Data = pd.concat([NN_All, SVM_All, SGD_All, DT_All, RF_All], axis=0) \n",
    "All_Data.reset_index(drop=True, inplace=True) \n",
    "All_Data.sort_values(by = [\"F1\"], ascending= False, inplace = True)  \n",
    "All_Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Models = {} \n",
    "All_Models[\"NN\"]  = [Barcode_NN_Models_Dict] \n",
    "All_Models[\"SVM\"] = [Barcode_SVM_Models_Dict, \"None\"] \n",
    "All_Models[\"SGD\"] = [Barcode_SGD_Models_Dict, \"None\"]\n",
    "All_Models[\"DT\"]  = [Barcode_DT_Models_Dict, \"None\"]\n",
    "All_Models[\"RF\"]  = [Barcode_RF_Models_Dict, \"None\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "\n",
    "model_dict = {}\n",
    "for i in range(len(All_Data)):\n",
    "    unique_label = \"_\".join(str(uuid.uuid4()).split(\"-\")[0:2] ) \n",
    "    # Take the accuracy by i\n",
    "    process    = process_barcode\n",
    "    accuracy   = All_Data[\"Accuracy\"][i] \n",
    "    model_name = All_Data[\"Model\"][i] \n",
    "\n",
    "    applications_condition = All_Data[\"Applications_Condition\"][i]  \n",
    "    applications = All_Data[\"Applications\"][i]  \n",
    "\n",
    "    try: \n",
    "        #print(f\"Model Name: {model_name}\") \n",
    "        if model_name == \"NeNe\":\n",
    "            model_name = \"NN\"\n",
    "            if applications_condition == \"Final_NeNe\":\n",
    "                model   = All_Models[ \"NN\" ][0][\"Model_0\"] \n",
    "                encoder = All_Models[ \"NN\" ][0][\"Encoder_0\"] \n",
    "        else:\n",
    "            pass \n",
    "        \n",
    "            if applications_condition == \"Final\":\n",
    "                model   = All_Models[ model_name ][0][\"Model_0\"] \n",
    "                encoder = \"None\"\n",
    "                encoder = \"None\" \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\") \n",
    "\n",
    "\n",
    "    attributes_dict = { \"process\": process,\n",
    "                        \"model_type\": model_name,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"applications_condition\":applications_condition, \n",
    "                        \"applications\": applications, \n",
    "                        \"model\": model,\n",
    "                         \"encoder\": encoder }  \n",
    "    \n",
    "    \n",
    "    model_dict[unique_label] = attributes_dict \n",
    "    \n",
    "model_Library_Current = pd.DataFrame(model_dict).T \n",
    "model_Library_Current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6- `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"data_raw\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(data_raw, file)   \n",
    "\n",
    "export_name = \"subject_data_full\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_data_full, file)   \n",
    "\n",
    "    \n",
    "export_name = \"subject_outlier_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_0, file)   \n",
    "\n",
    "export_name = \"subject_outlier_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_1, file)   \n",
    "\n",
    "export_name = \"subject_outlier\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier, file)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_normalization_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_0, file)   \n",
    "\n",
    "export_name = \"subject_normalization_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_1, file)   \n",
    "\n",
    "export_name = \"subject_normalization\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization, file)   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_autoencoder_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_0, file)   \n",
    "\n",
    "export_name = \"subject_autoencoder_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_1, file) \n",
    "\n",
    "export_name = \"subject_autoencoder\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder, file)   \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_dimension_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_0, file)   \n",
    "\n",
    "export_name = \"subject_dimension_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_1, file)   \n",
    "\n",
    "export_name = \"subject_dimension\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension, file)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN\n",
    "export_name = \"NN_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Models, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All_Models, file) \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All_Models, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All_Models, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Encoders\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Encoders, file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"model_Library_Current\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model/library\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(model_Library_Current, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
