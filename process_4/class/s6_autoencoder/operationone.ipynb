{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if subject_autoencoder_1 == \"Denoising_v0\": \n",
    "    # Assuming 'expressions' is your pandas Series containing the expression data\n",
    "    expressions_tensor = torch.tensor(expressions.values, dtype=torch.float32).view(-1, 1)  # Reshape to [N, 1]\n",
    "\n",
    "    # Creating a dataset and dataloader\n",
    "    dataset = TensorDataset(expressions_tensor, expressions_tensor)  # Input and target are the same for autoencoders\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    # Instantiate and train with modifications\n",
    "    model = SimpleAutoencoder(input_dim=1, encoding_dim=16)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-5)  # L2 regularization\n",
    "    criterion = nn.HuberLoss()\n",
    "\n",
    "    # Assume dataloader is defined and inputs are properly scaled\n",
    "    for epoch in range(10):\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        denoised_expressions = model(expressions_tensor).numpy().flatten()\n",
    "\n",
    "    expressions = denoised_expressions\n",
    "\n",
    "elif subject_autoencoder_1 == \"Free_v0\":\n",
    "    expressions = expressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Step 1: Define the autoencoder architecture\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Step 2: Define the denoising function with versions for different configurations\n",
    "def denoising_autoencoder(expressions, version):\n",
    "    # Convert expressions to a PyTorch tensor and reshape for single feature\n",
    "    expressions_tensor = torch.tensor(expressions.values, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    # Create a dataloader to feed data to the model in batches\n",
    "    dataset = TensorDataset(expressions_tensor, expressions_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Initialize the autoencoder model\n",
    "    model = SimpleAutoencoder(input_dim=1, encoding_dim=16)\n",
    "    \n",
    "    # Configure the model, optimizer, and loss function based on the version\n",
    "    if version == \"Denoising_v0\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-5)\n",
    "        criterion = nn.MSELoss()\n",
    "    elif version == \"Denoising_v1\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "        criterion = nn.L1Loss()\n",
    "    # Add more elif statements for additional versions\n",
    "\n",
    "    # Step 3: Train the model\n",
    "    for epoch in range(10):  # Number of epochs\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "    # Step 4: Apply the trained model to denoise the data\n",
    "    with torch.no_grad():\n",
    "        denoised_expressions = model(expressions_tensor).numpy().flatten()\n",
    "\n",
    "    # Return the denoised data and the trained model\n",
    "    return denoised_expressions, model\n",
    "\n",
    "# Step 5: Use the function with different configurations\n",
    "# Example usage:\n",
    "#denoised_v0, model_v0 = denoising_autoencoder(your_expressions_series, \"Denoising_v0\")\n",
    "#denoised_v1, model_v1 = denoising_autoencoder(your_expressions_series, \"Denoising_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
