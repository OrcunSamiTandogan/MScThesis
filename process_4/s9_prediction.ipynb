{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 7: Predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    if manager == 1:\n",
    "        print(\"s1_load.ipynb running from MANAGER\")\n",
    "except: \n",
    "    %run s0_config.ipynb \n",
    "    %run s8_preparation.ipynb \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_label  = subject_outlier_0     + \"_\" + subject_outlier_1     + \"_\" + subject_normalization_0 + \"_\" + subject_normalization_1 + \"_\" \n",
    "subject_label += subject_autoencoder_0 + \"_\" + subject_autoencoder_1 + \"_\" + subject_dimension_0     + \"_\" + subject_dimension_1 + \"_\" \n",
    "subject_label = \"Out_1_Nor_1_Aut_1_DR_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_labels(df):\n",
    "    # Extract features\n",
    "    X = np.array([np.concatenate(([row['Expression_Autoencoder']], row['Gene_Marker_One_Hot_Encoding_Autoencoder'])) for _, row in df.iterrows()])\n",
    "    \n",
    "    # Extract labels\n",
    "    y = df['Cell_Type'].values\n",
    "    return X, y\n",
    "\n",
    "# Extracted features and labels\n",
    "X_transformed_NN, y = extract_features_and_labels(subject_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract features and labels\n",
    "def extract_features_and_labels(df):\n",
    "    # Extract features\n",
    "    X = np.array([np.concatenate(([row['Expression_Autoencoder']], row['Gene_Marker_One_Hot_Encoding_Autoencoder'])) for _, row in df.iterrows()])\n",
    "    \n",
    "    # Extract labels\n",
    "    y = df['Cell_Type'].values\n",
    "    return X, y\n",
    "\n",
    "# Extracted features and labels\n",
    "X_transformed, y = extract_features_and_labels(subject_data_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "---\n",
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"NN.ipynb\")     \n",
    "%run $tool_prediction  \n",
    "\n",
    "Model_NeNe_Final               = Subject_Process_Dict[\"Model\"] \n",
    "Encoder_NeNe_Final             = encoder\n",
    "\n",
    "Predictions_NeNe_Final         = Subject_Process_Dict[\"Predictions\"]\n",
    "Statistics_Detailed_NeNe_Final = Subject_Process_Dict[\"Statistics\"]\n",
    "Statistics_NeNe_Final          = Subject_Process_Dict[\"Statistics_DF\"] \n",
    "Statistics_NeNe_Final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"SVM.ipynb\")     \n",
    "%run $tool_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the SVM function \n",
    "SVM_Dict_Final = prediction_model_SVM_multilabel_expression_onehot(X = X_transformed, \n",
    "                                                                    y = y, \n",
    "                                                                    subject_label         = subject_label, \n",
    "                                                                    subject_outlier       = subject_outlier, \n",
    "                                                                    subject_normalization = subject_normalization, \n",
    "                                                                    subject_autoencoder   = subject_autoencoder, \n",
    "                                                                    subject_dimension     = subject_dimension, \n",
    "                                                                    n_splits=5) \n",
    "Model_SVM_Final                = SVM_Dict_Final[\"Model\"] \n",
    "Predictions_SVM_Final          = SVM_Dict_Final[\"Predictions\"]\n",
    "Statistics_Detailed_SVM_Final  = SVM_Dict_Final[\"Statistics\"]\n",
    "Statistics_SVM_Final           = SVM_Dict_Final[\"Statistics_DF\"] \n",
    "Statistics_SVM_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    expressions = df['Expression_Autoencoder'].values.reshape(-1, 1)\n",
    "    gene_markers = np.array(df['Gene_Marker_One_Hot_Encoding_Autoencoder'].tolist())\n",
    "    X = np.hstack([expressions, gene_markers])\n",
    "    return X\n",
    "\n",
    "def extract_features_and_labels(df):\n",
    "    X = preprocess_data(df)\n",
    "    y = df['Cell_Type'].values\n",
    "    return X, y\n",
    "\n",
    "# Extract features and labels\n",
    "X_transformed_SVM, y = extract_features_and_labels(subject_data_full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data_full.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    # Run the SVM function \n",
    "    SVM_Dict_Final = prediction_model_SVM_with_GridSearch(X = X_transformed_SVM, \n",
    "                                                                        y = y, \n",
    "                                                                        subject_label         = subject_label, \n",
    "                                                                        subject_outlier       = subject_outlier, \n",
    "                                                                        subject_normalization = subject_normalization, \n",
    "                                                                        subject_autoencoder   = subject_autoencoder, \n",
    "                                                                        subject_dimension     = subject_dimension, \n",
    "                                                                        ) \n",
    "    Model_SVM_Final                = SVM_Dict_Final[\"Model\"] \n",
    "    Predictions_SVM_Final          = SVM_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_SVM_Final  = SVM_Dict_Final[\"Statistics\"]\n",
    "    Statistics_SVM_Final           = SVM_Dict_Final[\"Statistics_DF\"] \n",
    "    Statistics_SVM_Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"SGD.ipynb\")     \n",
    "%run $tool_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SGD_Dict_Final = prediction_model_SGD_multilabel_expression_onehot(\n",
    "                                                                    X=X_transformed, \n",
    "                                                                    y=y, \n",
    "                                                                    subject_label         = subject_label, \n",
    "                                                                    subject_outlier       = subject_outlier, \n",
    "                                                                    subject_normalization = subject_normalization, \n",
    "                                                                    subject_autoencoder   = subject_autoencoder, \n",
    "                                                                    subject_dimension     = subject_dimension, \n",
    "                                                                    n_splits=5\n",
    ")\n",
    "\n",
    "Model_SGD_Final               = SGD_Dict_Final[\"Model\"]\n",
    "Predictions_SGD_Final         = SGD_Dict_Final[\"Predictions\"]\n",
    "Statistics_Detailed_SGD_Final = SGD_Dict_Final[\"Statistics\"]\n",
    "Statistics_SGD_Final          = SGD_Dict_Final[\"Statistics_DF\"]\n",
    "Statistics_SGD_Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    expressions = df['Expression_Autoencoder'].values.reshape(-1, 1)\n",
    "    gene_markers = np.array(df['Gene_Marker_One_Hot_Encoding_Autoencoder'].tolist())\n",
    "    X = np.hstack([expressions, gene_markers])\n",
    "    return X\n",
    "\n",
    "def extract_features_and_labels(df):\n",
    "    X = preprocess_data(df)\n",
    "    y = df['Cell_Type'].values\n",
    "    return X, y\n",
    "\n",
    "X_transformed_SGD, y = extract_features_and_labels(subject_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    # Run the SGD function\n",
    "    SGD_Dict_Final = prediction_model_SGD_with_GridSearch(\n",
    "                                                                        X=X_transformed_SGD, \n",
    "                                                                        y=y, \n",
    "                                                                        subject_label         = subject_label, \n",
    "                                                                        subject_outlier       = subject_outlier, \n",
    "                                                                        subject_normalization = subject_normalization, \n",
    "                                                                        subject_autoencoder   = subject_autoencoder, \n",
    "                                                                        subject_dimension     = subject_dimension, \n",
    "                                                                        \n",
    "    )\n",
    "\n",
    "    Model_SGD_Final               = SGD_Dict_Final[\"Model\"]\n",
    "    Predictions_SGD_Final         = SGD_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_SGD_Final = SGD_Dict_Final[\"Statistics\"]\n",
    "    Statistics_SGD_Final          = SGD_Dict_Final[\"Statistics_DF\"]\n",
    "    Statistics_SGD_Final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"DT.ipynb\")     \n",
    "%run $tool_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the DT function\n",
    "DT_Dict_Final = prediction_model_DT_multilabel_expression_onehot(\n",
    "                                                                    X=X_transformed, \n",
    "                                                                    y=y, \n",
    "                                                                    subject_label         = subject_label, \n",
    "                                                                    subject_outlier       = subject_outlier, \n",
    "                                                                    subject_normalization = subject_normalization, \n",
    "                                                                    subject_autoencoder   = subject_autoencoder, \n",
    "                                                                    subject_dimension     = subject_dimension, \n",
    "                                                                     n_splits=5\n",
    ")\n",
    "\n",
    "Model_DT_Final               = DT_Dict_Final[\"Model\"]\n",
    "Predictions_DT_Final         = DT_Dict_Final[\"Predictions\"]\n",
    "Statistics_Detailed_DT_Final = DT_Dict_Final[\"Statistics\"]\n",
    "Statistics_DT_Final          = DT_Dict_Final[\"Statistics_DF\"]\n",
    "Statistics_DT_Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    expressions = df['Expression_Autoencoder'].values.reshape(-1, 1)\n",
    "    gene_markers = np.array(df['Gene_Marker_One_Hot_Encoding_Autoencoder'].tolist())\n",
    "    X = np.hstack([expressions, gene_markers])\n",
    "    return X\n",
    "\n",
    "def extract_features_and_labels(df):\n",
    "    X = preprocess_data(df)\n",
    "    y = df['Cell_Type'].values\n",
    "    return X, y\n",
    "\n",
    "# Extract features and labels\n",
    "X_transformed_DT, y = extract_features_and_labels(subject_data_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    # Run the DT function\n",
    "    DT_Dict_Final = prediction_model_DT_with_GridSearch(\n",
    "                                                                        X=X_transformed_DT, \n",
    "                                                                        y=y, \n",
    "                                                                        subject_label         = subject_label, \n",
    "                                                                        subject_outlier       = subject_outlier, \n",
    "                                                                        subject_normalization = subject_normalization, \n",
    "                                                                        subject_autoencoder   = subject_autoencoder, \n",
    "                                                                        subject_dimension     = subject_dimension, \n",
    "                                                                        \n",
    "    )\n",
    "\n",
    "    Model_DT_Final               = DT_Dict_Final[\"Model\"]\n",
    "    Predictions_DT_Final         = DT_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_DT_Final = DT_Dict_Final[\"Statistics\"]\n",
    "    Statistics_DT_Final          = DT_Dict_Final[\"Statistics_DF\"]\n",
    "    Statistics_DT_Final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_prediction = access_data_path(target_folder = f\"{process_barcode}/class/{folder_prediction}\", target_file = \"RF.ipynb\")     \n",
    "%run $tool_prediction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Random Forest function\n",
    "RF_Dict_Final = prediction_model_RF_multilabel_expression_onehot(\n",
    "                                                                    X=X_transformed, \n",
    "                                                                    y=y, \n",
    "                                                                    subject_label         = subject_label, \n",
    "                                                                    subject_outlier       = subject_outlier, \n",
    "                                                                    subject_normalization = subject_normalization, \n",
    "                                                                    subject_autoencoder   = subject_autoencoder, \n",
    "                                                                    subject_dimension     = subject_dimension, \n",
    "                                                                    n_splits=5\n",
    ")\n",
    "\n",
    "Model_RF_Final = RF_Dict_Final[\"Model\"]\n",
    "Predictions_RF_Final = RF_Dict_Final[\"Predictions\"]\n",
    "Statistics_Detailed_RF_Final = RF_Dict_Final[\"Statistics\"]\n",
    "Statistics_RF_Final = RF_Dict_Final[\"Statistics_DF\"]\n",
    "\n",
    "print(Statistics_RF_Final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    expressions = df['Expression_Autoencoder'].values.reshape(-1, 1)\n",
    "    gene_markers = np.array(df['Gene_Marker_One_Hot_Encoding_Autoencoder'].tolist())\n",
    "    X = np.hstack([expressions, gene_markers])\n",
    "    return X\n",
    "\n",
    "def extract_features_and_labels(df):\n",
    "    X = preprocess_data(df)\n",
    "    y = df['Cell_Type'].values\n",
    "    return X, y\n",
    "\n",
    "# Extract features and labels\n",
    "X_transformed_RF, y = extract_features_and_labels(subject_data_full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switch_complex_model == 1: \n",
    "    # Run the RF function\n",
    "    RF_Dict_Final = prediction_model_RF_with_GridSearch(\n",
    "                                                                        X=X_transformed_RF, \n",
    "                                                                        y=y, \n",
    "                                                                        subject_label         = subject_label, \n",
    "                                                                        subject_outlier       = subject_outlier, \n",
    "                                                                        subject_normalization = subject_normalization, \n",
    "                                                                        subject_autoencoder   = subject_autoencoder, \n",
    "                                                                        subject_dimension     = subject_dimension, \n",
    "                                                                        \n",
    "    )\n",
    "\n",
    "    Model_RF_Final               = RF_Dict_Final[\"Model\"]\n",
    "    Predictions_RF_Final         = RF_Dict_Final[\"Predictions\"]\n",
    "    Statistics_Detailed_RF_Final = RF_Dict_Final[\"Statistics\"]\n",
    "    Statistics_RF_Final          = RF_Dict_Final[\"Statistics_DF\"]\n",
    "    Statistics_RF_Final "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4- `Operation: Combine`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-) `Statistics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_N_0 == 1: \n",
    "        NN_All = pd.concat([NN_All, Statistics_NeNe_Final], axis = 0) \n",
    "except:\n",
    "    pass \n",
    "\n",
    "SVM_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_SVM_0 == 1: \n",
    "        SVM_All = pd.concat([SVM_All, SVM_Dict_Final[\"Statistics_DF\"]], axis = 0) \n",
    "except:\n",
    "    pass \n",
    "\n",
    "SGD_All = pd.DataFrame()\n",
    "try: \n",
    "    if switch_SGD_0 == 1:\n",
    "        SGD_All = pd.concat([SGD_All, SGD_Dict_Final[\"Statistics_DF\"]], axis = 0)\n",
    "    pass \n",
    "except:\n",
    "    pass \n",
    "\n",
    "DT_All = pd.DataFrame() \n",
    "try: \n",
    "    if switch_DT_0 == 1:\n",
    "        DT_All = pd.concat([DT_All, DT_Dict_Final[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n",
    "\n",
    "RF_All = pd.DataFrame()\n",
    "try:\n",
    "    if switch_RF_0 == 1:\n",
    "        RF_All = pd.concat([RF_All, RF_Dict_Final[\"Statistics_DF\"]], axis = 0)\n",
    "except:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) `Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_NN_Models_Dict = {} \n",
    "\n",
    "\n",
    "NN_All_Models   = [] \n",
    "NN_All_Encoders = [] \n",
    "if switch_N_0 == 1: \n",
    "    try:\n",
    "        NN_All_Models.append(Model_NeNe_Final) \n",
    "        NN_All_Encoders.append(Encoder_NeNe_Final)\n",
    "\n",
    "        Barcode_NN_Models_Dict[\"Model_0\"]   = Model_NeNe_Final \n",
    "        Barcode_NN_Models_Dict[\"Encoder_0\"] = Encoder_NeNe_Final \n",
    "    except:\n",
    "        print(\"Error: Model Loading | Model_NeNe_Final\")  \n",
    "\n",
    "NN_All_Models_Dict = {} \n",
    "for i in range(len(NN_All_Models)): \n",
    "    NN_All_Models_Dict[f\"Model_{i}\"] = NN_All_Models[i] \n",
    "\n",
    "NN_All_Encoders_Dict = {}\n",
    "for i in range(len(NN_All_Encoders)):\n",
    "    NN_All_Encoders_Dict[f\"Encoder_{i}\"] = NN_All_Encoders[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_SVM_Models_Dict = {} \n",
    "\n",
    "SVM_All_Models = []\n",
    "if switch_SVM_0 == 1: \n",
    "    try:\n",
    "        SVM_All_Models.append(SVM_Dict_Final[\"Model\"]) \n",
    "        Barcode_SVM_Models_Dict[\"Model_0\"] = SVM_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SVM_Dict_Final\")  \n",
    "\n",
    "\n",
    "SVM_All_Models_Dict = {} \n",
    "for i in range(len(SVM_All_Models)):\n",
    "    SVM_All_Models_Dict[f\"Model_{i}\"] = SVM_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_SGD_Models_Dict = {} \n",
    "\n",
    "SGD_All_Models = []\n",
    "if switch_SGD_0 == 1: \n",
    "    try:\n",
    "        SGD_All_Models.append(SGD_Dict_Final[\"Model\"]) \n",
    "        Barcode_SGD_Models_Dict[\"Model_0\"] = SGD_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | SGD_Dict_Final\")  \n",
    "\n",
    "\n",
    "SGD_All_Models_Dict = {} \n",
    "for i in range(len(SGD_All_Models)):\n",
    "    SGD_All_Models_Dict[f\"Model_{i}\"] = SGD_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_DT_Models_Dict = {} \n",
    "\n",
    "DT_All_Models = []\n",
    "if switch_DT_0 == 1: \n",
    "    try:\n",
    "        DT_All_Models.append(DT_Dict_Final[\"Model\"]) \n",
    "        Barcode_DT_Models_Dict[\"Model_0\"] = DT_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | DT_Dict_Final\")  \n",
    "\n",
    "\n",
    "\n",
    "DT_All_Models_Dict = {} \n",
    "for i in range(len(DT_All_Models)):\n",
    "    DT_All_Models_Dict[f\"Model_{i}\"] = DT_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Barcode_RF_Models_Dict = {} \n",
    "\n",
    "RF_All_Models = []\n",
    "if switch_RF_0 == 1: \n",
    "    try:\n",
    "        RF_All_Models.append(RF_Dict_Final[\"Model\"]) \n",
    "        Barcode_RF_Models_Dict[\"Model_0\"] = RF_Dict_Final[\"Model\"]  \n",
    "    except:\n",
    "        print(\"Error: Model Loading | RF_Dict_Final\")  \n",
    "\n",
    "RF_All_Models_Dict = {} \n",
    "for i in range(len(RF_All_Models)):\n",
    "    RF_All_Models_Dict[f\"Model_{i}\"] = RF_All_Models[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_All_Models_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-) `Report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Subject Outlier: {subject_outlier}\")\n",
    "print(f\"Subject Normalization: {subject_normalization}\") \n",
    "print(f\"Subject Autoencoder: {subject_autoencoder}\")\n",
    "print(f\"Subject Dimension: {subject_dimension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Data = pd.concat([NN_All, SVM_All, SGD_All, DT_All, RF_All], axis=0) \n",
    "All_Data.reset_index(drop=True, inplace=True) \n",
    "All_Data.sort_values(by = [\"F1\"], ascending= False, inplace = True)  \n",
    "All_Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Models = {} \n",
    "All_Models[\"NN\"]  = [Barcode_NN_Models_Dict] \n",
    "All_Models[\"SVM\"] = [Barcode_SVM_Models_Dict, \"None\"] \n",
    "All_Models[\"SGD\"] = [Barcode_SGD_Models_Dict, \"None\"]\n",
    "All_Models[\"DT\"]  = [Barcode_DT_Models_Dict, \"None\"]\n",
    "All_Models[\"RF\"]  = [Barcode_RF_Models_Dict, \"None\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "\n",
    "model_dict = {}\n",
    "for i in range(len(All_Data)):\n",
    "    unique_label = \"_\".join(str(uuid.uuid4()).split(\"-\")[0:2] ) \n",
    "    # Take the accuracy by i\n",
    "    process    = process_barcode\n",
    "    accuracy   = All_Data[\"Accuracy\"][i] \n",
    "    model_name = All_Data[\"Model\"][i] \n",
    "\n",
    "    applications_condition = All_Data[\"Applications_Condition\"][i]  \n",
    "    applications = All_Data[\"Applications\"][i]  \n",
    "\n",
    "    try: \n",
    "        #print(f\"Model Name: {model_name}\") \n",
    "        if model_name == \"NeNe\":\n",
    "            model_name = \"NN\"\n",
    "            if applications_condition == \"Final_NeNe\":\n",
    "                model   = All_Models[ \"NN\" ][0][\"Model_0\"] \n",
    "                encoder = All_Models[ \"NN\" ][0][\"Encoder_0\"] \n",
    "        else:\n",
    "            pass \n",
    "        \n",
    "            if applications_condition == \"Final\":\n",
    "                model   = All_Models[ model_name ][0][\"Model_0\"] \n",
    "                encoder = \"None\"\n",
    "                encoder = \"None\" \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\") \n",
    "\n",
    "\n",
    "    attributes_dict = { \"process\": process,\n",
    "                        \"model_type\": model_name,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"applications_condition\":applications_condition, \n",
    "                        \"applications\": applications, \n",
    "                        \"model\": model,\n",
    "                         \"encoder\": encoder }  \n",
    "    \n",
    "    \n",
    "    model_dict[unique_label] = attributes_dict \n",
    "    \n",
    "model_Library_Current = pd.DataFrame(model_dict).T \n",
    "model_Library_Current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6- `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"data_raw\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(data_raw, file)   \n",
    "\n",
    "export_name = \"subject_data_full\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_data_full, file)   \n",
    "\n",
    "    \n",
    "export_name = \"subject_outlier_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_0, file)   \n",
    "\n",
    "export_name = \"subject_outlier_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier_1, file)   \n",
    "\n",
    "export_name = \"subject_outlier\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_outlier, file)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_normalization_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_0, file)   \n",
    "\n",
    "export_name = \"subject_normalization_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization_1, file)   \n",
    "\n",
    "export_name = \"subject_normalization\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_normalization, file)   \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_autoencoder_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_0, file)   \n",
    "\n",
    "export_name = \"subject_autoencoder_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder_1, file) \n",
    "\n",
    "export_name = \"subject_autoencoder\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_autoencoder, file)   \n",
    "\n",
    "\n",
    "\n",
    "export_name = \"subject_dimension_0\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_0, file)   \n",
    "\n",
    "export_name = \"subject_dimension_1\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension_1, file)   \n",
    "\n",
    "export_name = \"subject_dimension\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(subject_dimension, file)   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN\n",
    "export_name = \"NN_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All, file) \n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_prediction}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Models, file) \n",
    "\n",
    "# --------------------\n",
    "# SVM \n",
    "export_name = \"SVM_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SVM_All_Models, file) \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# SGD\n",
    "export_name = \"SGD_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(SGD_All_Models, file)\n",
    "\n",
    "    \n",
    "# --------------------\n",
    "# DT\n",
    "export_name = \"DT_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(DT_All_Models, file)\n",
    "\n",
    "# --------------------\n",
    "# RF\n",
    "export_name = \"RF_All_Models\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(RF_All_Models, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# NN \n",
    "export_name = \"NN_All_Encoders\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(NN_All_Encoders, file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"model_Library_Current\"\n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/model/library\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(model_Library_Current, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilimlan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
