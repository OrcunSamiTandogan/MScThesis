{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Step 1: Setup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pickle   \n",
    "from itertools import combinations\n",
    "from IPython.display import HTML  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"Jupyter has been running from Manager\") \n",
    "except: \n",
    "    %run s0_config.ipynb  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true     = pd.read_csv( true_data ) \n",
    "data_selected = pd.read_csv( selected_data )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Operation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-) `True Labels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-) `Overview`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-) `Preprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-) `Drop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_true = data_true.drop(columns = \"Unnamed: 0\") \n",
    "except:\n",
    "    data_true = data_true\n",
    "data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true.rename(columns = {\"Cluster\":\"Cell_Type\"}, inplace = True)     \n",
    "data_true.rename(columns = {\"Gene\":\"Gene_Marker\"}, inplace = True)\n",
    "data_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true[[\"Cell_Type\", \"Gene_Marker\",\"Expression\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-) `Strip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"new_cell_type_names = [] \n",
    "for i in data_true[\"Cell_Type\"]:\n",
    "    new_cell_type_names.append(i.replace(\"cells\", \"\").strip() )\n",
    "\n",
    "data_true[\"Cell_Type\"] = new_cell_type_names\n",
    "data_true[\"Cell_Type\"]\n",
    "\n",
    "new_gene_marker_names = [] \n",
    "for i in data_true[\"Gene_Marker\"]:\n",
    "    try:\n",
    "        new_gene_marker_names.append(i.replace(\"cells\", \"\").strip() )\n",
    "    except:\n",
    "        new_gene_marker_names.append(i) \n",
    "\n",
    "data_true[\"Gene_Marker\"] = new_gene_marker_names\n",
    "data_true[\"Gene_Marker\"]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-) `Augmentation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lenght Before: \", len(data_true))\n",
    "data_true = data_true.dropna(subset=[\"Gene_Marker\"]) \n",
    "print(\"Lenght After: \", len(data_true))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Iterate through each unique cell type in the dataset\n",
    "for i in pd.unique(data_true[\"Cell_Type\"]): \n",
    "    current_cell_type = i\n",
    "    print(\"Current Cell Type: \", current_cell_type)\n",
    "    \n",
    "    # Step 2: For each cell type, select the first 6 gene markers and their expression levels\n",
    "    genes20 = data_true[data_true[\"Cell_Type\"] == current_cell_type]\n",
    "    # Ensure gene markers are converted to strings\n",
    "    gene_list = genes20[\"Gene_Marker\"][:6].astype(str).tolist()  # Convert gene markers to strings and then to list\n",
    "    expression_list = genes20[\"Expression\"][:6].tolist()  # Corresponding expression levels\n",
    "    p_values_list = genes20[\"P Value\"][:6].tolist()  # Corresponding p-values \n",
    "    p_values_adj_list = genes20[\"P Value(Adj)\"][:6].tolist()  # Corresponding adjusted p-values \n",
    "    scores_list = genes20[\"Score\"][:6].tolist()  # Corresponding scores \n",
    "\n",
    "    \n",
    "    # Initialize lists to store the combinations of gene markers and their calculated expressions\n",
    "    all_gene_combinations = []\n",
    "    all_expression_combinations = []\n",
    "    p_values_combinations = [] \n",
    "    p_values_adj_combinations = []   \n",
    "    scores_combinations = []     \n",
    "    \n",
    "    # Step 3: Generate combinations of gene markers ranging from 2 to 5\n",
    "    for r in range(2, 6):  # Combining 2 to 5 gene markers\n",
    "        gene_combinations_r = list(combinations(gene_list, r))  # Generate gene marker combinations\n",
    "        expression_combinations_r = list(combinations(expression_list, r))  # Generate corresponding expression combinations\n",
    "        p_values_combinations_r = list(combinations(p_values_list, r))  # Generate corresponding p-values combinations \n",
    "        p_values_adj_combinations_r = list(combinations(p_values_adj_list, r))  # Generate corresponding adjusted p-values combinations\n",
    "        scores_combinations_r = list(combinations(scores_list, r))  # Generate corresponding scores combinations \n",
    "        \n",
    "        # Convert each gene combination tuple to a string joined by \",\"\n",
    "        gene_combinations_r = [\",\".join(comb) for comb in gene_combinations_r]\n",
    "        all_gene_combinations.extend(gene_combinations_r)  # Append to the list of all gene marker combinations\n",
    "        \n",
    "        # Step 4: Calculate the average expression for each gene combination\n",
    "        for expression_comb in expression_combinations_r:\n",
    "            average_expression = np.mean(expression_comb)  # Compute average expression for the combination\n",
    "            all_expression_combinations.append(average_expression)  # Append to the list of expressions\n",
    "\n",
    "        # Step 5: Calculate the average p-value for each gene combination\n",
    "        for p_values_comb in p_values_combinations_r:\n",
    "            average_p_values = np.mean(p_values_comb) # Compute average p-value for the combination\n",
    "            p_values_combinations.append(average_p_values) # Append to the list of p-values \n",
    "\n",
    "        # Step 6: Calculate the average adjusted p-value for each gene combination\n",
    "        for p_values_adj_comb in p_values_adj_combinations_r:\n",
    "            average_p_values_adj = np.mean(p_values_adj_comb)\n",
    "            p_values_adj_combinations.append(average_p_values_adj) # Append to the list of adjusted p-values \n",
    "\n",
    "        # Step 7: Calculate the average score for each gene combination\n",
    "        for scores_comb in scores_combinations_r:\n",
    "            average_scores = np.mean(scores_comb) \n",
    "            scores_combinations.append(average_scores) # Append to the list of scores \n",
    "\n",
    "    \n",
    "    # Step 8: Create a new DataFrame with the combined gene markers and their average expression\n",
    "    new_pairs_DF = pd.DataFrame({\n",
    "        \"Cell_Type\": current_cell_type,  # Cell type for the combinations\n",
    "        \"Gene_Marker\": all_gene_combinations,  # Combined gene markers\n",
    "        \"Expression\": all_expression_combinations,  # Calculated average expressions\n",
    "        \"P Value\": p_values_combinations,  # Calculated average p-values \n",
    "        \"P Value(Adj)\": p_values_adj_combinations,  # Calculated average adjusted p-values \n",
    "        \"Score\": scores_combinations  # Calculated average scores    \n",
    "\n",
    "\n",
    "    })\n",
    "    \n",
    "    # Step 9: Append the new combinations to the main DataFrame\n",
    "    data_true = pd.concat([data_true, new_pairs_DF], axis=0)  # Combine the original and the new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-) `Result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-) `Selected`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-) `Overview`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-) `Preprocessing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-) `Drop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_selected = data_selected.drop(columns = \"Unnamed: 0\") \n",
    "except:\n",
    "    data_selected = data_selected\n",
    "data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected.rename(columns = {\"Cluster\":\"Cell_Type\"}, inplace = True)     \n",
    "data_selected.rename(columns = {\"Gene\":\"Gene_Marker\"}, inplace = True)\n",
    "data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected[[\"Cell_Type\", \"Gene_Marker\",\"Expression\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-) `Strip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cell_type_names = [] \n",
    "for i in data_selected[\"Cell_Type\"]:\n",
    "    try:\n",
    "        new_cell_type_names.append(i.replace(\"cells\", \"\").strip() )\n",
    "    except:\n",
    "        new_cell_type_names.append(i) \n",
    "\n",
    "data_selected[\"Cell_Type\"] = new_cell_type_names\n",
    "data_selected[\"Cell_Type\"]\n",
    "\n",
    "new_gene_marker_names = [] \n",
    "for i in data_selected[\"Gene_Marker\"]:\n",
    "    try:\n",
    "        new_gene_marker_names.append(i.replace(\"cells\", \"\").strip() )\n",
    "    except:\n",
    "        new_gene_marker_names.append(i) \n",
    "\n",
    "data_selected[\"Gene_Marker\"] = new_gene_marker_names\n",
    "data_selected[\"Gene_Marker\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-) `Augmentation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Iterate through each unique cell type in the dataset\n",
    "for i in pd.unique(data_selected[\"Cell_Type\"]): \n",
    "    current_cell_type = i\n",
    "    print(\"Current Cell Type: \", current_cell_type)\n",
    "    \n",
    "    # Step 2: For each cell type, select the first 6 gene markers and their expression levels\n",
    "    genes20 = data_selected[data_selected[\"Cell_Type\"] == current_cell_type]\n",
    "    # Ensure gene markers are converted to strings\n",
    "    gene_list = genes20[\"Gene_Marker\"][:6].astype(str).tolist()  # Convert gene markers to strings and then to list\n",
    "    expression_list = genes20[\"Expression\"][:6].tolist()  # Corresponding expression levels\n",
    "    p_values_list = genes20[\"P Value\"][:6].tolist()  # Corresponding p-values \n",
    "    p_values_adj_list = genes20[\"P Value(Adj)\"][:6].tolist()  # Corresponding adjusted p-values \n",
    "    scores_list = genes20[\"Score\"][:6].tolist()  # Corresponding scores \n",
    "\n",
    "    \n",
    "    # Initialize lists to store the combinations of gene markers and their calculated expressions\n",
    "    all_gene_combinations = []\n",
    "    all_expression_combinations = []\n",
    "    p_values_combinations = [] \n",
    "    p_values_adj_combinations = []   \n",
    "    scores_combinations = []     \n",
    "    \n",
    "    # Step 3: Generate combinations of gene markers ranging from 2 to 5\n",
    "    for r in range(2, 6):  # Combining 2 to 5 gene markers\n",
    "        gene_combinations_r = list(combinations(gene_list, r))  # Generate gene marker combinations\n",
    "        expression_combinations_r = list(combinations(expression_list, r))  # Generate corresponding expression combinations\n",
    "        p_values_combinations_r = list(combinations(p_values_list, r))  # Generate corresponding p-values combinations \n",
    "        p_values_adj_combinations_r = list(combinations(p_values_adj_list, r))  # Generate corresponding adjusted p-values combinations\n",
    "        scores_combinations_r = list(combinations(scores_list, r))  # Generate corresponding scores combinations \n",
    "        \n",
    "        # Convert each gene combination tuple to a string joined by \",\"\n",
    "        gene_combinations_r = [\",\".join(comb) for comb in gene_combinations_r]\n",
    "        all_gene_combinations.extend(gene_combinations_r)  # Append to the list of all gene marker combinations\n",
    "        \n",
    "        # Step 4: Calculate the average expression for each gene combination\n",
    "        for expression_comb in expression_combinations_r:\n",
    "            average_expression = np.mean(expression_comb)  # Compute average expression for the combination\n",
    "            all_expression_combinations.append(average_expression)  # Append to the list of expressions\n",
    "\n",
    "        # Step 5: Calculate the average p-value for each gene combination\n",
    "        for p_values_comb in p_values_combinations_r:\n",
    "            average_p_values = np.mean(p_values_comb) # Compute average p-value for the combination\n",
    "            p_values_combinations.append(average_p_values) # Append to the list of p-values \n",
    "\n",
    "        # Step 6: Calculate the average adjusted p-value for each gene combination\n",
    "        for p_values_adj_comb in p_values_adj_combinations_r:\n",
    "            average_p_values_adj = np.mean(p_values_adj_comb)\n",
    "            p_values_adj_combinations.append(average_p_values_adj) # Append to the list of adjusted p-values \n",
    "\n",
    "        # Step 7: Calculate the average score for each gene combination\n",
    "        for scores_comb in scores_combinations_r:\n",
    "            average_scores = np.mean(scores_comb) \n",
    "            scores_combinations.append(average_scores) # Append to the list of scores \n",
    "\n",
    "    \n",
    "    # Step 8: Create a new DataFrame with the combined gene markers and their average expression\n",
    "    new_pairs_DF = pd.DataFrame({\n",
    "        \"Cell_Type\": current_cell_type,  # Cell type for the combinations\n",
    "        \"Gene_Marker\": all_gene_combinations,  # Combined gene markers\n",
    "        \"Expression\": all_expression_combinations,  # Calculated average expressions\n",
    "        \"P Value\": p_values_combinations,  # Calculated average p-values \n",
    "        \"P Value(Adj)\": p_values_adj_combinations,  # Calculated average adjusted p-values \n",
    "        \"Score\": scores_combinations  # Calculated average scores    \n",
    "\n",
    "\n",
    "    })\n",
    "    \n",
    "    # Step 9: Append the new combinations to the main DataFrame\n",
    "    data_selected = pd.concat([data_selected, new_pairs_DF], axis=0)  # Combine the original and the new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-) `Result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-) `Concatenation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-) `Concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.concat([data_true, data_selected], axis=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-) `Result`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_HTML = data_combined.to_html(index=False)\n",
    "\n",
    "try:\n",
    "    if manager == 1:\n",
    "        print(\"Jupyter has been running from Manager\") \n",
    "        #display(HTML(data_HTML))   \n",
    "except: \n",
    "    for i in pd.unique(data_combined[\"Cell_Type\"]):\n",
    "        print(i)  \n",
    "\n",
    "data_combined  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `End`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_data = data_true.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "export_name = \"data_full\" \n",
    "with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_text}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "    pickle.dump(data_full, file)   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"s1_setup.ipynb | Progress 1.2\") \n",
    "\n",
    "    export_name = \"subject_data\" \n",
    "    with open(os.path.join(access_data_path(f\"{process_barcode}/data/{folder_setup}\", f\"{export_name}\" + \".pkl\"))  , 'wb') as file: \n",
    "        pickle.dump(subject_data, file)   \n",
    "\n",
    "except Exception as e: \n",
    "    print(\"s1_setup.ipynb | Error: \", e) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bilim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
